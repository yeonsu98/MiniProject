{"cells":[{"cell_type":"markdown","metadata":{"id":"52e1f0fb"},"source":["# 안녕하세요^^ \n","# AIVLE 미니 프로젝트에 오신 여러분을 환영합니다.\n","* 본 과정에서는 실제 사례와 데이터를 기반으로 문제를 해결하는 전체 과정을 자기 주도형 실습으로 진행해볼 예정입니다.\n","* 앞선 교육과정을 정리하는 마음과 지금까지 배운 내용을 바탕으로 문제 해결을 해볼게요!\n","* 미니 프로젝트를 통한 문제 해결 과정 'A에서 Z까지', 지금부터 시작합니다!"],"id":"52e1f0fb"},{"cell_type":"markdown","metadata":{"id":"nUXBrxPDiFd9"},"source":["---"],"id":"nUXBrxPDiFd9"},{"cell_type":"markdown","metadata":{"id":"orwgQqTkEW0C"},"source":["# __[Study] 2. 구글 오픈 이미지 데이터 셋 활용 YOLOv5 ObjectDetection__\n","- Google Open Image Data?<br>\n","구글이 머신러닝을 위해 2016년에 공개한 이미지에 주석이 달린 데이터셋으로 약 190만개에 전문 라벨러들이 라벨링을 검수한 이미지들을 포함하고 있습니다. 데이터셋은 V1부터 계속 업데이트 되어 2020년 2월 기준으로 가장 최신 버전인 V6버전까지 공개되었습니다.\n"],"id":"orwgQqTkEW0C"},{"cell_type":"markdown","metadata":{"id":"ZPJwlsgmDmMQ"},"source":["## 0. 환경 설정하기"],"id":"ZPJwlsgmDmMQ"},{"cell_type":"markdown","metadata":{"id":"Y5OZR2I9sfVq"},"source":["### 1) 구글 드라이브 연결하기\n"],"id":"Y5OZR2I9sfVq"},{"cell_type":"code","execution_count":2,"metadata":{"id":"opm0PySCseDD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666586594856,"user_tz":-540,"elapsed":24759,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"outputId":"f0fe00a6-9240-4033-a097-58d6d920d93f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# 코랩 사용 시 구글 드라이브 연결\n","from google.colab import drive\n","drive.mount('/content/drive')"],"id":"opm0PySCseDD"},{"cell_type":"markdown","metadata":{"id":"bzQ5ZM05swzJ"},"source":["### 2) 경로 확인하기\n","- \"WORK_SPACE\" 에 본인 작업 경로 작성 후 실행(구글 드라이브 최상위에 압축해제 시 그대로 실행. 수정 X).<br>"],"id":"bzQ5ZM05swzJ"},{"cell_type":"code","execution_count":3,"metadata":{"id":"I66_jbFEsuz9","executionInfo":{"status":"ok","timestamp":1666586594860,"user_tz":-540,"elapsed":19,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"outputs":[],"source":["# ROOT_PATH 확인 \n","import os\n","\n","# 구글 드라이브 내 프로젝트 압축해제된 영역 (구글 드라이브 최상위에 압축해제하였을 경우 수정하지 않으셔도 됩니다.)\n","WORK_SPACE = \"\"\n","\n","if os.getcwd() == '/content' :\n","  # 구글 드라이브 사용 시 \n","  ROOT_PATH = '/content' + WORK_SPACE\n","else :\n","  ROOT_PATH = os.path.abspath('..')\n","\n"],"id":"I66_jbFEsuz9"},{"cell_type":"markdown","metadata":{"id":"xB7iJVzd7eHh"},"source":["### 3) YOLOv5파일 다운로드 및 설치\n","\n","![install](https://github.com/DrKAI/CV/raw/main/UltraLytics_manual/yolov5_install.png)\n","\n","[Install Page](https://github.com/ultralytics/yolov5)\n","\n"],"id":"xB7iJVzd7eHh"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2444,"status":"ok","timestamp":1666586602120,"user":{"displayName":"정연수","userId":"02873126808620457795"},"user_tz":-540},"id":"E8ClcNk0cU7A","outputId":"e9341261-a7fe-41eb-e7bd-753c9b4c5606"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Cloning into 'yolov5'...\n","remote: Enumerating objects: 14379, done.\u001b[K\n","remote: Total 14379 (delta 0), reused 0 (delta 0), pack-reused 14379\u001b[K\n","Receiving objects: 100% (14379/14379), 13.32 MiB | 16.46 MiB/s, done.\n","Resolving deltas: 100% (9955/9955), done.\n"]}],"source":["# UltraLytics git에서 복사하기\n","%cd /content\n","!git clone https://github.com/ultralytics/yolov5"],"id":"E8ClcNk0cU7A"},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5078,"status":"ok","timestamp":1666586607188,"user":{"displayName":"정연수","userId":"02873126808620457795"},"user_tz":-540},"id":"_0O_N_2VctaW","outputId":"72533c4a-4fec-4112-b8b5-350e311d7e47"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.21.6)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (7.1.2)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (2.23.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.7.3)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.12.1+cu113)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.13.1+cu113)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (4.64.1)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (2.9.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (1.3.5)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 24)) (0.11.2)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 41)) (7.9.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 42)) (5.4.8)\n","Collecting thop>=0.1.1\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2022.9.24)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (4.1.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.35.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.49.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.4.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (57.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.37.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.8.1)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.17.3)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 23)) (2022.4)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.9.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.2.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (0.7.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (4.4.2)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 12.1 MB/s \n","\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (2.0.10)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (2.6.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (0.2.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (5.1.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (4.8.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->-r requirements.txt (line 41)) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r requirements.txt (line 41)) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->-r requirements.txt (line 41)) (0.7.0)\n","Installing collected packages: jedi, thop\n","Successfully installed jedi-0.18.1 thop-0.1.1.post2209072238\n"]}],"source":["# yolov5 폴더 이동 및 requirements.txt 내부 패키지 설치\n","%cd /content/yolov5\n","!pip install -r requirements.txt"],"id":"_0O_N_2VctaW"},{"cell_type":"markdown","metadata":{"id":"av7r3quaDmMV"},"source":["### 4) 라이브러리 불러오기\n","필요시 추가 라이브러리는 설치해서 사용하세요."],"id":"av7r3quaDmMV"},{"cell_type":"code","execution_count":6,"metadata":{"id":"ZYimZcrODmMW","scrolled":false,"executionInfo":{"status":"ok","timestamp":1666586607189,"user_tz":-540,"elapsed":13,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"outputs":[],"source":["# 필요 라이브러리 불러오기.\n","import glob\n","import yaml\n","from IPython.display import Image"],"id":"ZYimZcrODmMW"},{"cell_type":"markdown","metadata":{"id":"49648b6d"},"source":["---"],"id":"49648b6d"},{"cell_type":"markdown","metadata":{"id":"vocational-animal"},"source":["## 1. 데이터 불러오기\n","* OIDv4_ToolKit을 활용하여 Google Open Dataset 다운로드하기\n","> ① Google Open Dataset 검색<br>\n","  https://storage.googleapis.com/openimages/web/index.html<br>\n","  Google Open Image Dataset 특징 : COCO와 비슷하지만, 용량은 훨씬 많음.<br>\n","> ② OID Toolkit 설치<br>\n","  https://github.com/EscVM/OIDv4_ToolKit/<br>\n","  https://github.com/theAIGuysCode/OIDv4_ToolKit/<br> \n","```# 코드로 형식 지정됨\n","!git clone https://github.com/theAIGuysCode/OIDv4_ToolKit.git\n","%cd OIDv4_ToolKit\n","!pip install -r requirements.txt\n","```\n","> ③ OID Toolkit을 활용하여 Dataset 다운로드 하기<br>\n","```# 코드로 형식 지정됨\n","!python main.py downloader --classes Apple Orange --type_csv validation\n","```\n"],"id":"vocational-animal"},{"cell_type":"markdown","metadata":{"id":"OTqROJ9xMyPk"},"source":["<font color=\"green\">[실습문제]</font> 1. OID Toolkit을 다운로드하고 설치하세요."],"id":"OTqROJ9xMyPk"},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":552,"status":"ok","timestamp":1666586624328,"user":{"displayName":"정연수","userId":"02873126808620457795"},"user_tz":-540},"id":"FgwGNwAR7KSd","outputId":"cb8fc103-f1bb-42b0-a830-1197b4ecca02"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["# 현재 경로 화인하기\n","%pwd\n","%cd /content"],"id":"FgwGNwAR7KSd"},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":14642,"status":"ok","timestamp":1666586639771,"user":{"displayName":"정연수","userId":"02873126808620457795"},"user_tz":-540},"id":"W_YVEdsh2LL7","outputId":"c62e5b92-43ec-4468-8af4-ed9352e819c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'OIDv4_ToolKit'...\n","remote: Enumerating objects: 444, done.\u001b[K\n","remote: Total 444 (delta 0), reused 0 (delta 0), pack-reused 444\u001b[K\n","Receiving objects: 100% (444/444), 34.09 MiB | 16.58 MiB/s, done.\n","Resolving deltas: 100% (157/157), done.\n","/content/OIDv4_ToolKit\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.3.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.21.6)\n","Collecting awscli\n","  Downloading awscli-1.25.97-py3-none-any.whl (3.9 MB)\n","\u001b[K     |████████████████████████████████| 3.9 MB 15.2 MB/s \n","\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.24.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (4.64.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 1)) (2022.4)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 1)) (1.15.0)\n","Collecting botocore==1.27.96\n","  Downloading botocore-1.27.96-py3-none-any.whl (9.3 MB)\n","\u001b[K     |████████████████████████████████| 9.3 MB 58.9 MB/s \n","\u001b[?25hCollecting PyYAML<5.5,>=3.10\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 74.1 MB/s \n","\u001b[?25hCollecting rsa<4.8,>=3.1.2\n","  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n","Collecting colorama<0.4.5,>=0.2.5\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting s3transfer<0.7.0,>=0.6.0\n","  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.8 MB/s \n","\u001b[?25hCollecting docutils<0.17,>=0.10\n","  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n","\u001b[K     |████████████████████████████████| 548 kB 78.0 MB/s \n","\u001b[?25hCollecting urllib3\n","  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 61.2 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<4.8,>=3.1.2->awscli->-r requirements.txt (line 3)) (0.4.8)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, rsa, PyYAML, docutils, colorama, awscli\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: rsa\n","    Found existing installation: rsa 4.9\n","    Uninstalling rsa-4.9:\n","      Successfully uninstalled rsa-4.9\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","  Attempting uninstall: docutils\n","    Found existing installation: docutils 0.17.1\n","    Uninstalling docutils-0.17.1:\n","      Successfully uninstalled docutils-0.17.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.12 which is incompatible.\u001b[0m\n","Successfully installed PyYAML-5.4.1 awscli-1.25.97 botocore-1.27.96 colorama-0.4.4 docutils-0.16 jmespath-1.0.1 rsa-4.7.2 s3transfer-0.6.0 urllib3-1.26.12\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["yaml"]}}},"metadata":{}}],"source":["# 실습해보세요\n","!git clone https://github.com/theAIGuysCode/OIDv4_ToolKit.git\n","%cd OIDv4_ToolKit\n","!pip install -r requirements.txt"],"id":"W_YVEdsh2LL7"},{"cell_type":"markdown","metadata":{"id":"tgKkaBmH1kVf"},"source":["<font color=\"green\">[실습문제]</font> 2. OID Toolkit을 활용하여 Google Open Dataset 에서 'Helmet', 'Person' 키워드로 검색한 데이터 셋을 다운로드 하세요.\n","> --classes : Helmet, Person<br>\n","> --multiclasses : 다양한 class의 이미지를 다른 폴더에 넣는게 아니라 하나의 폴더에 묶어서 다운로드<br>\n","> --limit : 카테고리당, 최대 이미지 수<br>"],"id":"tgKkaBmH1kVf"},{"cell_type":"code","source":["%pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"E8Ufl4PLXtaa","executionInfo":{"status":"ok","timestamp":1666587748985,"user_tz":-540,"elapsed":8,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"outputId":"32c8628d-a2bb-413c-82af-8f9f26b1db57"},"id":"E8Ufl4PLXtaa","execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/yolov5'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["%cd /content/OIDv4_ToolKit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9D02i58vXvOv","executionInfo":{"status":"ok","timestamp":1666587777755,"user_tz":-540,"elapsed":349,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"outputId":"1596fbcd-5396-4c7a-f842-c1f0fcc5cf68"},"id":"9D02i58vXvOv","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/OIDv4_ToolKit\n"]}]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":198511,"status":"ok","timestamp":1666587978564,"user":{"displayName":"정연수","userId":"02873126808620457795"},"user_tz":-540},"id":"BRgP4wKe1jkI","outputId":"b7187f82-7c42-452a-f162-86c9d5181f8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[92m\n","\t\t   ___   _____  ______            _    _    \n","\t\t .'   `.|_   _||_   _ `.         | |  | |   \n","\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n","\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n","\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n","\t\t `.___.'|_____||______.'   \\__/     |_____|\n","\t\u001b[0m\n","\u001b[92m\n","             _____                    _                 _             \n","            (____ \\                  | |               | |            \n","             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n","            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n","            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n","            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n","                                                          \n","        \u001b[0m\n","    [INFO] | Downloading ['Helmet', 'Person'] together.\u001b[0m\n","\u001b[91m   [ERROR] | Missing the class-descriptions-boxable.csv file.\u001b[0m\n","\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n","\r...72%, 0 MB, 106171 KB/s, 0 seconds passed\r...145%, 0 MB, 72704 KB/s, 0 seconds passed\n","\u001b[94m[DOWNLOAD] | File class-descriptions-boxable.csv downloaded into OID/csv_folder/class-descriptions-boxable.csv.\u001b[0m\n","\u001b[91m   [ERROR] | Missing the train-annotations-bbox.csv file.\u001b[0m\n","\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n","...100%, 1138 MB, 42983 KB/s, 27 seconds passed\n","\u001b[94m[DOWNLOAD] | File train-annotations-bbox.csv downloaded into OID/csv_folder/train-annotations-bbox.csv.\u001b[0m\n","\n","\u001b[95mHelmet\u001b[0m\n","    [INFO] | Downloading train images.\u001b[0m\n","    [INFO] | [INFO] Found 7608 online images for train.\u001b[0m\n","    [INFO] | Limiting to 100 images.\u001b[0m\n","    [INFO] | Download of 100 images in train.\u001b[0m\n","100% 100/100 [00:40<00:00,  2.45it/s]\n","    [INFO] | Done!\u001b[0m\n","    [INFO] | Creating labels for Helmet of train.\u001b[0m\n","    [INFO] | Labels creation completed.\u001b[0m\n","\n","\u001b[95mPerson\u001b[0m\n","    [INFO] | Downloading train images.\u001b[0m\n","    [INFO] | [INFO] Found 248384 online images for train.\u001b[0m\n","    [INFO] | Limiting to 100 images.\u001b[0m\n","    [INFO] | Download of 98 images in train.\u001b[0m\n","100% 98/98 [00:44<00:00,  2.18it/s]\n","    [INFO] | Done!\u001b[0m\n","    [INFO] | Creating labels for Person of train.\u001b[0m\n","    [INFO] | Labels creation completed.\u001b[0m\n","\u001b[92m\n","\t\t   ___   _____  ______            _    _    \n","\t\t .'   `.|_   _||_   _ `.         | |  | |   \n","\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n","\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n","\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n","\t\t `.___.'|_____||______.'   \\__/     |_____|\n","\t\u001b[0m\n","\u001b[92m\n","             _____                    _                 _             \n","            (____ \\                  | |               | |            \n","             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n","            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n","            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n","            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n","                                                          \n","        \u001b[0m\n","    [INFO] | Downloading ['Helmet', 'Person'] together.\u001b[0m\n","\u001b[91m   [ERROR] | Missing the validation-annotations-bbox.csv file.\u001b[0m\n","\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n","...100%, 16 MB, 55334 KB/s, 0 seconds passed\n","\u001b[94m[DOWNLOAD] | File validation-annotations-bbox.csv downloaded into OID/csv_folder/validation-annotations-bbox.csv.\u001b[0m\n","\n","\u001b[95mHelmet\u001b[0m\n","    [INFO] | Downloading validation images.\u001b[0m\n","    [INFO] | [INFO] Found 274 online images for validation.\u001b[0m\n","    [INFO] | Limiting to 50 images.\u001b[0m\n","    [INFO] | Download of 50 images in validation.\u001b[0m\n","100% 50/50 [00:20<00:00,  2.49it/s]\n","    [INFO] | Done!\u001b[0m\n","    [INFO] | Creating labels for Helmet of validation.\u001b[0m\n","    [INFO] | Labels creation completed.\u001b[0m\n","\n","\u001b[95mPerson\u001b[0m\n","    [INFO] | Downloading validation images.\u001b[0m\n","    [INFO] | [INFO] Found 6436 online images for validation.\u001b[0m\n","    [INFO] | Limiting to 50 images.\u001b[0m\n","    [INFO] | Download of 50 images in validation.\u001b[0m\n","100% 50/50 [00:20<00:00,  2.43it/s]\n","    [INFO] | Done!\u001b[0m\n","    [INFO] | Creating labels for Person of validation.\u001b[0m\n","    [INFO] | Labels creation completed.\u001b[0m\n"]}],"source":["!python main.py downloader --classes Helmet Person --type_csv train --multiclasses 1 --limit 100 -y\n","!python main.py downloader --classes Helmet Person --type_csv validation --multiclasses 1 --limit 50 -y"],"id":"BRgP4wKe1jkI"},{"cell_type":"markdown","metadata":{"id":"3d25c0a2"},"source":["## 2. 모델링을 위한 Train Data(학습)와 Validation 데이터(검증) 확인\n","* 다운로드 완료된 데이터는 '/content/OID/OIDv4_ToolKit/OID/Dataset/\"에 위치하고 있습니다.\n","* [Tip] 폴더 구조를 불러올 때 쓰는 glob 라이브러리 활용\n","\n","> [방법1] \n",">> DATA_PATH = \"/content/OIDv4_ToolKit/OID/Dataset\" <br>\n",">> TRAIN_PATH = \"/content/OIDv4_ToolKit/OID/Dataset/train\"<br>\n",">> VALIDATION_PATH = \"/content/OIDv4_ToolKit/OID/Dataset/validation\"<br>"],"id":"3d25c0a2"},{"cell_type":"markdown","metadata":{"id":"uKsfTWsUNUrj"},"source":["<font color=\"green\">[실습문제]</font> 3. Train Data와 Test Data 이미지 개수를 확인하세요."],"id":"uKsfTWsUNUrj"},{"cell_type":"code","execution_count":32,"metadata":{"id":"KfH7TeTQ-jC6","executionInfo":{"status":"ok","timestamp":1666588027474,"user_tz":-540,"elapsed":3,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"outputs":[],"source":["# 라이브러리 불러오기\n","import glob"],"id":"KfH7TeTQ-jC6"},{"cell_type":"code","execution_count":33,"metadata":{"id":"500TMbwkNoYV","executionInfo":{"status":"ok","timestamp":1666588027956,"user_tz":-540,"elapsed":5,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"outputs":[],"source":["# 실습해보세요.\n","train_image_list = glob.glob(\"/content/OIDv4_ToolKit/OID/Dataset/train/*/*.jpg\")\n","validation_image_list = glob.glob(\"/content/OIDv4_ToolKit/OID/Dataset/validation/*/*.jpg\")"],"id":"500TMbwkNoYV"},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1666588027957,"user":{"displayName":"정연수","userId":"02873126808620457795"},"user_tz":-540},"id":"hCGtY3ypqROn","outputId":"9cf3f324-5de0-47b5-b7dd-11b7b9ebc7d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["학습 데이터(이미지) 개수 : 198\n","검증 데이터(이미지) 개수 : 100\n"]}],"source":["print(\"학습 데이터(이미지) 개수 : \" + str(len(train_image_list)))\n","print(\"검증 데이터(이미지) 개수 : \" + str(len(validation_image_list)))"],"id":"hCGtY3ypqROn"},{"cell_type":"markdown","metadata":{"id":"RU_w0oUlKwpU"},"source":["<font color=\"green\">[실습문제]</font> 4. label 디렉토리 내 .txt 파일을 확인하여 YOlOv5 학습을 위한 label .txt 파일과의 차이를 확인하세요.  <br> \n","> [Tip] 리눅스에서 파일 내용을 확인할 때는 cat 명령어를 사용합니다."],"id":"RU_w0oUlKwpU"},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":549,"status":"ok","timestamp":1666588111642,"user":{"displayName":"정연수","userId":"02873126808620457795"},"user_tz":-540},"id":"jTKotm04Kryj","outputId":"db9daeea-8a9d-42ef-bded-a87e128ef70c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Person 670.08 94.08 938.24 386.559744\n","Person 0.0 357.759744 58.88 634.239744\n","Person 522.24 91.52025599999999 661.12 330.879744\n","Person 984.96 330.879744 1023.36 397.43999999999994\n"]}],"source":["# 실습해보세요.\n","label_list = glob.glob(\"/content/OIDv4_ToolKit/OID/Dataset/train/Helmet_Person/Label/*.txt\")\n","%cat \"{label_list[100]}\""],"id":"jTKotm04Kryj"},{"cell_type":"markdown","metadata":{"id":"ooJza-Gx2kaD"},"source":["<font color=\"green\">[실습문제]</font> 5. \"/OIDv4_Toolkit\" 내 \"classes.txt\" 파일의 class 구성을 Helmet, Person으로 수정하고,<br>\n","&emsp;&emsp;&emsp;&emsp;&emsp;YOLO 학습을 위해 center_x, center_t, Dw, Dh 의 값을 정규화 후 다시 생성된 label .txt 파일을 확인해보세요.<br> \n","> [Tip] 정규화는 covert_annotaion.py 모듈을 활용하시면 진행 가능합니다.<br>\n","> &emsp;&emsp; Python 모듈은 !python ooooooo.py command를 입력하면 실행 가능합니다. <br>\n","> &emsp;&emsp; 새로 생성된 label .txt 파일은 이미지가 있는 경로(\"/Helmet_Person\")에 함께 생성됩니다."],"id":"ooJza-Gx2kaD"},{"cell_type":"code","source":["%pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"amvS1unzZvPk","executionInfo":{"status":"ok","timestamp":1666588279186,"user_tz":-540,"elapsed":8,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"outputId":"b5e26045-9d23-4abd-baad-954762d8dcfe"},"id":"amvS1unzZvPk","execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/OIDv4_ToolKit'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":41}]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1666588132834,"user":{"displayName":"정연수","userId":"02873126808620457795"},"user_tz":-540},"id":"zvIkivou_DFP","outputId":"bd1cdadd-de17-4cff-a368-81b80651bc8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/OIDv4_ToolKit\n"]}],"source":["# 현재 경로 확인\n","%pwd\n","%cd /content/OIDv4_ToolKit/\n"],"id":"zvIkivou_DFP"},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15388,"status":"ok","timestamp":1666588454583,"user":{"displayName":"정연수","userId":"02873126808620457795"},"user_tz":-540},"id":"wGVKlPB92j3a","outputId":"0c30096b-dd66-47f2-fca2-8ea2e5224b75"},"outputs":[{"output_type":"stream","name":"stdout","text":["Currently in subdirectory: validation\n","Converting annotations for class:  Helmet_Person\n","100% 100/100 [00:03<00:00, 29.63it/s]\n","Currently in subdirectory: train\n","Converting annotations for class:  Helmet_Person\n","100% 198/198 [00:11<00:00, 17.01it/s]\n"]}],"source":["# 실습해보세요.\n","!python convert_annotations.py"],"id":"wGVKlPB92j3a"},{"cell_type":"code","execution_count":50,"metadata":{"id":"FBC5up3s1vMN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666588598789,"user_tz":-540,"elapsed":9,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"outputId":"5a34132e-2d3e-4433-9e53-b9837c82ffee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Person 670.08 94.08 938.24 386.559744\n","Person 0.0 357.759744 58.88 634.239744\n","Person 522.24 91.52025599999999 661.12 330.879744\n","Person 984.96 330.879744 1023.36 397.43999999999994\n","Helmet 318.091587 68.23424 460.386399 228.891648\n","Person 190.553506 68.436992 769.500446 974.229504\n"]}],"source":["train_label_list = glob.glob(\"/content/OIDv4_ToolKit/OID/Dataset/train//Helmet_Person/Label/*.txt\")\n","validation_label_list = glob.glob(\"/content/OIDv4_ToolKit/OID/Dataset/validation/Helmet_Person/Label/*.txt\")\n","%cat \"{train_label_list[100]}\"\n","%cat \"{validation_label_list[0]}\""],"id":"FBC5up3s1vMN"},{"cell_type":"markdown","metadata":{"id":"dDJfSRaPBtPy"},"source":["<font color=\"green\">[실습문제]</font> 6. annotraion 정보를 convert 완료된 데이터를 복사/이동하여 YOLOv5 학습을 위한 디렉토리 구조로 변경합니다.<br>\n","* YOLOv5 모델링을 위해서 데이터 디렉터리 구조는 다음과 같이 만들어야 합니다.<br>\n","- 데이터 디렉터리 구조 <br>\n","> data ─ train&ensp;┐ <br>\n","> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;├ images <br>\n","> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;├ labels <br>\n","> &emsp;&emsp; ─ validation&ensp; ┐ <br>\n","> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&ensp;├ images <br>\n","> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&ensp;├ labels <br>"],"id":"dDJfSRaPBtPy"},{"cell_type":"code","execution_count":51,"metadata":{"id":"hpFtBcC-BnRI","executionInfo":{"status":"ok","timestamp":1666588714681,"user_tz":-540,"elapsed":553,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"outputs":[],"source":["# DATA_PATH 지정하기\n","DATA_PATH = \"/content/data\"\n","TRAIN_PATH = DATA_PATH + \"/train\"\n","VALIDATION_PATH = DATA_PATH + \"/validation\"\n","\n","import shutil\n","\n","def file_copy(file_list, file_path):\n","  if not os.path.exists(file_path):\n","    os.makedirs(file_path)  \n","  for f in file_list:\n","    shutil.move(f, file_path)"],"id":"hpFtBcC-BnRI"},{"cell_type":"code","execution_count":52,"metadata":{"id":"saORJr0OBY-l","executionInfo":{"status":"ok","timestamp":1666588718738,"user_tz":-540,"elapsed":372,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"outputs":[],"source":["file_copy(train_label_list, TRAIN_PATH + \"/labels\")\n","file_copy(train_image_list, TRAIN_PATH + \"/images\")\n","file_copy(validation_label_list, VALIDATION_PATH + \"/labels\")\n","file_copy(validation_image_list, VALIDATION_PATH + \"/images\")"],"id":"saORJr0OBY-l"},{"cell_type":"markdown","metadata":{"id":"HzSe0SSnoKXM"},"source":["## 3. Yaml 파일 생성하기\n","* Yaml이란? xml과 json 포맷과 같이 타 시스템 간에 데이터를 주고받을 때 약속된 포맷(규칙)이 정의되어있는 파일 형식<br>\n","https://abluesnake.tistory.com/128<br>"],"id":"HzSe0SSnoKXM"},{"cell_type":"markdown","metadata":{"id":"IiRgiZV4oKXM"},"source":["<font color=\"green\">[실습문제]</font> 6. train, validation 이미지 경로를 txt 파일로 저장하기 \n","- yolov5 학습을 위해 data.yaml 파일 내 \n","train, val의 값을 이미지 파일들의 경로를 저장한 .txt 파일로 변경이 필요합니다.\n","```\n","with open(DATA_PATH + '/train.txt', 'w') as f:\n","      f.write('\\n'.join(train_image_list) + '\\n')\n","```\n"],"id":"IiRgiZV4oKXM"},{"cell_type":"code","execution_count":59,"metadata":{"id":"Bvq8D4QboM68","executionInfo":{"status":"ok","timestamp":1666589532993,"user_tz":-540,"elapsed":520,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"outputs":[],"source":["# 실습해보세요\n","train_image_list = glob.glob(TRAIN_PATH + \"/*/*.jpg\")\n","validation_image_list = glob.glob(VALIDATION_PATH + \"/*/*.jpg\")\n","\n","\n","with open(DATA_PATH + '/train.txt', 'w') as f:\n","    f.write('\\n'.join(train_image_list) + '\\n')\n","\n","with open(DATA_PATH + '/validation.txt', 'w') as f:\n","    f.write('\\n'.join(validation_image_list) + '\\n')"],"id":"Bvq8D4QboM68"},{"cell_type":"markdown","metadata":{"id":"bHhUf2Y4obSV"},"source":["<font color=\"green\">[실습문제]</font> 7. \"data.yaml\" 파일을 생성하고 내 라벨 클래스들과 경로를 입력해주세요.\n","* data.yaml 파일은 딕셔너리 형태로 되어 있습니다.\n","> - 데이터 경로 <br>\n","> train : DATA_PATH + '/train.txt'<br>\n","> val : DATA_PATH + '/validation.txt'<br>\n","> - 클래스 수 <br>\n","> nc: 2<br>\n","> - 클래스 이름 <br>\n","> names: ['Helmet', 'Person'] <br>\n","```\n","data = {\n","              'train' : ,\n","              'val' : ,\n","              'nc' : ,\n","              'names' : [  ]       \n","}\n","```\n","* yaml 파일은 dump() 메소드로 쓰기 가능합니다.\n","```\n","with open(DATA_PATH + '/data.yaml', 'w') as f:\n","        yaml.dump(data, f)\n","```\n"],"id":"bHhUf2Y4obSV"},{"cell_type":"code","execution_count":60,"metadata":{"id":"GKq1-6sEF9xc","executionInfo":{"status":"ok","timestamp":1666589536631,"user_tz":-540,"elapsed":3,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"outputs":[],"source":["# 라이브러리 불러오기\n","import yaml"],"id":"GKq1-6sEF9xc"},{"cell_type":"code","source":["data = {\n","    'name' : ['Helmet', 'Person'],\n","    'nc' : 2, # class num\n","    'train' : DATA_PATH + '/train.txt',\n","    'val' : DATA_PATH + '/validation.txt'\n","}"],"metadata":{"id":"kYydX3AFdRc9"},"id":"kYydX3AFdRc9","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1666589538415,"user":{"displayName":"정연수","userId":"02873126808620457795"},"user_tz":-540},"id":"eE8D2BB6roG7","outputId":"9906bdd7-c5df-4aa8-8bc9-1f85a7ff1ba0"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'train': '/content/data/train.txt', 'val': '/content/data/validation.txt', 'nc': 2, 'names': ['Helmet', 'Person']}\n"]}],"source":["# 실습해보세요.\n","data = {\n","          'train' : DATA_PATH + '/train.txt',\n","          'val' : DATA_PATH + '/validation.txt',\n","          'nc' : 2 ,\n","          'names' : [ 'Helmet', 'Person' ]       \n","}\n","\n","with open(DATA_PATH + '/data.yaml', 'w') as f:\n","  yaml.dump(data, f)\n","\n","print(data)"],"id":"eE8D2BB6roG7"},{"cell_type":"markdown","metadata":{"id":"f0oi8s0DLcFX"},"source":["## 4. Yolov5 를 이용한 모델 학습\n","> https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data/<br>\n","> ○ [Command] \n","```# 코드로 형식 지정됨\n"," !python train.py --img 640 --epochs 3 --data coco.yaml --weights yolov5n.pt --batch 128 \n","                                                                  yolov5s            64\n","                                                                  yolov5m            40\n","                                                                  yolov5l            24\n","                                                                  yolov5x            16\n","```\n","\n","> ○ [Properties]\n",">> --img: 입력 이미지 크기 <br>\n",">> --batch: 배치 크기 <br>\n",">> --epochs: 학습 epoch 수 <br>\n",">> --data: data.yaml 파일 경로 <br>\n",">> --cfg: 모델 구성 지정 <br>\n",">> --weights: 가중치에 대한 사용자 정의 경로를 지정<br>\n",">> --name: 모델이 저장 될 폴더 이름 <br>\n",">> --nosave: 최종 체크포인트만 저장<br>\n",">> --cache: 더 빠른 학습을 위해 이미지를 캐시<br>\n","\n","> ○ [Select Model]<br>\n","><img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/model_comparison.png\" width=\"640px\">"],"id":"f0oi8s0DLcFX"},{"cell_type":"markdown","metadata":{"id":"szLs-keis-q7"},"source":["<font color=\"green\">[실습문제]</font> 8. Yolov5s(small) 모델을 활용하여 학습하세요.\n","> img size : 416 <br>\n","> batch size : 16 <br>\n","> epochs : 5 <br>\n","> data : /content/data/data.yaml <br>\n","> weights : yolov5s.pt <br>\n","> name : OID_helmet_data_detection <br>"],"id":"szLs-keis-q7"},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1666589542439,"user":{"displayName":"정연수","userId":"02873126808620457795"},"user_tz":-540},"id":"GLWAsKIMTaMp","outputId":"e7961fba-8b44-454a-fe63-9420f9bbc8fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n"]}],"source":["# 실행 경로 이동\n","%pwd\n","%cd /content/yolov5"],"id":"GLWAsKIMTaMp"},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11411,"status":"ok","timestamp":1666589586666,"user":{"displayName":"정연수","userId":"02873126808620457795"},"user_tz":-540},"id":"dgqhwjxeLItu","outputId":"532139d1-41e7-4aa5-863b-00b4b1e4efd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/data/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=OID_helmet_data_detection, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v6.2-205-geef9057 Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Overriding model.yaml nc=80 with nc=2\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7025023 parameters, 7025023 gradients, 16.0 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/train.cache' images and labels... 198 found, 0 missing, 0 empty, 198 corrupt: 100% 198/198 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/004ed0f30ff6c86e.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/031df2f238968e62.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/0323ec32a437699d.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/04dbcdd83c510b13.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/082853c578da0fdd.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/0855b0de9820af60.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/0b3e01007f7ed9dd.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/0b51694b97b286bc.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/0d3e94c2fe00e22d.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/0e6c7d3403f98596.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/10098923e741c6f5.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/104202ac022d052b.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/10d8098a70694c0d.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/12ec9225c35c7325.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/12eda05b42a0df6e.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/132ae0b60170e3e6.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/13b1b340cf777c45.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/141921f55824ac18.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/1574e12729cb08ec.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/15e6f3e4ecfdda68.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/17a220f2b9fd9161.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/1b5d55a3a1c60746.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/1be357157a029988.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/1c97e58e41d29a4e.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/1dafd4925a085def.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/1f2ac200d852a625.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/2048148e506e0f0a.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/20c34a6bda1b4aaf.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/2164b55d4a23f6f2.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/22cbad33630d619d.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/230fc4216f6d58f0.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/2c555ea8b948ba51.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/2c854a92c122b566.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/2ca0a872088b1e28.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/2cfcca20dacce5e3.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/2d01f504902bc10c.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/2d3df4e820a901c6.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/2e178f3fbf10394a.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/2fd48ecee60b2c1d.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/30da821f805959ae.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/30eef060454d1cde.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/3120e605d8741c10.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/312a212eeb4f6216.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/31ee6890410a17ff.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/3324f8b75e5617e5.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/35edb24d440c89f5.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/37371174b50ddff6.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/3a356f544ab7bf1c.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/3a4fb2d6a0689b3c.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/3da4728dcf3d46ed.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/3e850ebf324097ae.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/41691d4971f0be91.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/42875395d8f16c9a.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/43323f1dca5f3d65.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/439b37d391081fac.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/467449da5115d112.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/4781055c6c6d9d83.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/481043e63272ca41.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/48cb696b54d734ee.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/49b1726b433bdd26.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/4a7be6f8085e7d5b.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/4a925764a5c9bce0.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/4b8988d5d5ad2654.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/4c887a4882211644.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/4d2b253ead65c991.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/4dc86c525df187f6.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/4e4fa0eb5da85e81.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/4f548f88520670b7.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/505106c2d0dcc60d.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/54a80d3f97f38963.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/559e09bc4cffa2cd.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/58020925d9f16d45.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/58f5a15320c4444b.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/5b10f2afe280b799.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/5e126f50ce9e6b45.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/5ea2d854592b85a1.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/61c6371bd2b49b91.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/61d35d460f4dc2ae.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/65298d258215c875.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/659c1a7481c6d3e5.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/65e5249a5f89a8d0.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/68b875052ceb57d7.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/68f1e94f56d83559.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/68fb80426480bf5b.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/69f6528114a7a654.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/6bf9874847110f96.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/6cf0d1abb5a420a5.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/70203184bfbb8125.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/718d6e5baf4fae0c.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/7433ac1b4c130e05.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/754c8f9cf8cf92e3.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/755de4a07fffca26.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/7718104a8a18f8c3.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/7a9e9a2e5c53372f.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/7bbd13a3ce5bb4e8.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/7f14dc5ebf9a5b2c.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/7f4bbdae6007639c.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/7fb373a64c1405c2.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/820ef45443588dfa.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/835b2d83c512e04f.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/851590d6d3dc76df.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/85258989676a823b.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/8550be04204793f7.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/86fb9b487dd05a66.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/88cda191a66a5bca.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/8a31eceaeec5ad0e.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/8cb80ce69acf052c.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/8d26ba7e42388c01.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/8ef463913c00431d.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/92508db5fc16fd5e.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/92d8b3a99e015746.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/942f7966d0366dc2.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/944671bb8d2812dc.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/95ae7055d4792b42.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/97a67a6e3a8df5bf.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/9a216d69b3e87889.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/9b3ef73a643ad929.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/9df093df249c23c3.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/9e52830c12ef4922.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/9fa15810cdd4d88b.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/9fb581b3d0d01f2e.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/a2083b4b02bb8487.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/a2e32a05feecb4ae.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/a2f5e3b80002fad1.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/a36431c8959c0f3a.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/a3bef29794edd780.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/a538268f3a521662.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/a6069164cd98f287.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/a89434a29d3d2410.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/a8bb38e1f134279a.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/a98cbf52b8fcbe2c.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/aa53f2bc88f284a0.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/ae2279f5a48c2070.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/ae5a25ebd5da4e15.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/ae8ba3b5580d2473.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/ae9c7a4f8ea0454b.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/aefdca06de959ba4.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/b0cc79e62b5f87a9.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/b152ff272a803bae.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/b18883a48520f263.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/b2318fa1ca329d1a.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/b261d031601fcee9.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/b3aa4a119dd9ecf5.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/b3b0911aeacf8160.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/b4c17535e80432bb.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/b580bf08115882b7.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/b8e75bd648927fdc.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/bb4972f2e9e71728.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/bc6b6a23a89fae36.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/beb7a2afa5b179c7.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/bf0c05d9e23adab5.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/bf8ae97a449538be.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/c12398a8dbb4d377.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/c31ddb5de1adbfb0.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/c4c0eed1d768b004.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/c8a88cecec7c5a40.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/ca06f6afda1ab97f.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/cb40e160ec3230ab.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/cc1cb62088ee15a6.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/ccab1a885f2af702.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/cdf0eba2f30fee7c.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/ce0b20bb346358bb.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/cf6ce7ea525aeb2d.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/cff03abc527aee01.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/d07e212cad3b5ded.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/d1e522d729568afa.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/d21cd4987100f60c.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/d33489c4bb755095.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/d38308752d721a42.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/d3c8b2f7d7657e4b.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/d63221173ba9f3e6.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/d8ef1e2d05d34ade.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/d98fadac206891c6.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/da691d6e79df0568.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/dc882adc3a2ec4e4.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/dcb1c4f29653fec2.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/de8a87f5725dee51.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/e127ea148b0ef22e.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/e14f4f2ec98c7090.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/e44df044ab2a51bc.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/e63e1c93e84cdb9d.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/e78d4f8c5d8a4f4d.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/e8cf522b9d921026.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/e8e2e15ea6e33dfb.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/e93b0b89fffa0a87.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/e9e9d68adc5cbfee.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/ea7e4782969dcdc3.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/f0eeabc10efad173.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/f6f48a3996bf4ed1.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/f72c4a67f546e363.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/f763d22026a4e70e.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/f7f8576449341a76.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/f8c31147f2017b83.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/fa0ef68ded44ca39.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/fac4ecf45c7395e7.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/fd502bd83af2369e.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/ff10af2c9913cb42.jpg: ignoring corrupt image/label: could not convert string to float: 'Helmet'\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data/train/images/ff994d43e15e0817.jpg: ignoring corrupt image/label: could not convert string to float: 'Person'\n","Traceback (most recent call last):\n","  File \"train.py\", line 630, in <module>\n","    main(opt)\n","  File \"train.py\", line 524, in main\n","    train(opt.hyp, opt, device, callbacks)\n","  File \"train.py\", line 199, in train\n","    shuffle=True)\n","  File \"/content/yolov5/utils/dataloaders.py\", line 135, in create_dataloader\n","    prefix=prefix)\n","  File \"/content/yolov5/utils/dataloaders.py\", line 501, in __init__\n","    labels, shapes, self.segments = zip(*cache.values())\n","ValueError: not enough values to unpack (expected 3, got 0)\n"]}],"source":["# 실습해보세요.\n","!python train.py --img 416 --batch 16 --epochs 5 --data /content/data/data.yaml --weights yolov5s.pt --name OID_helmet_data_detection"],"id":"dgqhwjxeLItu"},{"cell_type":"markdown","metadata":{"id":"d3G--l-Xf8ZG"},"source":["## 5. 모델 성능 평가\n","> Yolo에서는 모델의 성능(정확도)를 Mean Average Precision(mAP)를 통해 확인합니다. <br>\n","mAP가 높을수록 정확하고, 작을수록 부정확합니다. <br>\n","> AP를 계산할 때, precision-recall,IoU 와 연관이 있습니다. <br>\n"],"id":"d3G--l-Xf8ZG"},{"cell_type":"markdown","metadata":{"id":"iCKM0MCGe0NQ"},"source":["## 6. Test 데이터 추론하기 \n","* 해당 결과는 runs/detect/exp/ 위치에 저장됩니다.\n","> ○ [Command] \n","``` # 코드로 형식 지정됨\n","!python detect.py --source 0  # webcam\n","                           img.jpg  # image\n","                           vid.mp4  # video\n","                           screen  # screenshot\n","                           path/  # directory\n","                           'path/*.jpg'  # glob\n","                           'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n","                           'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n","```\n","> ○ [Properties] \n",">> -- source : test 데이터(이미지, 영상 파일 혹은 폴더) 경로 <br>\n",">> -- weights : 학습이 완료된 weight 파일 경로 (pt 형식) <br>\n",">> -- conf : IOU_threshold 값 (0 ~ 1 사이의 값)\n"],"id":"iCKM0MCGe0NQ"},{"cell_type":"markdown","metadata":{"id":"XpuLW8yAHN-W"},"source":["* TEST 데이터 다운로드하기(아래의 코드를 실행하세요)\n"],"id":"XpuLW8yAHN-W"},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1666590283730,"user":{"displayName":"정연수","userId":"02873126808620457795"},"user_tz":-540},"id":"Kgxu2agF2cAr","outputId":"9ae4908a-0360-41e5-ebb9-b3f8ae59d94d"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["# 현재 디렉토리 확인\n","%pwd\n","%cd /content"],"id":"Kgxu2agF2cAr"},{"cell_type":"code","execution_count":66,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2850,"status":"ok","timestamp":1666591050441,"user":{"displayName":"정연수","userId":"02873126808620457795"},"user_tz":-540},"id":"JnEqBQ8C2MeH","outputId":"4a01d41c-3f56-4b2f-c137-76427e49f173"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.25.11)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"]}],"source":["!pip install gdown"],"id":"JnEqBQ8C2MeH"},{"cell_type":"code","execution_count":67,"metadata":{"id":"AcNkxlOD2SYd","executionInfo":{"status":"ok","timestamp":1666591072955,"user_tz":-540,"elapsed":455,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"outputs":[],"source":["import gdown\n","import zipfile"],"id":"AcNkxlOD2SYd"},{"cell_type":"code","execution_count":68,"metadata":{"id":"ddT3ob9cBZX1","executionInfo":{"status":"ok","timestamp":1666591073356,"user_tz":-540,"elapsed":2,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"outputs":[],"source":["test_file_id = \"14PsLrMhL2v7n3dYjv2JOFWF6iIUFYhyQ\"\n","\n","def goolge_drive_download (file_id): \n","  google_path = 'https://drive.google.com/uc?id='\n","  output_name = 'download_file.zip'\n","\n","  gdown.download(google_path+file_id,output_name,quiet=False)\n","\n","  zip_file = \"/content/download_file.zip\"\n","\n","  \n","  with zipfile.ZipFile(zip_file) as z:\n","    z.extractall(\"/content\")\n","\n","  os.remove(zip_file) \n"],"id":"ddT3ob9cBZX1"},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1251,"status":"ok","timestamp":1666591077680,"user":{"displayName":"정연수","userId":"02873126808620457795"},"user_tz":-540},"id":"3G3jHfuW2XnO","outputId":"e49b593a-fe20-4530-c036-73b1ba5508d6"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=14PsLrMhL2v7n3dYjv2JOFWF6iIUFYhyQ\n","To: /content/download_file.zip\n","100%|██████████| 9.86M/9.86M [00:00<00:00, 278MB/s]\n"]}],"source":["goolge_drive_download(test_file_id)"],"id":"3G3jHfuW2XnO"},{"cell_type":"markdown","metadata":{"id":"F4I-AY3bp0Pb"},"source":["<font color=\"green\">[실습문제]</font> 9-1. 이미지를 소스로 한 객체 검출하기 \n","> 경로 \"TEST_IMAGE_PATH\" 의 이미지 파일들의 객체를 검출해 보세요.  \n","> [조건] \n","> ① img size : 416, ② IOU Threshold : 0.5, ③ 모델 weights : best.pt"],"id":"F4I-AY3bp0Pb"},{"cell_type":"code","execution_count":70,"metadata":{"id":"av7GzbrdH2HP","executionInfo":{"status":"ok","timestamp":1666591876886,"user_tz":-540,"elapsed":410,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"outputs":[],"source":["# 경로 설정\n","TEST_IMAGE_PATH = \"/content/data/test/images\""],"id":"av7GzbrdH2HP"},{"cell_type":"code","execution_count":71,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3490,"status":"ok","timestamp":1666591880365,"user":{"displayName":"정연수","userId":"02873126808620457795"},"user_tz":-540},"id":"J216grQfp0Pb","outputId":"c6be38a6-590a-4bd0-908f-2f27f902c221"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n","\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/OID_helmet_data_detection/weights/best.pt'], source=/content/data/test/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v6.2-205-geef9057 Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Traceback (most recent call last):\n","  File \"detect.py\", line 258, in <module>\n","    main(opt)\n","  File \"detect.py\", line 253, in main\n","    run(**vars(opt))\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"detect.py\", line 95, in run\n","    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n","  File \"/content/yolov5/models/common.py\", line 342, in __init__\n","    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n","  File \"/content/yolov5/models/experimental.py\", line 79, in attempt_load\n","    ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 699, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n","    super(_open_file, self).__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: '/content/yolov5/runs/train/OID_helmet_data_detection/weights/best.pt'\n"]}],"source":["# 실습해보세요\n","%cd /content/yolov5\n","\n","!python detect.py --source '{TEST_IMAGE_PATH}' --weights /content/yolov5/runs/train/OID_helmet_data_detection/weights/best.pt --img 416 --conf 0.5\n"],"id":"J216grQfp0Pb"},{"cell_type":"markdown","metadata":{"id":"7ow6CvdOOLcw"},"source":["<font color=\"green\">[실습문제]</font> 9-2. detect가 완료된 이미지를 확인해 보세요.\n","\n","\n"],"id":"7ow6CvdOOLcw"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6VHAuI2I-Rb"},"outputs":[],"source":["# 필요 라이브러리 불러오기\n","from PIL import Image               # to load images\n","from IPython.display import display # to display images"],"id":"c6VHAuI2I-Rb"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1KjIAOarGGv1uabgA0aSGuKGomxrYKitr"},"executionInfo":{"elapsed":46671,"status":"ok","timestamp":1666267864483,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"_eJlfDx0Bz9S","outputId":"323f8a86-8ed2-4cba-8e5e-c9770bfb7ae8"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# 실습해보세요.\n","detect_image_path = \"/content/yolov5/runs/detect/exp\"  #detect가 완료된 파일의 경로\n","\n","for i in glob.glob(detect_image_path + '/*.jpg'):\n","  img = Image.open(i)\n","  img_resize = img.resize((640, 360))\n","  display(img_resize)\n","  print('\\n')\n"],"id":"_eJlfDx0Bz9S"},{"cell_type":"markdown","metadata":{"id":"u8l3c5namfEs"},"source":["<font color=\"green\">[실습문제]</font> 10-1. 동영상을 소스로 한 객체 검출하기 \n","> 경로 \"TEST_VIDEO_PATH\" 의 이미지 파일들의 객체를 검출해 보세요.  \n","> [조건] \n","> ① IOU Threshold : 0.5, ② 모델 weights : best.pt "],"id":"u8l3c5namfEs"},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZ0EJ9cnmeKX"},"outputs":[],"source":["# 실습해보세요\n","!python detect.py --source '{TEST_VIDEO_PATH}' --weights /content/yolov5/runs/train/OID_helmet_data_detection/weights/best.pt --img 416 --conf 0.5"],"id":"pZ0EJ9cnmeKX"},{"cell_type":"markdown","metadata":{"id":"bXLmOotHpkjl"},"source":["<font color=\"green\">[실습문제]</font> 10-2. detect가 완료된 동영상을 확인해 보세요.\n","- 아래의 코드는 colab에서 비디오 파일을 실행하기 위해 video 파일을 압축하고 HTML video 속성으로 출력하는 코드입니다. \n","- detect_video(detect가 완료된 비디오 파일) 의 경로만 변경하시고 그대로 실행하시면 되겠습니다."],"id":"bXLmOotHpkjl"},{"cell_type":"code","execution_count":null,"metadata":{"id":"DTsF2qXVpkIq"},"outputs":[],"source":["# 실습해보세요.\n","detect_video = '/content/test_video_01.mp4' # 경로 수정\n","compressed_video = '' # 압축이 완료된 이후 저장되는 파일 경로 변수\n","\n","# 비디오 데이터 압축 (Colab에서 실행 목적)\n","def video_compressing(detect_video):  \n","  compressed_video = detect_video[:-4] + \"_compressed.mp4\"\n","  os.system(f\"ffmpeg -i {detect_video} -vcodec libx264 {compressed_video}\")\n","\n","  return compressed_video \n"],"id":"DTsF2qXVpkIq"},{"cell_type":"code","execution_count":null,"metadata":{"id":"LzzZg93a-Zjn"},"outputs":[],"source":["compressed_video = video_compressing(detect_video)\n","\n","from IPython.display import HTML\n","from base64 import b64encode\n","\n","mp4 = open(compressed_video,'rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width=400 controls>\n","    <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"],"id":"LzzZg93a-Zjn"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}