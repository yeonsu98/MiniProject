{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "b4b2ad36-a254-4323-8950-c64eaff55244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 학습/평가 데이터 로딩\n",
    "train_x = pd.read_csv(\"train_x.csv\")\n",
    "train_y = pd.read_csv(\"train_y.csv\")\n",
    "test_x = pd.read_csv(\"test_x.csv\")\n",
    "test_y = pd.read_csv(\"test_y.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "37e816f2-62ec-4b52-8580-ace48ce9a2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2m</th>\n",
       "      <th>2m_1d</th>\n",
       "      <th>2m_7d</th>\n",
       "      <th>3m</th>\n",
       "      <th>4m</th>\n",
       "      <th>5m</th>\n",
       "      <th>6m</th>\n",
       "      <th>1y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35342.1679</td>\n",
       "      <td>35571.0425</td>\n",
       "      <td>36284.5717</td>\n",
       "      <td>35214.2772</td>\n",
       "      <td>35365.2990</td>\n",
       "      <td>35479.2268</td>\n",
       "      <td>35707.2110</td>\n",
       "      <td>36173.9265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35733.4837</td>\n",
       "      <td>35798.3192</td>\n",
       "      <td>36509.1258</td>\n",
       "      <td>35467.7452</td>\n",
       "      <td>35451.5653</td>\n",
       "      <td>35973.2792</td>\n",
       "      <td>35979.8079</td>\n",
       "      <td>36749.8637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36098.9195</td>\n",
       "      <td>36138.7426</td>\n",
       "      <td>36212.5100</td>\n",
       "      <td>35393.9337</td>\n",
       "      <td>35936.0222</td>\n",
       "      <td>36601.5563</td>\n",
       "      <td>36400.6248</td>\n",
       "      <td>37188.8978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37140.7503</td>\n",
       "      <td>37034.5347</td>\n",
       "      <td>36861.9255</td>\n",
       "      <td>36347.6980</td>\n",
       "      <td>36281.0365</td>\n",
       "      <td>37404.0037</td>\n",
       "      <td>37553.3600</td>\n",
       "      <td>38709.5514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37047.2616</td>\n",
       "      <td>37171.8236</td>\n",
       "      <td>37000.5171</td>\n",
       "      <td>36812.7855</td>\n",
       "      <td>36452.7145</td>\n",
       "      <td>37705.7549</td>\n",
       "      <td>37832.7474</td>\n",
       "      <td>39119.4872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5859</th>\n",
       "      <td>35708.4819</td>\n",
       "      <td>36087.9937</td>\n",
       "      <td>35815.6482</td>\n",
       "      <td>35563.5385</td>\n",
       "      <td>36550.1959</td>\n",
       "      <td>36124.9666</td>\n",
       "      <td>36233.8503</td>\n",
       "      <td>36453.0970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5860</th>\n",
       "      <td>35924.7026</td>\n",
       "      <td>36339.3987</td>\n",
       "      <td>36009.3918</td>\n",
       "      <td>35699.0653</td>\n",
       "      <td>36875.3016</td>\n",
       "      <td>36259.2079</td>\n",
       "      <td>36489.2861</td>\n",
       "      <td>37038.1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5861</th>\n",
       "      <td>36597.7205</td>\n",
       "      <td>36527.5722</td>\n",
       "      <td>36339.1032</td>\n",
       "      <td>36035.3930</td>\n",
       "      <td>37537.6841</td>\n",
       "      <td>36985.6251</td>\n",
       "      <td>36939.7032</td>\n",
       "      <td>37596.2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5862</th>\n",
       "      <td>37163.4665</td>\n",
       "      <td>36940.6312</td>\n",
       "      <td>37097.1192</td>\n",
       "      <td>36564.0947</td>\n",
       "      <td>37773.6538</td>\n",
       "      <td>37525.4398</td>\n",
       "      <td>37687.9966</td>\n",
       "      <td>37581.0946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>39853.9949</td>\n",
       "      <td>40458.3040</td>\n",
       "      <td>40566.3709</td>\n",
       "      <td>39539.9719</td>\n",
       "      <td>40546.8265</td>\n",
       "      <td>40030.7485</td>\n",
       "      <td>40977.0472</td>\n",
       "      <td>40412.3882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5864 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              2m       2m_1d       2m_7d          3m          4m          5m  \\\n",
       "0     35342.1679  35571.0425  36284.5717  35214.2772  35365.2990  35479.2268   \n",
       "1     35733.4837  35798.3192  36509.1258  35467.7452  35451.5653  35973.2792   \n",
       "2     36098.9195  36138.7426  36212.5100  35393.9337  35936.0222  36601.5563   \n",
       "3     37140.7503  37034.5347  36861.9255  36347.6980  36281.0365  37404.0037   \n",
       "4     37047.2616  37171.8236  37000.5171  36812.7855  36452.7145  37705.7549   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "5859  35708.4819  36087.9937  35815.6482  35563.5385  36550.1959  36124.9666   \n",
       "5860  35924.7026  36339.3987  36009.3918  35699.0653  36875.3016  36259.2079   \n",
       "5861  36597.7205  36527.5722  36339.1032  36035.3930  37537.6841  36985.6251   \n",
       "5862  37163.4665  36940.6312  37097.1192  36564.0947  37773.6538  37525.4398   \n",
       "5863  39853.9949  40458.3040  40566.3709  39539.9719  40546.8265  40030.7485   \n",
       "\n",
       "              6m          1y  \n",
       "0     35707.2110  36173.9265  \n",
       "1     35979.8079  36749.8637  \n",
       "2     36400.6248  37188.8978  \n",
       "3     37553.3600  38709.5514  \n",
       "4     37832.7474  39119.4872  \n",
       "...          ...         ...  \n",
       "5859  36233.8503  36453.0970  \n",
       "5860  36489.2861  37038.1230  \n",
       "5861  36939.7032  37596.2976  \n",
       "5862  37687.9966  37581.0946  \n",
       "5863  40977.0472  40412.3882  \n",
       "\n",
       "[5864 rows x 8 columns]"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "4a550469-b325-4d47-9d7b-620e41569b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2m</th>\n",
       "      <th>2m_1d</th>\n",
       "      <th>2m_7d</th>\n",
       "      <th>3m</th>\n",
       "      <th>4m</th>\n",
       "      <th>5m</th>\n",
       "      <th>6m</th>\n",
       "      <th>1y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2m</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.881796</td>\n",
       "      <td>0.814272</td>\n",
       "      <td>0.679611</td>\n",
       "      <td>0.709086</td>\n",
       "      <td>0.757771</td>\n",
       "      <td>0.768552</td>\n",
       "      <td>0.802776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2m_1d</th>\n",
       "      <td>0.881796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772162</td>\n",
       "      <td>0.711579</td>\n",
       "      <td>0.718317</td>\n",
       "      <td>0.729241</td>\n",
       "      <td>0.809315</td>\n",
       "      <td>0.762775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2m_7d</th>\n",
       "      <td>0.814272</td>\n",
       "      <td>0.772162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704285</td>\n",
       "      <td>0.711776</td>\n",
       "      <td>0.755410</td>\n",
       "      <td>0.762674</td>\n",
       "      <td>0.812133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3m</th>\n",
       "      <td>0.679611</td>\n",
       "      <td>0.711579</td>\n",
       "      <td>0.704285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702232</td>\n",
       "      <td>0.683765</td>\n",
       "      <td>0.742673</td>\n",
       "      <td>0.726180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4m</th>\n",
       "      <td>0.709086</td>\n",
       "      <td>0.718317</td>\n",
       "      <td>0.711776</td>\n",
       "      <td>0.702232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745688</td>\n",
       "      <td>0.719815</td>\n",
       "      <td>0.747949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5m</th>\n",
       "      <td>0.757771</td>\n",
       "      <td>0.729241</td>\n",
       "      <td>0.755410</td>\n",
       "      <td>0.683765</td>\n",
       "      <td>0.745688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.755960</td>\n",
       "      <td>0.826602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6m</th>\n",
       "      <td>0.768552</td>\n",
       "      <td>0.809315</td>\n",
       "      <td>0.762674</td>\n",
       "      <td>0.742673</td>\n",
       "      <td>0.719815</td>\n",
       "      <td>0.755960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1y</th>\n",
       "      <td>0.802776</td>\n",
       "      <td>0.762775</td>\n",
       "      <td>0.812133</td>\n",
       "      <td>0.726180</td>\n",
       "      <td>0.747949</td>\n",
       "      <td>0.826602</td>\n",
       "      <td>0.855613</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             2m     2m_1d     2m_7d        3m        4m        5m        6m  \\\n",
       "2m     1.000000  0.881796  0.814272  0.679611  0.709086  0.757771  0.768552   \n",
       "2m_1d  0.881796  1.000000  0.772162  0.711579  0.718317  0.729241  0.809315   \n",
       "2m_7d  0.814272  0.772162  1.000000  0.704285  0.711776  0.755410  0.762674   \n",
       "3m     0.679611  0.711579  0.704285  1.000000  0.702232  0.683765  0.742673   \n",
       "4m     0.709086  0.718317  0.711776  0.702232  1.000000  0.745688  0.719815   \n",
       "5m     0.757771  0.729241  0.755410  0.683765  0.745688  1.000000  0.755960   \n",
       "6m     0.768552  0.809315  0.762674  0.742673  0.719815  0.755960  1.000000   \n",
       "1y     0.802776  0.762775  0.812133  0.726180  0.747949  0.826602  0.855613   \n",
       "\n",
       "             1y  \n",
       "2m     0.802776  \n",
       "2m_1d  0.762775  \n",
       "2m_7d  0.812133  \n",
       "3m     0.726180  \n",
       "4m     0.747949  \n",
       "5m     0.826602  \n",
       "6m     0.855613  \n",
       "1y     1.000000  "
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "db56b0e7-6cc4-4ca0-b27e-c79ccf60199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_result(true,pred):\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import r2_score\n",
    "    print('RMSE : %.5f' % mean_squared_error(true, pred)**0.5)\n",
    "    print('R2-Score : %.5f' % r2_score(true, pred))\n",
    "    return (round(mean_squared_error(true, pred)**0.5, 5), round(r2_score(true, pred), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "51cef6ac-3549-4433-8066-9e956709ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하세요.\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "4cbb1fc1-acdc-49d6-be66-7789c1caaf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-78 {color: black;background-color: white;}#sk-container-id-78 pre{padding: 0;}#sk-container-id-78 div.sk-toggleable {background-color: white;}#sk-container-id-78 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-78 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-78 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-78 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-78 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-78 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-78 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-78 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-78 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-78 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-78 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-78 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-78 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-78 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-78 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-78 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-78 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-78 div.sk-item {position: relative;z-index: 1;}#sk-container-id-78 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-78 div.sk-item::before, #sk-container-id-78 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-78 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-78 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-78 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-78 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-78 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-78 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-78 div.sk-label-container {text-align: center;}#sk-container-id-78 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-78 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-78\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(learning_rate=0.08, min_data_in_leaf=20, n_estimators=250)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" checked><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(learning_rate=0.08, min_data_in_leaf=20, n_estimators=250)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(learning_rate=0.08, min_data_in_leaf=20, n_estimators=250)"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아래에 실습코드를 작성하세요.\n",
    "lgbm = LGBMRegressor(n_estimators=250, learning_rate=0.08, min_data_in_leaf=20)\n",
    "lgbm.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "f78c247e-3ebb-4d3e-9d22-dc5fdf9b3e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1103.17873\n",
      "R2-Score : 0.64793\n"
     ]
    }
   ],
   "source": [
    "pred = lgbm.predict(test_x)\n",
    "lgbm_rmse, lgbm_r2 = pred_result(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "ce148584-2dea-479e-b590-84a09a582059",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lgbm.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "e90aa80b-ca1e-41f5-a998-9a03a29c9bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39818.07794503, 39572.16364885, 39524.94204977, ...,\n",
       "       36897.17506541, 37045.57069561, 39186.24338292])"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638427bb-5ac3-47b4-9321-33bc9f97827b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "2590ac53-8071-4e36-a6a1-c6100e8631db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1    12803584.0707           10.16s\n",
      "         2    11461556.5106            8.85s\n",
      "         3    10356324.9387            8.63s\n",
      "         4     9452010.0121            8.75s\n",
      "         5     8687754.2930            8.70s\n",
      "         6     8046481.2368            8.66s\n",
      "         7     7523895.5026            8.60s\n",
      "         8     7083104.7450            8.65s\n",
      "         9     6725521.2282            8.64s\n",
      "        10     6427964.6895            8.64s\n",
      "        11     6176203.9766            8.67s\n",
      "        12     5969865.0305            8.62s\n",
      "        13     5797674.4146            8.51s\n",
      "        14     5647804.9134            8.35s\n",
      "        15     5518602.7269            8.25s\n",
      "        16     5412286.4558            8.14s\n",
      "        17     5325879.9135            7.95s\n",
      "        18     5252737.7073            7.78s\n",
      "        19     5185750.5173            7.63s\n",
      "        20     5130016.6395            7.51s\n",
      "        21     5085264.1827            7.43s\n",
      "        22     5041925.3823            7.29s\n",
      "        23     5004396.8467            7.14s\n",
      "        24     4974524.4379            7.00s\n",
      "        25     4950752.9756            6.89s\n",
      "        26     4926520.4276            6.75s\n",
      "        27     4904324.4616            6.64s\n",
      "        28     4887307.3258            6.53s\n",
      "        29     4873518.8191            6.39s\n",
      "        30     4861881.1067            6.29s\n",
      "        31     4847730.9229            6.19s\n",
      "        32     4838227.8134            6.07s\n",
      "        33     4828805.0993            5.95s\n",
      "        34     4817586.1240            5.84s\n",
      "        35     4810210.7199            5.73s\n",
      "        36     4802819.5819            5.61s\n",
      "        37     4795546.2943            5.49s\n",
      "        38     4787664.0627            5.38s\n",
      "        39     4780157.8300            5.26s\n",
      "        40     4775179.0289            5.15s\n",
      "        41     4770519.1633            5.04s\n",
      "        42     4759697.6168            4.94s\n",
      "        43     4756680.7669            4.84s\n",
      "        44     4746016.9638            4.74s\n",
      "        45     4743629.1441            4.66s\n",
      "        46     4736451.9609            4.57s\n",
      "        47     4731479.6814            4.49s\n",
      "        48     4728455.4657            4.41s\n",
      "        49     4725236.4908            4.32s\n",
      "        50     4722601.2393            4.22s\n",
      "        51     4716533.1164            4.12s\n",
      "        52     4713847.8244            4.02s\n",
      "        53     4712715.8355            3.92s\n",
      "        54     4710905.7383            3.85s\n",
      "        55     4708270.8486            3.78s\n",
      "        56     4706318.9724            3.71s\n",
      "        57     4702766.0629            3.63s\n",
      "        58     4701449.5726            3.55s\n",
      "        59     4699689.3010            3.46s\n",
      "        60     4698212.7939            3.37s\n",
      "        61     4697372.5412            3.29s\n",
      "        62     4695738.7961            3.20s\n",
      "        63     4694385.1425            3.11s\n",
      "        64     4690154.4096            3.03s\n",
      "        65     4686326.1176            2.95s\n",
      "        66     4685344.0258            2.87s\n",
      "        67     4683946.5377            2.79s\n",
      "        68     4681881.0908            2.71s\n",
      "        69     4680216.8695            2.63s\n",
      "        70     4679196.0576            2.55s\n",
      "        71     4677675.3669            2.48s\n",
      "        72     4677057.6347            2.40s\n",
      "        73     4676080.0324            2.32s\n",
      "        74     4669659.1464            2.24s\n",
      "        75     4664146.6403            2.16s\n",
      "        76     4662285.1073            2.08s\n",
      "        77     4656962.1970            2.00s\n",
      "        78     4655474.8135            1.91s\n",
      "        79     4652579.9506            1.82s\n",
      "        80     4651104.4397            1.74s\n",
      "        81     4648334.2540            1.66s\n",
      "        82     4641515.0638            1.57s\n",
      "        83     4640099.1340            1.49s\n",
      "        84     4635588.9837            1.40s\n",
      "        85     4634865.7570            1.31s\n",
      "        86     4634126.2540            1.23s\n",
      "        87     4631828.9349            1.14s\n",
      "        88     4630104.2791            1.05s\n",
      "        89     4628833.9903            0.96s\n",
      "        90     4626735.5683            0.87s\n",
      "        91     4626189.2626            0.79s\n",
      "        92     4622425.2948            0.70s\n",
      "        93     4621632.5476            0.61s\n",
      "        94     4617884.2470            0.52s\n",
      "        95     4615976.0012            0.44s\n",
      "        96     4615591.9020            0.35s\n",
      "        97     4610313.6521            0.26s\n",
      "        98     4609193.4075            0.17s\n",
      "        99     4608713.1943            0.09s\n",
      "       100     4607633.8283            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-81 {color: black;background-color: white;}#sk-container-id-81 pre{padding: 0;}#sk-container-id-81 div.sk-toggleable {background-color: white;}#sk-container-id-81 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-81 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-81 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-81 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-81 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-81 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-81 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-81 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-81 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-81 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-81 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-81 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-81 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-81 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-81 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-81 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-81 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-81 div.sk-item {position: relative;z-index: 1;}#sk-container-id-81 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-81 div.sk-item::before, #sk-container-id-81 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-81 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-81 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-81 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-81 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-81 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-81 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-81 div.sk-label-container {text-align: center;}#sk-container-id-81 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-81 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-81\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" checked><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(verbose=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(verbose=2)"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아래에 실습코드를 작성하세요.\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor(verbose=2)\n",
    "gbr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "eab63cd8-7b50-4500-8d46-bd86535d5081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1090.94316\n",
      "R2-Score : 0.65570\n"
     ]
    }
   ],
   "source": [
    "# 아래에 실습코드를 작성하세요.\n",
    "pred = gbr.predict(test_x)\n",
    "gbr_rmse, gbr_r2 = pred_result(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "4e485f6a-42ac-40ec-83f6-897eae766f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gbr.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a7ea1-cc34-47c1-a8b8-becf552f601b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6dcd18-c8ee-423e-b78e-08bd9f020341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "91dcdb4c-6f32-4fd5-becf-f80bb635f886",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   25.7s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-80 {color: black;background-color: white;}#sk-container-id-80 pre{padding: 0;}#sk-container-id-80 div.sk-toggleable {background-color: white;}#sk-container-id-80 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-80 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-80 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-80 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-80 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-80 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-80 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-80 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-80 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-80 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-80 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-80 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-80 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-80 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-80 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-80 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-80 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-80 div.sk-item {position: relative;z-index: 1;}#sk-container-id-80 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-80 div.sk-item::before, #sk-container-id-80 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-80 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-80 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-80 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-80 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-80 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-80 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-80 div.sk-label-container {text-align: center;}#sk-container-id-80 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-80 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-80\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" checked><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(verbose=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(verbose=2)"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아래에 실습코드를 작성하세요.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import tqdm\n",
    "\n",
    "rf = RandomForestRegressor(verbose=2)\n",
    "rf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "cc726641-63e3-49c6-befc-d08a6a0e66ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1210.48582\n",
      "R2-Score : 0.57611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "pred = rf.predict(test_x)\n",
    "rf_rmse, rf_r2 = pred_result(test_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d2d49ac-4646-4151-9b47-d389a5d8ee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "pred = rf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665edc72-988b-435b-aad7-2676bea0b7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "e9fa2ef5-2dd5-456a-a7de-ddf8984bf113",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.071118\n",
      "0:\tlearn: 3638.1135643\ttotal: 8.61ms\tremaining: 8.6s\n",
      "1:\tlearn: 3490.0635164\ttotal: 15.9ms\tremaining: 7.92s\n",
      "2:\tlearn: 3356.0020464\ttotal: 22.2ms\tremaining: 7.39s\n",
      "3:\tlearn: 3235.8233744\ttotal: 31.8ms\tremaining: 7.92s\n",
      "4:\tlearn: 3126.2833358\ttotal: 38.2ms\tremaining: 7.61s\n",
      "5:\tlearn: 3028.2734468\ttotal: 45.7ms\tremaining: 7.58s\n",
      "6:\tlearn: 2940.6951552\ttotal: 52.7ms\tremaining: 7.48s\n",
      "7:\tlearn: 2860.2084465\ttotal: 60.4ms\tremaining: 7.48s\n",
      "8:\tlearn: 2788.2122260\ttotal: 73ms\tremaining: 8.04s\n",
      "9:\tlearn: 2725.5637820\ttotal: 86.8ms\tremaining: 8.6s\n",
      "10:\tlearn: 2669.2053816\ttotal: 94.8ms\tremaining: 8.52s\n",
      "11:\tlearn: 2617.7436031\ttotal: 101ms\tremaining: 8.33s\n",
      "12:\tlearn: 2570.8398361\ttotal: 107ms\tremaining: 8.15s\n",
      "13:\tlearn: 2529.6536748\ttotal: 112ms\tremaining: 7.92s\n",
      "14:\tlearn: 2491.7874626\ttotal: 119ms\tremaining: 7.79s\n",
      "15:\tlearn: 2459.8371367\ttotal: 125ms\tremaining: 7.72s\n",
      "16:\tlearn: 2432.4017400\ttotal: 130ms\tremaining: 7.54s\n",
      "17:\tlearn: 2406.0579751\ttotal: 135ms\tremaining: 7.39s\n",
      "18:\tlearn: 2383.1582237\ttotal: 143ms\tremaining: 7.36s\n",
      "19:\tlearn: 2363.0098211\ttotal: 149ms\tremaining: 7.32s\n",
      "20:\tlearn: 2344.9898807\ttotal: 158ms\tremaining: 7.38s\n",
      "21:\tlearn: 2328.4463905\ttotal: 165ms\tremaining: 7.33s\n",
      "22:\tlearn: 2314.2226206\ttotal: 173ms\tremaining: 7.35s\n",
      "23:\tlearn: 2301.5241598\ttotal: 180ms\tremaining: 7.31s\n",
      "24:\tlearn: 2290.1090665\ttotal: 197ms\tremaining: 7.69s\n",
      "25:\tlearn: 2279.8029753\ttotal: 211ms\tremaining: 7.89s\n",
      "26:\tlearn: 2270.9659458\ttotal: 217ms\tremaining: 7.81s\n",
      "27:\tlearn: 2262.4362825\ttotal: 228ms\tremaining: 7.91s\n",
      "28:\tlearn: 2255.3873637\ttotal: 236ms\tremaining: 7.91s\n",
      "29:\tlearn: 2249.0977239\ttotal: 242ms\tremaining: 7.83s\n",
      "30:\tlearn: 2243.5454538\ttotal: 248ms\tremaining: 7.75s\n",
      "31:\tlearn: 2237.6572777\ttotal: 255ms\tremaining: 7.71s\n",
      "32:\tlearn: 2232.9517025\ttotal: 270ms\tremaining: 7.91s\n",
      "33:\tlearn: 2228.5156247\ttotal: 277ms\tremaining: 7.86s\n",
      "34:\tlearn: 2224.4259663\ttotal: 286ms\tremaining: 7.88s\n",
      "35:\tlearn: 2220.7706848\ttotal: 291ms\tremaining: 7.8s\n",
      "36:\tlearn: 2217.4436723\ttotal: 299ms\tremaining: 7.78s\n",
      "37:\tlearn: 2213.7631143\ttotal: 305ms\tremaining: 7.72s\n",
      "38:\tlearn: 2210.3151187\ttotal: 312ms\tremaining: 7.69s\n",
      "39:\tlearn: 2207.6885610\ttotal: 320ms\tremaining: 7.69s\n",
      "40:\tlearn: 2205.7828249\ttotal: 330ms\tremaining: 7.72s\n",
      "41:\tlearn: 2203.2432484\ttotal: 339ms\tremaining: 7.72s\n",
      "42:\tlearn: 2201.1441539\ttotal: 345ms\tremaining: 7.68s\n",
      "43:\tlearn: 2199.2715460\ttotal: 355ms\tremaining: 7.71s\n",
      "44:\tlearn: 2197.5875373\ttotal: 362ms\tremaining: 7.68s\n",
      "45:\tlearn: 2196.0787812\ttotal: 383ms\tremaining: 7.95s\n",
      "46:\tlearn: 2194.3278340\ttotal: 391ms\tremaining: 7.93s\n",
      "47:\tlearn: 2192.8072444\ttotal: 402ms\tremaining: 7.98s\n",
      "48:\tlearn: 2191.2449413\ttotal: 412ms\tremaining: 8s\n",
      "49:\tlearn: 2190.0816644\ttotal: 418ms\tremaining: 7.94s\n",
      "50:\tlearn: 2188.5419298\ttotal: 424ms\tremaining: 7.89s\n",
      "51:\tlearn: 2186.3657031\ttotal: 433ms\tremaining: 7.89s\n",
      "52:\tlearn: 2184.6483565\ttotal: 438ms\tremaining: 7.83s\n",
      "53:\tlearn: 2183.4203463\ttotal: 445ms\tremaining: 7.8s\n",
      "54:\tlearn: 2181.9023165\ttotal: 453ms\tremaining: 7.79s\n",
      "55:\tlearn: 2180.7383848\ttotal: 473ms\tremaining: 7.97s\n",
      "56:\tlearn: 2179.6813236\ttotal: 485ms\tremaining: 8.03s\n",
      "57:\tlearn: 2178.6745060\ttotal: 495ms\tremaining: 8.03s\n",
      "58:\tlearn: 2177.8107010\ttotal: 501ms\tremaining: 7.99s\n",
      "59:\tlearn: 2176.8663269\ttotal: 511ms\tremaining: 8s\n",
      "60:\tlearn: 2176.1629603\ttotal: 517ms\tremaining: 7.96s\n",
      "61:\tlearn: 2175.4030075\ttotal: 525ms\tremaining: 7.94s\n",
      "62:\tlearn: 2174.3509065\ttotal: 533ms\tremaining: 7.93s\n",
      "63:\tlearn: 2172.6678149\ttotal: 541ms\tremaining: 7.92s\n",
      "64:\tlearn: 2171.9964910\ttotal: 563ms\tremaining: 8.1s\n",
      "65:\tlearn: 2170.7260468\ttotal: 570ms\tremaining: 8.06s\n",
      "66:\tlearn: 2169.8447808\ttotal: 576ms\tremaining: 8.02s\n",
      "67:\tlearn: 2168.9245763\ttotal: 581ms\tremaining: 7.97s\n",
      "68:\tlearn: 2167.5435399\ttotal: 587ms\tremaining: 7.91s\n",
      "69:\tlearn: 2166.9271821\ttotal: 592ms\tremaining: 7.87s\n",
      "70:\tlearn: 2166.4052417\ttotal: 597ms\tremaining: 7.81s\n",
      "71:\tlearn: 2165.3381976\ttotal: 602ms\tremaining: 7.76s\n",
      "72:\tlearn: 2164.6436141\ttotal: 610ms\tremaining: 7.75s\n",
      "73:\tlearn: 2164.1762527\ttotal: 616ms\tremaining: 7.71s\n",
      "74:\tlearn: 2163.4099854\ttotal: 625ms\tremaining: 7.71s\n",
      "75:\tlearn: 2162.4760366\ttotal: 630ms\tremaining: 7.65s\n",
      "76:\tlearn: 2161.6233888\ttotal: 636ms\tremaining: 7.62s\n",
      "77:\tlearn: 2161.0177637\ttotal: 644ms\tremaining: 7.61s\n",
      "78:\tlearn: 2160.6253060\ttotal: 650ms\tremaining: 7.57s\n",
      "79:\tlearn: 2159.4758286\ttotal: 667ms\tremaining: 7.67s\n",
      "80:\tlearn: 2158.9700625\ttotal: 675ms\tremaining: 7.66s\n",
      "81:\tlearn: 2158.5410661\ttotal: 681ms\tremaining: 7.62s\n",
      "82:\tlearn: 2158.1486824\ttotal: 688ms\tremaining: 7.6s\n",
      "83:\tlearn: 2157.1686273\ttotal: 694ms\tremaining: 7.57s\n",
      "84:\tlearn: 2156.6895060\ttotal: 704ms\tremaining: 7.58s\n",
      "85:\tlearn: 2156.0875000\ttotal: 710ms\tremaining: 7.55s\n",
      "86:\tlearn: 2155.6772580\ttotal: 721ms\tremaining: 7.56s\n",
      "87:\tlearn: 2155.2499731\ttotal: 726ms\tremaining: 7.53s\n",
      "88:\tlearn: 2154.6885313\ttotal: 734ms\tremaining: 7.51s\n",
      "89:\tlearn: 2153.7348786\ttotal: 752ms\tremaining: 7.61s\n",
      "90:\tlearn: 2152.7810587\ttotal: 760ms\tremaining: 7.59s\n",
      "91:\tlearn: 2152.0054441\ttotal: 769ms\tremaining: 7.59s\n",
      "92:\tlearn: 2151.4361309\ttotal: 775ms\tremaining: 7.56s\n",
      "93:\tlearn: 2150.9455586\ttotal: 782ms\tremaining: 7.54s\n",
      "94:\tlearn: 2150.3966343\ttotal: 789ms\tremaining: 7.51s\n",
      "95:\tlearn: 2150.0444582\ttotal: 795ms\tremaining: 7.49s\n",
      "96:\tlearn: 2149.4185206\ttotal: 800ms\tremaining: 7.45s\n",
      "97:\tlearn: 2149.0411550\ttotal: 805ms\tremaining: 7.41s\n",
      "98:\tlearn: 2148.4795391\ttotal: 811ms\tremaining: 7.38s\n",
      "99:\tlearn: 2148.1761083\ttotal: 817ms\tremaining: 7.35s\n",
      "100:\tlearn: 2147.5013714\ttotal: 822ms\tremaining: 7.31s\n",
      "101:\tlearn: 2147.0880288\ttotal: 828ms\tremaining: 7.29s\n",
      "102:\tlearn: 2146.5360981\ttotal: 834ms\tremaining: 7.26s\n",
      "103:\tlearn: 2146.0087950\ttotal: 840ms\tremaining: 7.23s\n",
      "104:\tlearn: 2145.3039630\ttotal: 861ms\tremaining: 7.34s\n",
      "105:\tlearn: 2144.9154879\ttotal: 871ms\tremaining: 7.35s\n",
      "106:\tlearn: 2143.9848532\ttotal: 879ms\tremaining: 7.33s\n",
      "107:\tlearn: 2143.6507992\ttotal: 885ms\tremaining: 7.31s\n",
      "108:\tlearn: 2143.4180459\ttotal: 895ms\tremaining: 7.32s\n",
      "109:\tlearn: 2142.2933367\ttotal: 901ms\tremaining: 7.29s\n",
      "110:\tlearn: 2141.7821196\ttotal: 910ms\tremaining: 7.29s\n",
      "111:\tlearn: 2140.8493124\ttotal: 915ms\tremaining: 7.25s\n",
      "112:\tlearn: 2140.5747990\ttotal: 922ms\tremaining: 7.23s\n",
      "113:\tlearn: 2140.1949587\ttotal: 928ms\tremaining: 7.21s\n",
      "114:\tlearn: 2139.6695046\ttotal: 943ms\tremaining: 7.26s\n",
      "115:\tlearn: 2139.0695069\ttotal: 949ms\tremaining: 7.23s\n",
      "116:\tlearn: 2138.7044814\ttotal: 957ms\tremaining: 7.22s\n",
      "117:\tlearn: 2138.2418620\ttotal: 962ms\tremaining: 7.19s\n",
      "118:\tlearn: 2137.9630531\ttotal: 966ms\tremaining: 7.15s\n",
      "119:\tlearn: 2137.6461178\ttotal: 972ms\tremaining: 7.13s\n",
      "120:\tlearn: 2137.3179305\ttotal: 977ms\tremaining: 7.1s\n",
      "121:\tlearn: 2136.5568437\ttotal: 983ms\tremaining: 7.08s\n",
      "122:\tlearn: 2136.1719021\ttotal: 994ms\tremaining: 7.08s\n",
      "123:\tlearn: 2135.7563289\ttotal: 999ms\tremaining: 7.06s\n",
      "124:\tlearn: 2135.5149532\ttotal: 1.01s\tremaining: 7.06s\n",
      "125:\tlearn: 2135.1489371\ttotal: 1.01s\tremaining: 7.04s\n",
      "126:\tlearn: 2134.6330027\ttotal: 1.02s\tremaining: 7.03s\n",
      "127:\tlearn: 2133.9243831\ttotal: 1.03s\tremaining: 7.02s\n",
      "128:\tlearn: 2133.3295083\ttotal: 1.04s\tremaining: 7.04s\n",
      "129:\tlearn: 2132.7885307\ttotal: 1.06s\tremaining: 7.1s\n",
      "130:\tlearn: 2132.5263652\ttotal: 1.07s\tremaining: 7.08s\n",
      "131:\tlearn: 2132.2104195\ttotal: 1.07s\tremaining: 7.05s\n",
      "132:\tlearn: 2131.8266372\ttotal: 1.08s\tremaining: 7.04s\n",
      "133:\tlearn: 2131.5539229\ttotal: 1.09s\tremaining: 7.03s\n",
      "134:\tlearn: 2130.7009976\ttotal: 1.09s\tremaining: 7.01s\n",
      "135:\tlearn: 2130.3821853\ttotal: 1.1s\tremaining: 7s\n",
      "136:\tlearn: 2130.1365483\ttotal: 1.11s\tremaining: 6.97s\n",
      "137:\tlearn: 2129.5892188\ttotal: 1.11s\tremaining: 6.94s\n",
      "138:\tlearn: 2129.1113440\ttotal: 1.12s\tremaining: 6.93s\n",
      "139:\tlearn: 2128.8220372\ttotal: 1.13s\tremaining: 6.96s\n",
      "140:\tlearn: 2128.3819479\ttotal: 1.14s\tremaining: 6.95s\n",
      "141:\tlearn: 2127.5558617\ttotal: 1.15s\tremaining: 6.94s\n",
      "142:\tlearn: 2126.8740126\ttotal: 1.15s\tremaining: 6.92s\n",
      "143:\tlearn: 2126.2066348\ttotal: 1.16s\tremaining: 6.9s\n",
      "144:\tlearn: 2125.7061931\ttotal: 1.17s\tremaining: 6.88s\n",
      "145:\tlearn: 2125.4228212\ttotal: 1.17s\tremaining: 6.86s\n",
      "146:\tlearn: 2125.1269195\ttotal: 1.18s\tremaining: 6.85s\n",
      "147:\tlearn: 2124.5750935\ttotal: 1.19s\tremaining: 6.83s\n",
      "148:\tlearn: 2124.0088104\ttotal: 1.19s\tremaining: 6.8s\n",
      "149:\tlearn: 2123.4367115\ttotal: 1.2s\tremaining: 6.79s\n",
      "150:\tlearn: 2123.1847772\ttotal: 1.2s\tremaining: 6.77s\n",
      "151:\tlearn: 2122.9155031\ttotal: 1.21s\tremaining: 6.75s\n",
      "152:\tlearn: 2122.1393658\ttotal: 1.22s\tremaining: 6.74s\n",
      "153:\tlearn: 2121.9190264\ttotal: 1.22s\tremaining: 6.72s\n",
      "154:\tlearn: 2121.6891220\ttotal: 1.24s\tremaining: 6.76s\n",
      "155:\tlearn: 2120.9360220\ttotal: 1.25s\tremaining: 6.78s\n",
      "156:\tlearn: 2120.5235556\ttotal: 1.26s\tremaining: 6.77s\n",
      "157:\tlearn: 2119.8719594\ttotal: 1.27s\tremaining: 6.75s\n",
      "158:\tlearn: 2119.3368886\ttotal: 1.27s\tremaining: 6.75s\n",
      "159:\tlearn: 2118.8502738\ttotal: 1.28s\tremaining: 6.73s\n",
      "160:\tlearn: 2117.9618404\ttotal: 1.29s\tremaining: 6.71s\n",
      "161:\tlearn: 2117.7746134\ttotal: 1.3s\tremaining: 6.71s\n",
      "162:\tlearn: 2117.1078926\ttotal: 1.3s\tremaining: 6.69s\n",
      "163:\tlearn: 2116.2187716\ttotal: 1.31s\tremaining: 6.68s\n",
      "164:\tlearn: 2115.4700379\ttotal: 1.32s\tremaining: 6.71s\n",
      "165:\tlearn: 2115.1140483\ttotal: 1.33s\tremaining: 6.69s\n",
      "166:\tlearn: 2114.7836305\ttotal: 1.34s\tremaining: 6.67s\n",
      "167:\tlearn: 2114.3791933\ttotal: 1.34s\tremaining: 6.66s\n",
      "168:\tlearn: 2114.0129846\ttotal: 1.35s\tremaining: 6.64s\n",
      "169:\tlearn: 2113.6743841\ttotal: 1.36s\tremaining: 6.63s\n",
      "170:\tlearn: 2112.9400960\ttotal: 1.36s\tremaining: 6.61s\n",
      "171:\tlearn: 2112.7135673\ttotal: 1.37s\tremaining: 6.61s\n",
      "172:\tlearn: 2112.1143097\ttotal: 1.38s\tremaining: 6.59s\n",
      "173:\tlearn: 2111.6315511\ttotal: 1.39s\tremaining: 6.58s\n",
      "174:\tlearn: 2111.2718120\ttotal: 1.39s\tremaining: 6.56s\n",
      "175:\tlearn: 2110.5548859\ttotal: 1.4s\tremaining: 6.54s\n",
      "176:\tlearn: 2109.6639352\ttotal: 1.4s\tremaining: 6.53s\n",
      "177:\tlearn: 2109.3373722\ttotal: 1.41s\tremaining: 6.52s\n",
      "178:\tlearn: 2109.1676861\ttotal: 1.42s\tremaining: 6.53s\n",
      "179:\tlearn: 2108.7212040\ttotal: 1.44s\tremaining: 6.56s\n",
      "180:\tlearn: 2108.2129541\ttotal: 1.45s\tremaining: 6.57s\n",
      "181:\tlearn: 2107.9449617\ttotal: 1.46s\tremaining: 6.55s\n",
      "182:\tlearn: 2107.6591333\ttotal: 1.47s\tremaining: 6.56s\n",
      "183:\tlearn: 2107.2415664\ttotal: 1.48s\tremaining: 6.55s\n",
      "184:\tlearn: 2106.7307940\ttotal: 1.49s\tremaining: 6.55s\n",
      "185:\tlearn: 2106.3048290\ttotal: 1.49s\tremaining: 6.54s\n",
      "186:\tlearn: 2106.0351503\ttotal: 1.51s\tremaining: 6.57s\n",
      "187:\tlearn: 2105.5348410\ttotal: 1.53s\tremaining: 6.59s\n",
      "188:\tlearn: 2104.8253559\ttotal: 1.53s\tremaining: 6.59s\n",
      "189:\tlearn: 2104.4754865\ttotal: 1.54s\tremaining: 6.57s\n",
      "190:\tlearn: 2103.9313359\ttotal: 1.55s\tremaining: 6.56s\n",
      "191:\tlearn: 2103.5594078\ttotal: 1.55s\tremaining: 6.54s\n",
      "192:\tlearn: 2103.0343797\ttotal: 1.56s\tremaining: 6.52s\n",
      "193:\tlearn: 2102.7158522\ttotal: 1.57s\tremaining: 6.51s\n",
      "194:\tlearn: 2102.3258000\ttotal: 1.57s\tremaining: 6.49s\n",
      "195:\tlearn: 2102.1291885\ttotal: 1.58s\tremaining: 6.47s\n",
      "196:\tlearn: 2101.6631322\ttotal: 1.58s\tremaining: 6.46s\n",
      "197:\tlearn: 2101.4673050\ttotal: 1.59s\tremaining: 6.44s\n",
      "198:\tlearn: 2101.0696143\ttotal: 1.6s\tremaining: 6.43s\n",
      "199:\tlearn: 2100.6702241\ttotal: 1.62s\tremaining: 6.48s\n",
      "200:\tlearn: 2100.1767581\ttotal: 1.63s\tremaining: 6.48s\n",
      "201:\tlearn: 2099.6250212\ttotal: 1.64s\tremaining: 6.46s\n",
      "202:\tlearn: 2099.2801455\ttotal: 1.64s\tremaining: 6.45s\n",
      "203:\tlearn: 2099.0798224\ttotal: 1.65s\tremaining: 6.43s\n",
      "204:\tlearn: 2098.6253814\ttotal: 1.66s\tremaining: 6.42s\n",
      "205:\tlearn: 2098.3713605\ttotal: 1.66s\tremaining: 6.41s\n",
      "206:\tlearn: 2098.0814506\ttotal: 1.67s\tremaining: 6.39s\n",
      "207:\tlearn: 2097.7275524\ttotal: 1.67s\tremaining: 6.38s\n",
      "208:\tlearn: 2097.1019759\ttotal: 1.68s\tremaining: 6.36s\n",
      "209:\tlearn: 2096.7264046\ttotal: 1.69s\tremaining: 6.34s\n",
      "210:\tlearn: 2096.0176864\ttotal: 1.69s\tremaining: 6.34s\n",
      "211:\tlearn: 2095.4628055\ttotal: 1.7s\tremaining: 6.32s\n",
      "212:\tlearn: 2095.2991565\ttotal: 1.72s\tremaining: 6.35s\n",
      "213:\tlearn: 2094.8471323\ttotal: 1.73s\tremaining: 6.36s\n",
      "214:\tlearn: 2094.4407139\ttotal: 1.74s\tremaining: 6.34s\n",
      "215:\tlearn: 2094.2693653\ttotal: 1.74s\tremaining: 6.33s\n",
      "216:\tlearn: 2093.8530021\ttotal: 1.75s\tremaining: 6.31s\n",
      "217:\tlearn: 2093.6498207\ttotal: 1.76s\tremaining: 6.31s\n",
      "218:\tlearn: 2093.4305479\ttotal: 1.76s\tremaining: 6.29s\n",
      "219:\tlearn: 2093.1310537\ttotal: 1.77s\tremaining: 6.29s\n",
      "220:\tlearn: 2092.7871321\ttotal: 1.78s\tremaining: 6.27s\n",
      "221:\tlearn: 2092.5641357\ttotal: 1.79s\tremaining: 6.26s\n",
      "222:\tlearn: 2092.1655537\ttotal: 1.79s\tremaining: 6.25s\n",
      "223:\tlearn: 2091.8024005\ttotal: 1.8s\tremaining: 6.25s\n",
      "224:\tlearn: 2091.4564804\ttotal: 1.82s\tremaining: 6.28s\n",
      "225:\tlearn: 2091.1046864\ttotal: 1.83s\tremaining: 6.26s\n",
      "226:\tlearn: 2090.6148545\ttotal: 1.84s\tremaining: 6.25s\n",
      "227:\tlearn: 2090.1345568\ttotal: 1.84s\tremaining: 6.24s\n",
      "228:\tlearn: 2089.8493319\ttotal: 1.85s\tremaining: 6.22s\n",
      "229:\tlearn: 2089.4044118\ttotal: 1.85s\tremaining: 6.2s\n",
      "230:\tlearn: 2088.4574376\ttotal: 1.86s\tremaining: 6.19s\n",
      "231:\tlearn: 2088.1740363\ttotal: 1.87s\tremaining: 6.18s\n",
      "232:\tlearn: 2087.9536824\ttotal: 1.87s\tremaining: 6.16s\n",
      "233:\tlearn: 2087.5750128\ttotal: 1.88s\tremaining: 6.15s\n",
      "234:\tlearn: 2087.2842199\ttotal: 1.89s\tremaining: 6.14s\n",
      "235:\tlearn: 2087.0202408\ttotal: 1.89s\tremaining: 6.13s\n",
      "236:\tlearn: 2086.7069963\ttotal: 1.91s\tremaining: 6.16s\n",
      "237:\tlearn: 2086.2546327\ttotal: 1.92s\tremaining: 6.15s\n",
      "238:\tlearn: 2085.9183098\ttotal: 1.93s\tremaining: 6.14s\n",
      "239:\tlearn: 2085.7046548\ttotal: 1.93s\tremaining: 6.13s\n",
      "240:\tlearn: 2085.3238669\ttotal: 1.94s\tremaining: 6.11s\n",
      "241:\tlearn: 2084.8641673\ttotal: 1.95s\tremaining: 6.1s\n",
      "242:\tlearn: 2084.6885471\ttotal: 1.95s\tremaining: 6.08s\n",
      "243:\tlearn: 2084.3653317\ttotal: 1.96s\tremaining: 6.08s\n",
      "244:\tlearn: 2083.7530282\ttotal: 1.97s\tremaining: 6.07s\n",
      "245:\tlearn: 2083.5323539\ttotal: 1.98s\tremaining: 6.06s\n",
      "246:\tlearn: 2082.8345045\ttotal: 1.99s\tremaining: 6.07s\n",
      "247:\tlearn: 2082.4359129\ttotal: 2s\tremaining: 6.07s\n",
      "248:\tlearn: 2082.3151034\ttotal: 2.01s\tremaining: 6.06s\n",
      "249:\tlearn: 2081.9109493\ttotal: 2.02s\tremaining: 6.05s\n",
      "250:\tlearn: 2081.6330759\ttotal: 2.03s\tremaining: 6.05s\n",
      "251:\tlearn: 2081.4507148\ttotal: 2.03s\tremaining: 6.04s\n",
      "252:\tlearn: 2081.0780150\ttotal: 2.04s\tremaining: 6.02s\n",
      "253:\tlearn: 2080.6818621\ttotal: 2.04s\tremaining: 6.01s\n",
      "254:\tlearn: 2080.1948030\ttotal: 2.05s\tremaining: 5.99s\n",
      "255:\tlearn: 2079.9486710\ttotal: 2.06s\tremaining: 5.99s\n",
      "256:\tlearn: 2079.4326096\ttotal: 2.06s\tremaining: 5.97s\n",
      "257:\tlearn: 2079.2441817\ttotal: 2.07s\tremaining: 5.96s\n",
      "258:\tlearn: 2078.8991983\ttotal: 2.08s\tremaining: 5.95s\n",
      "259:\tlearn: 2078.6819265\ttotal: 2.1s\tremaining: 5.97s\n",
      "260:\tlearn: 2078.3491957\ttotal: 2.1s\tremaining: 5.96s\n",
      "261:\tlearn: 2077.9700643\ttotal: 2.11s\tremaining: 5.95s\n",
      "262:\tlearn: 2077.6579065\ttotal: 2.12s\tremaining: 5.94s\n",
      "263:\tlearn: 2077.2982786\ttotal: 2.13s\tremaining: 5.93s\n",
      "264:\tlearn: 2077.1587187\ttotal: 2.13s\tremaining: 5.92s\n",
      "265:\tlearn: 2076.7107970\ttotal: 2.14s\tremaining: 5.9s\n",
      "266:\tlearn: 2076.4825978\ttotal: 2.15s\tremaining: 5.89s\n",
      "267:\tlearn: 2076.0858513\ttotal: 2.15s\tremaining: 5.88s\n",
      "268:\tlearn: 2075.7933094\ttotal: 2.16s\tremaining: 5.87s\n",
      "269:\tlearn: 2075.3261181\ttotal: 2.17s\tremaining: 5.85s\n",
      "270:\tlearn: 2074.8682541\ttotal: 2.17s\tremaining: 5.84s\n",
      "271:\tlearn: 2074.6241713\ttotal: 2.19s\tremaining: 5.86s\n",
      "272:\tlearn: 2074.3955467\ttotal: 2.2s\tremaining: 5.86s\n",
      "273:\tlearn: 2074.2462260\ttotal: 2.21s\tremaining: 5.85s\n",
      "274:\tlearn: 2073.9937694\ttotal: 2.21s\tremaining: 5.84s\n",
      "275:\tlearn: 2073.7549059\ttotal: 2.22s\tremaining: 5.83s\n",
      "276:\tlearn: 2073.4396415\ttotal: 2.23s\tremaining: 5.82s\n",
      "277:\tlearn: 2073.0291402\ttotal: 2.24s\tremaining: 5.82s\n",
      "278:\tlearn: 2072.3652111\ttotal: 2.25s\tremaining: 5.81s\n",
      "279:\tlearn: 2072.0066221\ttotal: 2.31s\tremaining: 5.93s\n",
      "280:\tlearn: 2071.7409117\ttotal: 2.31s\tremaining: 5.92s\n",
      "281:\tlearn: 2071.4344223\ttotal: 2.33s\tremaining: 5.92s\n",
      "282:\tlearn: 2070.7566687\ttotal: 2.33s\tremaining: 5.91s\n",
      "283:\tlearn: 2070.3015229\ttotal: 2.34s\tremaining: 5.91s\n",
      "284:\tlearn: 2070.1110238\ttotal: 2.35s\tremaining: 5.9s\n",
      "285:\tlearn: 2069.8585319\ttotal: 2.36s\tremaining: 5.89s\n",
      "286:\tlearn: 2069.5926853\ttotal: 2.38s\tremaining: 5.92s\n",
      "287:\tlearn: 2069.3297153\ttotal: 2.4s\tremaining: 5.92s\n",
      "288:\tlearn: 2068.8825398\ttotal: 2.42s\tremaining: 5.94s\n",
      "289:\tlearn: 2068.3932669\ttotal: 2.42s\tremaining: 5.94s\n",
      "290:\tlearn: 2068.1825912\ttotal: 2.43s\tremaining: 5.93s\n",
      "291:\tlearn: 2067.7835492\ttotal: 2.45s\tremaining: 5.94s\n",
      "292:\tlearn: 2067.4962735\ttotal: 2.48s\tremaining: 5.98s\n",
      "293:\tlearn: 2067.1901370\ttotal: 2.49s\tremaining: 5.98s\n",
      "294:\tlearn: 2066.6226566\ttotal: 2.5s\tremaining: 5.99s\n",
      "295:\tlearn: 2066.2558069\ttotal: 2.52s\tremaining: 5.99s\n",
      "296:\tlearn: 2066.0870999\ttotal: 2.52s\tremaining: 5.97s\n",
      "297:\tlearn: 2065.5264896\ttotal: 2.53s\tremaining: 5.96s\n",
      "298:\tlearn: 2065.3591135\ttotal: 2.54s\tremaining: 5.94s\n",
      "299:\tlearn: 2064.7488690\ttotal: 2.54s\tremaining: 5.93s\n",
      "300:\tlearn: 2064.5096988\ttotal: 2.55s\tremaining: 5.91s\n",
      "301:\tlearn: 2064.0902564\ttotal: 2.55s\tremaining: 5.9s\n",
      "302:\tlearn: 2063.9004683\ttotal: 2.56s\tremaining: 5.88s\n",
      "303:\tlearn: 2063.5685567\ttotal: 2.58s\tremaining: 5.9s\n",
      "304:\tlearn: 2063.0864897\ttotal: 2.59s\tremaining: 5.89s\n",
      "305:\tlearn: 2062.7047363\ttotal: 2.59s\tremaining: 5.88s\n",
      "306:\tlearn: 2062.5074910\ttotal: 2.6s\tremaining: 5.86s\n",
      "307:\tlearn: 2062.3102785\ttotal: 2.6s\tremaining: 5.85s\n",
      "308:\tlearn: 2061.7585888\ttotal: 2.61s\tremaining: 5.84s\n",
      "309:\tlearn: 2061.3285105\ttotal: 2.62s\tremaining: 5.83s\n",
      "310:\tlearn: 2060.8858203\ttotal: 2.62s\tremaining: 5.81s\n",
      "311:\tlearn: 2060.5275888\ttotal: 2.63s\tremaining: 5.8s\n",
      "312:\tlearn: 2059.9598212\ttotal: 2.64s\tremaining: 5.79s\n",
      "313:\tlearn: 2059.6048882\ttotal: 2.64s\tremaining: 5.78s\n",
      "314:\tlearn: 2059.3473565\ttotal: 2.66s\tremaining: 5.78s\n",
      "315:\tlearn: 2059.1644550\ttotal: 2.66s\tremaining: 5.77s\n",
      "316:\tlearn: 2058.8320644\ttotal: 2.67s\tremaining: 5.75s\n",
      "317:\tlearn: 2058.2924363\ttotal: 2.68s\tremaining: 5.75s\n",
      "318:\tlearn: 2057.9629639\ttotal: 2.69s\tremaining: 5.73s\n",
      "319:\tlearn: 2057.7553078\ttotal: 2.69s\tremaining: 5.72s\n",
      "320:\tlearn: 2057.5578749\ttotal: 2.7s\tremaining: 5.71s\n",
      "321:\tlearn: 2057.2328262\ttotal: 2.71s\tremaining: 5.7s\n",
      "322:\tlearn: 2056.9904317\ttotal: 2.71s\tremaining: 5.69s\n",
      "323:\tlearn: 2056.6300436\ttotal: 2.72s\tremaining: 5.67s\n",
      "324:\tlearn: 2056.4126171\ttotal: 2.73s\tremaining: 5.66s\n",
      "325:\tlearn: 2055.8892857\ttotal: 2.73s\tremaining: 5.65s\n",
      "326:\tlearn: 2055.4050623\ttotal: 2.74s\tremaining: 5.64s\n",
      "327:\tlearn: 2055.1620591\ttotal: 2.75s\tremaining: 5.64s\n",
      "328:\tlearn: 2054.9890502\ttotal: 2.78s\tremaining: 5.66s\n",
      "329:\tlearn: 2054.7716141\ttotal: 2.79s\tremaining: 5.66s\n",
      "330:\tlearn: 2054.3840854\ttotal: 2.8s\tremaining: 5.66s\n",
      "331:\tlearn: 2054.2022691\ttotal: 2.81s\tremaining: 5.65s\n",
      "332:\tlearn: 2053.8937529\ttotal: 2.82s\tremaining: 5.64s\n",
      "333:\tlearn: 2053.6224829\ttotal: 2.83s\tremaining: 5.64s\n",
      "334:\tlearn: 2053.2835212\ttotal: 2.84s\tremaining: 5.63s\n",
      "335:\tlearn: 2052.7690586\ttotal: 2.86s\tremaining: 5.65s\n",
      "336:\tlearn: 2052.3135616\ttotal: 2.87s\tremaining: 5.64s\n",
      "337:\tlearn: 2052.2397700\ttotal: 2.87s\tremaining: 5.63s\n",
      "338:\tlearn: 2052.0479097\ttotal: 2.88s\tremaining: 5.62s\n",
      "339:\tlearn: 2051.9220730\ttotal: 2.89s\tremaining: 5.61s\n",
      "340:\tlearn: 2051.6683972\ttotal: 2.9s\tremaining: 5.61s\n",
      "341:\tlearn: 2051.4825070\ttotal: 2.91s\tremaining: 5.59s\n",
      "342:\tlearn: 2051.2969665\ttotal: 2.92s\tremaining: 5.59s\n",
      "343:\tlearn: 2051.0112607\ttotal: 2.93s\tremaining: 5.58s\n",
      "344:\tlearn: 2050.3049250\ttotal: 2.94s\tremaining: 5.58s\n",
      "345:\tlearn: 2050.0648575\ttotal: 2.95s\tremaining: 5.57s\n",
      "346:\tlearn: 2049.7373724\ttotal: 2.97s\tremaining: 5.59s\n",
      "347:\tlearn: 2049.5123272\ttotal: 2.98s\tremaining: 5.59s\n",
      "348:\tlearn: 2049.3425098\ttotal: 2.99s\tremaining: 5.58s\n",
      "349:\tlearn: 2049.0615971\ttotal: 3s\tremaining: 5.57s\n",
      "350:\tlearn: 2048.8554560\ttotal: 3.01s\tremaining: 5.56s\n",
      "351:\tlearn: 2048.5124107\ttotal: 3.01s\tremaining: 5.55s\n",
      "352:\tlearn: 2048.1801976\ttotal: 3.02s\tremaining: 5.54s\n",
      "353:\tlearn: 2047.7568349\ttotal: 3.03s\tremaining: 5.53s\n",
      "354:\tlearn: 2047.1925710\ttotal: 3.05s\tremaining: 5.54s\n",
      "355:\tlearn: 2046.9971263\ttotal: 3.06s\tremaining: 5.53s\n",
      "356:\tlearn: 2046.7482260\ttotal: 3.07s\tremaining: 5.53s\n",
      "357:\tlearn: 2046.6156114\ttotal: 3.08s\tremaining: 5.52s\n",
      "358:\tlearn: 2046.3892054\ttotal: 3.08s\tremaining: 5.51s\n",
      "359:\tlearn: 2045.9911196\ttotal: 3.1s\tremaining: 5.5s\n",
      "360:\tlearn: 2045.7989732\ttotal: 3.1s\tremaining: 5.49s\n",
      "361:\tlearn: 2045.3428619\ttotal: 3.11s\tremaining: 5.49s\n",
      "362:\tlearn: 2044.9830650\ttotal: 3.12s\tremaining: 5.47s\n",
      "363:\tlearn: 2044.4098650\ttotal: 3.13s\tremaining: 5.47s\n",
      "364:\tlearn: 2044.1892831\ttotal: 3.14s\tremaining: 5.46s\n",
      "365:\tlearn: 2043.7373109\ttotal: 3.16s\tremaining: 5.48s\n",
      "366:\tlearn: 2043.5996308\ttotal: 3.18s\tremaining: 5.48s\n",
      "367:\tlearn: 2043.5039483\ttotal: 3.18s\tremaining: 5.47s\n",
      "368:\tlearn: 2042.8749852\ttotal: 3.19s\tremaining: 5.46s\n",
      "369:\tlearn: 2042.6685508\ttotal: 3.21s\tremaining: 5.46s\n",
      "370:\tlearn: 2042.3881636\ttotal: 3.22s\tremaining: 5.46s\n",
      "371:\tlearn: 2042.1566422\ttotal: 3.23s\tremaining: 5.45s\n",
      "372:\tlearn: 2041.9272009\ttotal: 3.25s\tremaining: 5.46s\n",
      "373:\tlearn: 2041.7036471\ttotal: 3.25s\tremaining: 5.45s\n",
      "374:\tlearn: 2041.5330825\ttotal: 3.26s\tremaining: 5.44s\n",
      "375:\tlearn: 2041.3247621\ttotal: 3.27s\tremaining: 5.43s\n",
      "376:\tlearn: 2041.1365446\ttotal: 3.29s\tremaining: 5.43s\n",
      "377:\tlearn: 2040.9703187\ttotal: 3.29s\tremaining: 5.42s\n",
      "378:\tlearn: 2040.5723546\ttotal: 3.3s\tremaining: 5.41s\n",
      "379:\tlearn: 2040.1390375\ttotal: 3.31s\tremaining: 5.4s\n",
      "380:\tlearn: 2039.9686484\ttotal: 3.32s\tremaining: 5.39s\n",
      "381:\tlearn: 2039.7667135\ttotal: 3.33s\tremaining: 5.39s\n",
      "382:\tlearn: 2039.5554130\ttotal: 3.35s\tremaining: 5.4s\n",
      "383:\tlearn: 2039.1368278\ttotal: 3.37s\tremaining: 5.41s\n",
      "384:\tlearn: 2038.8008563\ttotal: 3.38s\tremaining: 5.4s\n",
      "385:\tlearn: 2038.3704071\ttotal: 3.39s\tremaining: 5.39s\n",
      "386:\tlearn: 2038.1837429\ttotal: 3.4s\tremaining: 5.39s\n",
      "387:\tlearn: 2038.0900773\ttotal: 3.42s\tremaining: 5.39s\n",
      "388:\tlearn: 2037.9393454\ttotal: 3.43s\tremaining: 5.39s\n",
      "389:\tlearn: 2037.7572967\ttotal: 3.44s\tremaining: 5.38s\n",
      "390:\tlearn: 2037.5115738\ttotal: 3.45s\tremaining: 5.37s\n",
      "391:\tlearn: 2037.1201370\ttotal: 3.46s\tremaining: 5.37s\n",
      "392:\tlearn: 2036.7017249\ttotal: 3.47s\tremaining: 5.36s\n",
      "393:\tlearn: 2036.5260878\ttotal: 3.48s\tremaining: 5.36s\n",
      "394:\tlearn: 2036.3403002\ttotal: 3.49s\tremaining: 5.35s\n",
      "395:\tlearn: 2036.0137951\ttotal: 3.5s\tremaining: 5.34s\n",
      "396:\tlearn: 2035.7401061\ttotal: 3.52s\tremaining: 5.34s\n",
      "397:\tlearn: 2035.3398820\ttotal: 3.53s\tremaining: 5.34s\n",
      "398:\tlearn: 2035.0854198\ttotal: 3.54s\tremaining: 5.33s\n",
      "399:\tlearn: 2034.9580831\ttotal: 3.55s\tremaining: 5.33s\n",
      "400:\tlearn: 2034.5538580\ttotal: 3.56s\tremaining: 5.32s\n",
      "401:\tlearn: 2034.3364948\ttotal: 3.58s\tremaining: 5.32s\n",
      "402:\tlearn: 2033.9465791\ttotal: 3.59s\tremaining: 5.32s\n",
      "403:\tlearn: 2033.6496653\ttotal: 3.6s\tremaining: 5.31s\n",
      "404:\tlearn: 2033.4864539\ttotal: 3.61s\tremaining: 5.3s\n",
      "405:\tlearn: 2033.1673029\ttotal: 3.63s\tremaining: 5.32s\n",
      "406:\tlearn: 2033.0317946\ttotal: 3.65s\tremaining: 5.31s\n",
      "407:\tlearn: 2032.6934824\ttotal: 3.66s\tremaining: 5.3s\n",
      "408:\tlearn: 2032.5579363\ttotal: 3.67s\tremaining: 5.3s\n",
      "409:\tlearn: 2032.3779452\ttotal: 3.68s\tremaining: 5.29s\n",
      "410:\tlearn: 2032.1388692\ttotal: 3.69s\tremaining: 5.29s\n",
      "411:\tlearn: 2031.8950828\ttotal: 3.7s\tremaining: 5.28s\n",
      "412:\tlearn: 2031.7065054\ttotal: 3.71s\tremaining: 5.28s\n",
      "413:\tlearn: 2031.3961151\ttotal: 3.73s\tremaining: 5.28s\n",
      "414:\tlearn: 2031.1943812\ttotal: 3.75s\tremaining: 5.28s\n",
      "415:\tlearn: 2030.8509128\ttotal: 3.75s\tremaining: 5.27s\n",
      "416:\tlearn: 2030.7240769\ttotal: 3.76s\tremaining: 5.26s\n",
      "417:\tlearn: 2030.5039297\ttotal: 3.77s\tremaining: 5.25s\n",
      "418:\tlearn: 2030.1396575\ttotal: 3.79s\tremaining: 5.25s\n",
      "419:\tlearn: 2029.9130636\ttotal: 3.79s\tremaining: 5.24s\n",
      "420:\tlearn: 2029.6635645\ttotal: 3.8s\tremaining: 5.23s\n",
      "421:\tlearn: 2029.4150322\ttotal: 3.81s\tremaining: 5.22s\n",
      "422:\tlearn: 2029.2377370\ttotal: 3.82s\tremaining: 5.21s\n",
      "423:\tlearn: 2028.9411460\ttotal: 3.83s\tremaining: 5.2s\n",
      "424:\tlearn: 2028.7265857\ttotal: 3.83s\tremaining: 5.19s\n",
      "425:\tlearn: 2028.5644281\ttotal: 3.84s\tremaining: 5.18s\n",
      "426:\tlearn: 2028.4063662\ttotal: 3.85s\tremaining: 5.17s\n",
      "427:\tlearn: 2027.9175502\ttotal: 3.86s\tremaining: 5.16s\n",
      "428:\tlearn: 2027.5229069\ttotal: 3.87s\tremaining: 5.15s\n",
      "429:\tlearn: 2027.0831596\ttotal: 3.88s\tremaining: 5.15s\n",
      "430:\tlearn: 2026.8982130\ttotal: 3.9s\tremaining: 5.15s\n",
      "431:\tlearn: 2026.4767365\ttotal: 3.92s\tremaining: 5.15s\n",
      "432:\tlearn: 2026.1508343\ttotal: 3.95s\tremaining: 5.17s\n",
      "433:\tlearn: 2025.9227317\ttotal: 3.97s\tremaining: 5.17s\n",
      "434:\tlearn: 2025.4746724\ttotal: 3.98s\tremaining: 5.17s\n",
      "435:\tlearn: 2025.2781473\ttotal: 3.99s\tremaining: 5.17s\n",
      "436:\tlearn: 2024.9668640\ttotal: 4s\tremaining: 5.16s\n",
      "437:\tlearn: 2024.7130287\ttotal: 4.01s\tremaining: 5.15s\n",
      "438:\tlearn: 2024.5719317\ttotal: 4.02s\tremaining: 5.14s\n",
      "439:\tlearn: 2024.4246220\ttotal: 4.04s\tremaining: 5.14s\n",
      "440:\tlearn: 2024.2474742\ttotal: 4.04s\tremaining: 5.13s\n",
      "441:\tlearn: 2024.1257742\ttotal: 4.06s\tremaining: 5.12s\n",
      "442:\tlearn: 2023.9168829\ttotal: 4.08s\tremaining: 5.12s\n",
      "443:\tlearn: 2023.7676552\ttotal: 4.09s\tremaining: 5.12s\n",
      "444:\tlearn: 2023.5970962\ttotal: 4.1s\tremaining: 5.11s\n",
      "445:\tlearn: 2023.3679479\ttotal: 4.12s\tremaining: 5.12s\n",
      "446:\tlearn: 2023.2546111\ttotal: 4.13s\tremaining: 5.11s\n",
      "447:\tlearn: 2022.9898373\ttotal: 4.14s\tremaining: 5.1s\n",
      "448:\tlearn: 2022.8281852\ttotal: 4.15s\tremaining: 5.1s\n",
      "449:\tlearn: 2022.6335642\ttotal: 4.17s\tremaining: 5.09s\n",
      "450:\tlearn: 2022.4298595\ttotal: 4.17s\tremaining: 5.08s\n",
      "451:\tlearn: 2022.2199086\ttotal: 4.2s\tremaining: 5.09s\n",
      "452:\tlearn: 2021.8630613\ttotal: 4.21s\tremaining: 5.08s\n",
      "453:\tlearn: 2021.5728015\ttotal: 4.22s\tremaining: 5.08s\n",
      "454:\tlearn: 2021.4285710\ttotal: 4.23s\tremaining: 5.07s\n",
      "455:\tlearn: 2021.2989044\ttotal: 4.24s\tremaining: 5.05s\n",
      "456:\tlearn: 2020.9996985\ttotal: 4.25s\tremaining: 5.05s\n",
      "457:\tlearn: 2020.6632070\ttotal: 4.26s\tremaining: 5.04s\n",
      "458:\tlearn: 2020.4693701\ttotal: 4.27s\tremaining: 5.03s\n",
      "459:\tlearn: 2020.3673524\ttotal: 4.28s\tremaining: 5.02s\n",
      "460:\tlearn: 2019.9531882\ttotal: 4.29s\tremaining: 5.02s\n",
      "461:\tlearn: 2019.8802524\ttotal: 4.3s\tremaining: 5.01s\n",
      "462:\tlearn: 2019.5899024\ttotal: 4.34s\tremaining: 5.04s\n",
      "463:\tlearn: 2019.2516501\ttotal: 4.37s\tremaining: 5.05s\n",
      "464:\tlearn: 2019.0415131\ttotal: 4.4s\tremaining: 5.07s\n",
      "465:\tlearn: 2018.7944634\ttotal: 4.42s\tremaining: 5.07s\n",
      "466:\tlearn: 2018.5359457\ttotal: 4.44s\tremaining: 5.07s\n",
      "467:\tlearn: 2018.3166064\ttotal: 4.46s\tremaining: 5.07s\n",
      "468:\tlearn: 2018.0380811\ttotal: 4.49s\tremaining: 5.09s\n",
      "469:\tlearn: 2017.6913198\ttotal: 4.53s\tremaining: 5.11s\n",
      "470:\tlearn: 2017.3893174\ttotal: 4.55s\tremaining: 5.12s\n",
      "471:\tlearn: 2017.2784237\ttotal: 4.58s\tremaining: 5.13s\n",
      "472:\tlearn: 2016.9163717\ttotal: 4.61s\tremaining: 5.13s\n",
      "473:\tlearn: 2016.6958317\ttotal: 4.63s\tremaining: 5.14s\n",
      "474:\tlearn: 2016.3060010\ttotal: 4.65s\tremaining: 5.14s\n",
      "475:\tlearn: 2016.2284314\ttotal: 4.68s\tremaining: 5.16s\n",
      "476:\tlearn: 2015.9990557\ttotal: 4.7s\tremaining: 5.16s\n",
      "477:\tlearn: 2015.8385159\ttotal: 4.72s\tremaining: 5.16s\n",
      "478:\tlearn: 2015.5635706\ttotal: 4.74s\tremaining: 5.16s\n",
      "479:\tlearn: 2015.2968901\ttotal: 4.76s\tremaining: 5.16s\n",
      "480:\tlearn: 2015.0230259\ttotal: 4.79s\tremaining: 5.17s\n",
      "481:\tlearn: 2014.7941702\ttotal: 4.81s\tremaining: 5.17s\n",
      "482:\tlearn: 2014.6886838\ttotal: 4.82s\tremaining: 5.16s\n",
      "483:\tlearn: 2014.4808867\ttotal: 4.84s\tremaining: 5.16s\n",
      "484:\tlearn: 2013.9770215\ttotal: 4.86s\tremaining: 5.16s\n",
      "485:\tlearn: 2013.8015435\ttotal: 4.88s\tremaining: 5.16s\n",
      "486:\tlearn: 2013.6489145\ttotal: 4.89s\tremaining: 5.15s\n",
      "487:\tlearn: 2013.3975250\ttotal: 4.91s\tremaining: 5.15s\n",
      "488:\tlearn: 2013.0836519\ttotal: 4.92s\tremaining: 5.14s\n",
      "489:\tlearn: 2012.8912539\ttotal: 4.93s\tremaining: 5.13s\n",
      "490:\tlearn: 2012.4724890\ttotal: 4.94s\tremaining: 5.12s\n",
      "491:\tlearn: 2012.1864132\ttotal: 4.95s\tremaining: 5.12s\n",
      "492:\tlearn: 2011.9342269\ttotal: 4.97s\tremaining: 5.11s\n",
      "493:\tlearn: 2011.7072016\ttotal: 4.98s\tremaining: 5.1s\n",
      "494:\tlearn: 2011.6164232\ttotal: 4.99s\tremaining: 5.09s\n",
      "495:\tlearn: 2011.4570777\ttotal: 5s\tremaining: 5.08s\n",
      "496:\tlearn: 2011.2761216\ttotal: 5.02s\tremaining: 5.08s\n",
      "497:\tlearn: 2011.1562348\ttotal: 5.03s\tremaining: 5.07s\n",
      "498:\tlearn: 2010.9928502\ttotal: 5.04s\tremaining: 5.06s\n",
      "499:\tlearn: 2010.7365334\ttotal: 5.05s\tremaining: 5.05s\n",
      "500:\tlearn: 2010.5915880\ttotal: 5.07s\tremaining: 5.05s\n",
      "501:\tlearn: 2010.3749118\ttotal: 5.09s\tremaining: 5.05s\n",
      "502:\tlearn: 2010.1456016\ttotal: 5.1s\tremaining: 5.04s\n",
      "503:\tlearn: 2009.8687183\ttotal: 5.12s\tremaining: 5.03s\n",
      "504:\tlearn: 2009.6377239\ttotal: 5.13s\tremaining: 5.03s\n",
      "505:\tlearn: 2009.4247137\ttotal: 5.14s\tremaining: 5.02s\n",
      "506:\tlearn: 2009.0955829\ttotal: 5.16s\tremaining: 5.01s\n",
      "507:\tlearn: 2008.7114787\ttotal: 5.18s\tremaining: 5.02s\n",
      "508:\tlearn: 2008.3728377\ttotal: 5.19s\tremaining: 5.01s\n",
      "509:\tlearn: 2008.1371569\ttotal: 5.2s\tremaining: 5s\n",
      "510:\tlearn: 2007.9041810\ttotal: 5.21s\tremaining: 4.99s\n",
      "511:\tlearn: 2007.6387098\ttotal: 5.22s\tremaining: 4.98s\n",
      "512:\tlearn: 2007.3266539\ttotal: 5.23s\tremaining: 4.97s\n",
      "513:\tlearn: 2007.0941261\ttotal: 5.25s\tremaining: 4.96s\n",
      "514:\tlearn: 2007.0175977\ttotal: 5.28s\tremaining: 4.97s\n",
      "515:\tlearn: 2006.6944474\ttotal: 5.29s\tremaining: 4.96s\n",
      "516:\tlearn: 2006.5233428\ttotal: 5.31s\tremaining: 4.96s\n",
      "517:\tlearn: 2006.3358947\ttotal: 5.33s\tremaining: 4.96s\n",
      "518:\tlearn: 2006.1749116\ttotal: 5.35s\tremaining: 4.96s\n",
      "519:\tlearn: 2005.8465104\ttotal: 5.37s\tremaining: 4.96s\n",
      "520:\tlearn: 2005.6629035\ttotal: 5.38s\tremaining: 4.95s\n",
      "521:\tlearn: 2005.1281292\ttotal: 5.4s\tremaining: 4.94s\n",
      "522:\tlearn: 2004.8817317\ttotal: 5.41s\tremaining: 4.93s\n",
      "523:\tlearn: 2004.7905252\ttotal: 5.42s\tremaining: 4.92s\n",
      "524:\tlearn: 2004.6025992\ttotal: 5.43s\tremaining: 4.91s\n",
      "525:\tlearn: 2004.3008607\ttotal: 5.46s\tremaining: 4.92s\n",
      "526:\tlearn: 2004.1754770\ttotal: 5.48s\tremaining: 4.92s\n",
      "527:\tlearn: 2004.0106513\ttotal: 5.5s\tremaining: 4.91s\n",
      "528:\tlearn: 2003.9340269\ttotal: 5.51s\tremaining: 4.9s\n",
      "529:\tlearn: 2003.8162905\ttotal: 5.52s\tremaining: 4.89s\n",
      "530:\tlearn: 2003.6132328\ttotal: 5.53s\tremaining: 4.88s\n",
      "531:\tlearn: 2003.3684428\ttotal: 5.55s\tremaining: 4.88s\n",
      "532:\tlearn: 2003.2384214\ttotal: 5.56s\tremaining: 4.87s\n",
      "533:\tlearn: 2003.1068553\ttotal: 5.57s\tremaining: 4.86s\n",
      "534:\tlearn: 2002.8735792\ttotal: 5.59s\tremaining: 4.86s\n",
      "535:\tlearn: 2002.7722370\ttotal: 5.6s\tremaining: 4.85s\n",
      "536:\tlearn: 2002.6151585\ttotal: 5.61s\tremaining: 4.84s\n",
      "537:\tlearn: 2002.4616400\ttotal: 5.62s\tremaining: 4.83s\n",
      "538:\tlearn: 2002.3256072\ttotal: 5.65s\tremaining: 4.83s\n",
      "539:\tlearn: 2002.1672593\ttotal: 5.66s\tremaining: 4.82s\n",
      "540:\tlearn: 2001.8587733\ttotal: 5.67s\tremaining: 4.81s\n",
      "541:\tlearn: 2001.6936149\ttotal: 5.68s\tremaining: 4.8s\n",
      "542:\tlearn: 2001.3858485\ttotal: 5.69s\tremaining: 4.79s\n",
      "543:\tlearn: 2001.0793598\ttotal: 5.7s\tremaining: 4.78s\n",
      "544:\tlearn: 2000.9845726\ttotal: 5.71s\tremaining: 4.76s\n",
      "545:\tlearn: 2000.8170069\ttotal: 5.72s\tremaining: 4.76s\n",
      "546:\tlearn: 2000.4494201\ttotal: 5.73s\tremaining: 4.75s\n",
      "547:\tlearn: 2000.2722722\ttotal: 5.74s\tremaining: 4.74s\n",
      "548:\tlearn: 2000.0587672\ttotal: 5.75s\tremaining: 4.72s\n",
      "549:\tlearn: 1999.8222148\ttotal: 5.76s\tremaining: 4.71s\n",
      "550:\tlearn: 1999.6720150\ttotal: 5.77s\tremaining: 4.7s\n",
      "551:\tlearn: 1999.3085906\ttotal: 5.78s\tremaining: 4.69s\n",
      "552:\tlearn: 1998.9335040\ttotal: 5.79s\tremaining: 4.68s\n",
      "553:\tlearn: 1998.7673565\ttotal: 5.8s\tremaining: 4.67s\n",
      "554:\tlearn: 1998.4151087\ttotal: 5.8s\tremaining: 4.65s\n",
      "555:\tlearn: 1998.2184262\ttotal: 5.82s\tremaining: 4.65s\n",
      "556:\tlearn: 1998.1079702\ttotal: 5.84s\tremaining: 4.64s\n",
      "557:\tlearn: 1997.6625244\ttotal: 5.85s\tremaining: 4.63s\n",
      "558:\tlearn: 1997.5181171\ttotal: 5.86s\tremaining: 4.62s\n",
      "559:\tlearn: 1997.1883340\ttotal: 5.87s\tremaining: 4.61s\n",
      "560:\tlearn: 1996.9866122\ttotal: 5.88s\tremaining: 4.6s\n",
      "561:\tlearn: 1996.8224255\ttotal: 5.88s\tremaining: 4.58s\n",
      "562:\tlearn: 1996.7124250\ttotal: 5.89s\tremaining: 4.57s\n",
      "563:\tlearn: 1996.4858776\ttotal: 5.9s\tremaining: 4.56s\n",
      "564:\tlearn: 1996.1255320\ttotal: 5.91s\tremaining: 4.55s\n",
      "565:\tlearn: 1995.9733941\ttotal: 5.92s\tremaining: 4.54s\n",
      "566:\tlearn: 1995.7323424\ttotal: 5.93s\tremaining: 4.53s\n",
      "567:\tlearn: 1995.5959799\ttotal: 5.94s\tremaining: 4.52s\n",
      "568:\tlearn: 1995.4909742\ttotal: 5.95s\tremaining: 4.51s\n",
      "569:\tlearn: 1995.2312575\ttotal: 5.96s\tremaining: 4.5s\n",
      "570:\tlearn: 1994.8534828\ttotal: 5.97s\tremaining: 4.49s\n",
      "571:\tlearn: 1994.6944313\ttotal: 5.98s\tremaining: 4.47s\n",
      "572:\tlearn: 1994.3951821\ttotal: 5.99s\tremaining: 4.46s\n",
      "573:\tlearn: 1993.9997586\ttotal: 5.99s\tremaining: 4.45s\n",
      "574:\tlearn: 1993.8518643\ttotal: 6s\tremaining: 4.44s\n",
      "575:\tlearn: 1993.6231736\ttotal: 6.01s\tremaining: 4.42s\n",
      "576:\tlearn: 1993.3299025\ttotal: 6.04s\tremaining: 4.42s\n",
      "577:\tlearn: 1993.1054556\ttotal: 6.04s\tremaining: 4.41s\n",
      "578:\tlearn: 1992.9518973\ttotal: 6.05s\tremaining: 4.4s\n",
      "579:\tlearn: 1992.7871649\ttotal: 6.06s\tremaining: 4.39s\n",
      "580:\tlearn: 1992.5259102\ttotal: 6.07s\tremaining: 4.38s\n",
      "581:\tlearn: 1992.3896607\ttotal: 6.09s\tremaining: 4.37s\n",
      "582:\tlearn: 1992.2567290\ttotal: 6.1s\tremaining: 4.36s\n",
      "583:\tlearn: 1992.0128073\ttotal: 6.12s\tremaining: 4.36s\n",
      "584:\tlearn: 1991.6923966\ttotal: 6.13s\tremaining: 4.34s\n",
      "585:\tlearn: 1991.4305263\ttotal: 6.14s\tremaining: 4.33s\n",
      "586:\tlearn: 1991.3003753\ttotal: 6.15s\tremaining: 4.33s\n",
      "587:\tlearn: 1991.1650953\ttotal: 6.15s\tremaining: 4.31s\n",
      "588:\tlearn: 1990.8841517\ttotal: 6.17s\tremaining: 4.3s\n",
      "589:\tlearn: 1990.6532165\ttotal: 6.17s\tremaining: 4.29s\n",
      "590:\tlearn: 1990.5211029\ttotal: 6.18s\tremaining: 4.28s\n",
      "591:\tlearn: 1990.1884468\ttotal: 6.19s\tremaining: 4.26s\n",
      "592:\tlearn: 1990.0066447\ttotal: 6.2s\tremaining: 4.25s\n",
      "593:\tlearn: 1989.8997529\ttotal: 6.22s\tremaining: 4.25s\n",
      "594:\tlearn: 1989.6567143\ttotal: 6.24s\tremaining: 4.25s\n",
      "595:\tlearn: 1989.4442086\ttotal: 6.25s\tremaining: 4.24s\n",
      "596:\tlearn: 1989.2396267\ttotal: 6.26s\tremaining: 4.22s\n",
      "597:\tlearn: 1988.8869021\ttotal: 6.26s\tremaining: 4.21s\n",
      "598:\tlearn: 1988.7353451\ttotal: 6.28s\tremaining: 4.2s\n",
      "599:\tlearn: 1988.6068105\ttotal: 6.28s\tremaining: 4.19s\n",
      "600:\tlearn: 1988.3699543\ttotal: 6.29s\tremaining: 4.18s\n",
      "601:\tlearn: 1988.0862326\ttotal: 6.31s\tremaining: 4.17s\n",
      "602:\tlearn: 1987.9439762\ttotal: 6.32s\tremaining: 4.16s\n",
      "603:\tlearn: 1987.8389731\ttotal: 6.33s\tremaining: 4.15s\n",
      "604:\tlearn: 1987.6369939\ttotal: 6.34s\tremaining: 4.14s\n",
      "605:\tlearn: 1987.3762443\ttotal: 6.35s\tremaining: 4.13s\n",
      "606:\tlearn: 1987.1513625\ttotal: 6.36s\tremaining: 4.12s\n",
      "607:\tlearn: 1986.9033745\ttotal: 6.37s\tremaining: 4.11s\n",
      "608:\tlearn: 1986.7143483\ttotal: 6.38s\tremaining: 4.09s\n",
      "609:\tlearn: 1986.6656331\ttotal: 6.39s\tremaining: 4.08s\n",
      "610:\tlearn: 1986.3318864\ttotal: 6.41s\tremaining: 4.08s\n",
      "611:\tlearn: 1986.1645112\ttotal: 6.43s\tremaining: 4.08s\n",
      "612:\tlearn: 1986.0117336\ttotal: 6.44s\tremaining: 4.07s\n",
      "613:\tlearn: 1985.8347783\ttotal: 6.45s\tremaining: 4.05s\n",
      "614:\tlearn: 1985.6824192\ttotal: 6.46s\tremaining: 4.04s\n",
      "615:\tlearn: 1985.4986217\ttotal: 6.47s\tremaining: 4.03s\n",
      "616:\tlearn: 1985.2856837\ttotal: 6.47s\tremaining: 4.02s\n",
      "617:\tlearn: 1985.1120875\ttotal: 6.48s\tremaining: 4.01s\n",
      "618:\tlearn: 1984.8039885\ttotal: 6.5s\tremaining: 4s\n",
      "619:\tlearn: 1984.5730661\ttotal: 6.51s\tremaining: 3.99s\n",
      "620:\tlearn: 1984.4387701\ttotal: 6.51s\tremaining: 3.98s\n",
      "621:\tlearn: 1984.1727511\ttotal: 6.52s\tremaining: 3.96s\n",
      "622:\tlearn: 1983.9813074\ttotal: 6.53s\tremaining: 3.95s\n",
      "623:\tlearn: 1983.7752232\ttotal: 6.54s\tremaining: 3.94s\n",
      "624:\tlearn: 1983.5523392\ttotal: 6.54s\tremaining: 3.93s\n",
      "625:\tlearn: 1983.3637257\ttotal: 6.55s\tremaining: 3.91s\n",
      "626:\tlearn: 1983.1559274\ttotal: 6.56s\tremaining: 3.9s\n",
      "627:\tlearn: 1982.8999769\ttotal: 6.57s\tremaining: 3.89s\n",
      "628:\tlearn: 1982.8410851\ttotal: 6.58s\tremaining: 3.88s\n",
      "629:\tlearn: 1982.4935135\ttotal: 6.6s\tremaining: 3.88s\n",
      "630:\tlearn: 1982.2709142\ttotal: 6.62s\tremaining: 3.87s\n",
      "631:\tlearn: 1982.0861273\ttotal: 6.63s\tremaining: 3.86s\n",
      "632:\tlearn: 1981.9227694\ttotal: 6.63s\tremaining: 3.85s\n",
      "633:\tlearn: 1981.5285036\ttotal: 6.65s\tremaining: 3.84s\n",
      "634:\tlearn: 1981.3740248\ttotal: 6.66s\tremaining: 3.83s\n",
      "635:\tlearn: 1981.1058028\ttotal: 6.67s\tremaining: 3.82s\n",
      "636:\tlearn: 1980.8159481\ttotal: 6.69s\tremaining: 3.81s\n",
      "637:\tlearn: 1980.6022869\ttotal: 6.7s\tremaining: 3.8s\n",
      "638:\tlearn: 1980.3276719\ttotal: 6.71s\tremaining: 3.79s\n",
      "639:\tlearn: 1980.1976182\ttotal: 6.72s\tremaining: 3.78s\n",
      "640:\tlearn: 1979.9602047\ttotal: 6.73s\tremaining: 3.77s\n",
      "641:\tlearn: 1979.8101196\ttotal: 6.74s\tremaining: 3.76s\n",
      "642:\tlearn: 1979.6265409\ttotal: 6.75s\tremaining: 3.75s\n",
      "643:\tlearn: 1979.2994475\ttotal: 6.76s\tremaining: 3.74s\n",
      "644:\tlearn: 1979.2242411\ttotal: 6.77s\tremaining: 3.73s\n",
      "645:\tlearn: 1978.9213669\ttotal: 6.79s\tremaining: 3.72s\n",
      "646:\tlearn: 1978.7711825\ttotal: 6.8s\tremaining: 3.71s\n",
      "647:\tlearn: 1978.5555486\ttotal: 6.81s\tremaining: 3.7s\n",
      "648:\tlearn: 1978.3844275\ttotal: 6.82s\tremaining: 3.69s\n",
      "649:\tlearn: 1978.1256126\ttotal: 6.83s\tremaining: 3.68s\n",
      "650:\tlearn: 1978.0232512\ttotal: 6.84s\tremaining: 3.66s\n",
      "651:\tlearn: 1977.7824968\ttotal: 6.84s\tremaining: 3.65s\n",
      "652:\tlearn: 1977.6316601\ttotal: 6.85s\tremaining: 3.64s\n",
      "653:\tlearn: 1977.4781402\ttotal: 6.86s\tremaining: 3.63s\n",
      "654:\tlearn: 1977.3340545\ttotal: 6.87s\tremaining: 3.62s\n",
      "655:\tlearn: 1976.9995769\ttotal: 6.88s\tremaining: 3.61s\n",
      "656:\tlearn: 1976.8686220\ttotal: 6.9s\tremaining: 3.6s\n",
      "657:\tlearn: 1976.3399236\ttotal: 6.91s\tremaining: 3.59s\n",
      "658:\tlearn: 1976.1309357\ttotal: 6.92s\tremaining: 3.58s\n",
      "659:\tlearn: 1975.8470014\ttotal: 6.92s\tremaining: 3.57s\n",
      "660:\tlearn: 1975.7305060\ttotal: 6.93s\tremaining: 3.56s\n",
      "661:\tlearn: 1975.5151992\ttotal: 6.94s\tremaining: 3.54s\n",
      "662:\tlearn: 1975.3732690\ttotal: 6.95s\tremaining: 3.53s\n",
      "663:\tlearn: 1975.1573845\ttotal: 6.96s\tremaining: 3.52s\n",
      "664:\tlearn: 1975.0472777\ttotal: 6.97s\tremaining: 3.51s\n",
      "665:\tlearn: 1974.9133280\ttotal: 6.99s\tremaining: 3.5s\n",
      "666:\tlearn: 1974.8186878\ttotal: 7.01s\tremaining: 3.5s\n",
      "667:\tlearn: 1974.4992126\ttotal: 7.01s\tremaining: 3.49s\n",
      "668:\tlearn: 1974.3402707\ttotal: 7.03s\tremaining: 3.48s\n",
      "669:\tlearn: 1974.1821340\ttotal: 7.03s\tremaining: 3.46s\n",
      "670:\tlearn: 1973.9207314\ttotal: 7.04s\tremaining: 3.45s\n",
      "671:\tlearn: 1973.6706934\ttotal: 7.05s\tremaining: 3.44s\n",
      "672:\tlearn: 1973.5577202\ttotal: 7.07s\tremaining: 3.43s\n",
      "673:\tlearn: 1973.1885978\ttotal: 7.07s\tremaining: 3.42s\n",
      "674:\tlearn: 1972.9237159\ttotal: 7.08s\tremaining: 3.41s\n",
      "675:\tlearn: 1972.7862351\ttotal: 7.09s\tremaining: 3.4s\n",
      "676:\tlearn: 1972.5663978\ttotal: 7.1s\tremaining: 3.39s\n",
      "677:\tlearn: 1972.3107137\ttotal: 7.11s\tremaining: 3.38s\n",
      "678:\tlearn: 1972.1781391\ttotal: 7.12s\tremaining: 3.36s\n",
      "679:\tlearn: 1971.9443633\ttotal: 7.12s\tremaining: 3.35s\n",
      "680:\tlearn: 1971.7097515\ttotal: 7.13s\tremaining: 3.34s\n",
      "681:\tlearn: 1971.5314617\ttotal: 7.14s\tremaining: 3.33s\n",
      "682:\tlearn: 1971.2321482\ttotal: 7.15s\tremaining: 3.32s\n",
      "683:\tlearn: 1971.1572075\ttotal: 7.16s\tremaining: 3.31s\n",
      "684:\tlearn: 1970.9170106\ttotal: 7.18s\tremaining: 3.3s\n",
      "685:\tlearn: 1970.7686196\ttotal: 7.2s\tremaining: 3.29s\n",
      "686:\tlearn: 1970.5537974\ttotal: 7.21s\tremaining: 3.29s\n",
      "687:\tlearn: 1970.3831520\ttotal: 7.22s\tremaining: 3.27s\n",
      "688:\tlearn: 1970.1614161\ttotal: 7.24s\tremaining: 3.27s\n",
      "689:\tlearn: 1970.0040612\ttotal: 7.24s\tremaining: 3.25s\n",
      "690:\tlearn: 1969.8413120\ttotal: 7.27s\tremaining: 3.25s\n",
      "691:\tlearn: 1969.6066216\ttotal: 7.27s\tremaining: 3.24s\n",
      "692:\tlearn: 1969.4871300\ttotal: 7.29s\tremaining: 3.23s\n",
      "693:\tlearn: 1969.2410263\ttotal: 7.3s\tremaining: 3.22s\n",
      "694:\tlearn: 1968.9548282\ttotal: 7.31s\tremaining: 3.21s\n",
      "695:\tlearn: 1968.7363062\ttotal: 7.32s\tremaining: 3.2s\n",
      "696:\tlearn: 1968.5739970\ttotal: 7.33s\tremaining: 3.19s\n",
      "697:\tlearn: 1968.4480707\ttotal: 7.34s\tremaining: 3.17s\n",
      "698:\tlearn: 1968.2818443\ttotal: 7.35s\tremaining: 3.17s\n",
      "699:\tlearn: 1968.0263337\ttotal: 7.38s\tremaining: 3.16s\n",
      "700:\tlearn: 1967.7707679\ttotal: 7.39s\tremaining: 3.15s\n",
      "701:\tlearn: 1967.5937775\ttotal: 7.4s\tremaining: 3.14s\n",
      "702:\tlearn: 1967.3965347\ttotal: 7.41s\tremaining: 3.13s\n",
      "703:\tlearn: 1966.8910854\ttotal: 7.42s\tremaining: 3.12s\n",
      "704:\tlearn: 1966.7565810\ttotal: 7.43s\tremaining: 3.11s\n",
      "705:\tlearn: 1966.5068312\ttotal: 7.44s\tremaining: 3.1s\n",
      "706:\tlearn: 1966.4258274\ttotal: 7.46s\tremaining: 3.09s\n",
      "707:\tlearn: 1966.2369753\ttotal: 7.47s\tremaining: 3.08s\n",
      "708:\tlearn: 1966.1351399\ttotal: 7.48s\tremaining: 3.07s\n",
      "709:\tlearn: 1966.0234103\ttotal: 7.49s\tremaining: 3.06s\n",
      "710:\tlearn: 1965.8977469\ttotal: 7.5s\tremaining: 3.05s\n",
      "711:\tlearn: 1965.7543651\ttotal: 7.51s\tremaining: 3.04s\n",
      "712:\tlearn: 1965.6216470\ttotal: 7.52s\tremaining: 3.03s\n",
      "713:\tlearn: 1965.4421607\ttotal: 7.53s\tremaining: 3.02s\n",
      "714:\tlearn: 1965.1689994\ttotal: 7.56s\tremaining: 3.01s\n",
      "715:\tlearn: 1965.0181938\ttotal: 7.58s\tremaining: 3.01s\n",
      "716:\tlearn: 1964.7940535\ttotal: 7.59s\tremaining: 3s\n",
      "717:\tlearn: 1964.5551800\ttotal: 7.6s\tremaining: 2.98s\n",
      "718:\tlearn: 1964.4512118\ttotal: 7.61s\tremaining: 2.97s\n",
      "719:\tlearn: 1964.3555017\ttotal: 7.62s\tremaining: 2.96s\n",
      "720:\tlearn: 1964.1818566\ttotal: 7.63s\tremaining: 2.95s\n",
      "721:\tlearn: 1963.9558345\ttotal: 7.64s\tremaining: 2.94s\n",
      "722:\tlearn: 1963.6943739\ttotal: 7.66s\tremaining: 2.93s\n",
      "723:\tlearn: 1963.4810122\ttotal: 7.67s\tremaining: 2.92s\n",
      "724:\tlearn: 1963.3418188\ttotal: 7.67s\tremaining: 2.91s\n",
      "725:\tlearn: 1963.1964245\ttotal: 7.68s\tremaining: 2.9s\n",
      "726:\tlearn: 1962.9787055\ttotal: 7.7s\tremaining: 2.89s\n",
      "727:\tlearn: 1962.8579572\ttotal: 7.71s\tremaining: 2.88s\n",
      "728:\tlearn: 1962.6350249\ttotal: 7.71s\tremaining: 2.87s\n",
      "729:\tlearn: 1962.5530632\ttotal: 7.72s\tremaining: 2.86s\n",
      "730:\tlearn: 1962.2378494\ttotal: 7.74s\tremaining: 2.85s\n",
      "731:\tlearn: 1962.1040258\ttotal: 7.76s\tremaining: 2.84s\n",
      "732:\tlearn: 1961.9937729\ttotal: 7.77s\tremaining: 2.83s\n",
      "733:\tlearn: 1961.7783468\ttotal: 7.78s\tremaining: 2.82s\n",
      "734:\tlearn: 1961.5161097\ttotal: 7.79s\tremaining: 2.81s\n",
      "735:\tlearn: 1961.4085659\ttotal: 7.8s\tremaining: 2.8s\n",
      "736:\tlearn: 1961.1646800\ttotal: 7.81s\tremaining: 2.79s\n",
      "737:\tlearn: 1960.9064363\ttotal: 7.82s\tremaining: 2.78s\n",
      "738:\tlearn: 1960.7225265\ttotal: 7.83s\tremaining: 2.77s\n",
      "739:\tlearn: 1960.4939727\ttotal: 7.85s\tremaining: 2.76s\n",
      "740:\tlearn: 1960.3828967\ttotal: 7.87s\tremaining: 2.75s\n",
      "741:\tlearn: 1960.2234192\ttotal: 7.88s\tremaining: 2.74s\n",
      "742:\tlearn: 1960.0302949\ttotal: 7.9s\tremaining: 2.73s\n",
      "743:\tlearn: 1959.8676387\ttotal: 7.91s\tremaining: 2.72s\n",
      "744:\tlearn: 1959.5462526\ttotal: 7.92s\tremaining: 2.71s\n",
      "745:\tlearn: 1959.4099488\ttotal: 7.94s\tremaining: 2.7s\n",
      "746:\tlearn: 1959.1206686\ttotal: 7.95s\tremaining: 2.69s\n",
      "747:\tlearn: 1958.9433235\ttotal: 7.95s\tremaining: 2.68s\n",
      "748:\tlearn: 1958.6595951\ttotal: 7.97s\tremaining: 2.67s\n",
      "749:\tlearn: 1958.3216393\ttotal: 7.98s\tremaining: 2.66s\n",
      "750:\tlearn: 1958.2316148\ttotal: 7.99s\tremaining: 2.65s\n",
      "751:\tlearn: 1958.0365345\ttotal: 8s\tremaining: 2.64s\n",
      "752:\tlearn: 1957.9369757\ttotal: 8s\tremaining: 2.63s\n",
      "753:\tlearn: 1957.7953481\ttotal: 8.02s\tremaining: 2.62s\n",
      "754:\tlearn: 1957.6414936\ttotal: 8.03s\tremaining: 2.61s\n",
      "755:\tlearn: 1957.3456400\ttotal: 8.04s\tremaining: 2.6s\n",
      "756:\tlearn: 1957.0733678\ttotal: 8.05s\tremaining: 2.58s\n",
      "757:\tlearn: 1956.9210646\ttotal: 8.06s\tremaining: 2.57s\n",
      "758:\tlearn: 1956.6906829\ttotal: 8.07s\tremaining: 2.56s\n",
      "759:\tlearn: 1956.5754968\ttotal: 8.08s\tremaining: 2.55s\n",
      "760:\tlearn: 1956.3348647\ttotal: 8.09s\tremaining: 2.54s\n",
      "761:\tlearn: 1956.2474747\ttotal: 8.1s\tremaining: 2.53s\n",
      "762:\tlearn: 1956.1400486\ttotal: 8.11s\tremaining: 2.52s\n",
      "763:\tlearn: 1955.9779160\ttotal: 8.12s\tremaining: 2.51s\n",
      "764:\tlearn: 1955.8534219\ttotal: 8.14s\tremaining: 2.5s\n",
      "765:\tlearn: 1955.5388483\ttotal: 8.16s\tremaining: 2.49s\n",
      "766:\tlearn: 1955.3416555\ttotal: 8.18s\tremaining: 2.48s\n",
      "767:\tlearn: 1955.1410372\ttotal: 8.19s\tremaining: 2.47s\n",
      "768:\tlearn: 1954.9818123\ttotal: 8.21s\tremaining: 2.46s\n",
      "769:\tlearn: 1954.8080258\ttotal: 8.24s\tremaining: 2.46s\n",
      "770:\tlearn: 1954.6016974\ttotal: 8.26s\tremaining: 2.45s\n",
      "771:\tlearn: 1954.5256321\ttotal: 8.27s\tremaining: 2.44s\n",
      "772:\tlearn: 1954.2610937\ttotal: 8.29s\tremaining: 2.44s\n",
      "773:\tlearn: 1954.1499719\ttotal: 8.31s\tremaining: 2.42s\n",
      "774:\tlearn: 1953.8786241\ttotal: 8.33s\tremaining: 2.42s\n",
      "775:\tlearn: 1953.7999320\ttotal: 8.35s\tremaining: 2.41s\n",
      "776:\tlearn: 1953.7073536\ttotal: 8.38s\tremaining: 2.4s\n",
      "777:\tlearn: 1953.5658139\ttotal: 8.39s\tremaining: 2.39s\n",
      "778:\tlearn: 1953.4788450\ttotal: 8.41s\tremaining: 2.38s\n",
      "779:\tlearn: 1953.3473569\ttotal: 8.42s\tremaining: 2.37s\n",
      "780:\tlearn: 1953.1961071\ttotal: 8.43s\tremaining: 2.36s\n",
      "781:\tlearn: 1953.0989583\ttotal: 8.44s\tremaining: 2.35s\n",
      "782:\tlearn: 1952.9490920\ttotal: 8.45s\tremaining: 2.34s\n",
      "783:\tlearn: 1952.8468147\ttotal: 8.46s\tremaining: 2.33s\n",
      "784:\tlearn: 1952.5263955\ttotal: 8.47s\tremaining: 2.32s\n",
      "785:\tlearn: 1952.3000903\ttotal: 8.48s\tremaining: 2.31s\n",
      "786:\tlearn: 1952.1297065\ttotal: 8.48s\tremaining: 2.3s\n",
      "787:\tlearn: 1951.9771072\ttotal: 8.49s\tremaining: 2.28s\n",
      "788:\tlearn: 1951.8435611\ttotal: 8.51s\tremaining: 2.28s\n",
      "789:\tlearn: 1951.5396055\ttotal: 8.52s\tremaining: 2.26s\n",
      "790:\tlearn: 1951.4471737\ttotal: 8.53s\tremaining: 2.25s\n",
      "791:\tlearn: 1951.3172299\ttotal: 8.54s\tremaining: 2.24s\n",
      "792:\tlearn: 1951.1318362\ttotal: 8.55s\tremaining: 2.23s\n",
      "793:\tlearn: 1950.9920236\ttotal: 8.56s\tremaining: 2.22s\n",
      "794:\tlearn: 1950.7187501\ttotal: 8.57s\tremaining: 2.21s\n",
      "795:\tlearn: 1950.6623259\ttotal: 8.58s\tremaining: 2.2s\n",
      "796:\tlearn: 1950.4454580\ttotal: 8.59s\tremaining: 2.19s\n",
      "797:\tlearn: 1950.3590202\ttotal: 8.6s\tremaining: 2.18s\n",
      "798:\tlearn: 1950.1603900\ttotal: 8.61s\tremaining: 2.16s\n",
      "799:\tlearn: 1949.8827333\ttotal: 8.62s\tremaining: 2.15s\n",
      "800:\tlearn: 1949.7536560\ttotal: 8.64s\tremaining: 2.15s\n",
      "801:\tlearn: 1949.5869131\ttotal: 8.65s\tremaining: 2.13s\n",
      "802:\tlearn: 1949.3858710\ttotal: 8.66s\tremaining: 2.12s\n",
      "803:\tlearn: 1949.2819805\ttotal: 8.67s\tremaining: 2.11s\n",
      "804:\tlearn: 1949.1170772\ttotal: 8.67s\tremaining: 2.1s\n",
      "805:\tlearn: 1948.9860525\ttotal: 8.68s\tremaining: 2.09s\n",
      "806:\tlearn: 1948.8678249\ttotal: 8.7s\tremaining: 2.08s\n",
      "807:\tlearn: 1948.7161633\ttotal: 8.71s\tremaining: 2.07s\n",
      "808:\tlearn: 1948.5573648\ttotal: 8.72s\tremaining: 2.06s\n",
      "809:\tlearn: 1948.3193981\ttotal: 8.72s\tremaining: 2.05s\n",
      "810:\tlearn: 1948.1883186\ttotal: 8.73s\tremaining: 2.04s\n",
      "811:\tlearn: 1948.0012961\ttotal: 8.74s\tremaining: 2.02s\n",
      "812:\tlearn: 1947.8535371\ttotal: 8.75s\tremaining: 2.01s\n",
      "813:\tlearn: 1947.6933425\ttotal: 8.76s\tremaining: 2s\n",
      "814:\tlearn: 1947.5557416\ttotal: 8.77s\tremaining: 1.99s\n",
      "815:\tlearn: 1947.3987967\ttotal: 8.78s\tremaining: 1.98s\n",
      "816:\tlearn: 1947.2115574\ttotal: 8.79s\tremaining: 1.97s\n",
      "817:\tlearn: 1946.9709637\ttotal: 8.8s\tremaining: 1.96s\n",
      "818:\tlearn: 1946.7465251\ttotal: 8.82s\tremaining: 1.95s\n",
      "819:\tlearn: 1946.5519160\ttotal: 8.83s\tremaining: 1.94s\n",
      "820:\tlearn: 1946.4929318\ttotal: 8.84s\tremaining: 1.93s\n",
      "821:\tlearn: 1946.3763083\ttotal: 8.85s\tremaining: 1.92s\n",
      "822:\tlearn: 1946.2058981\ttotal: 8.86s\tremaining: 1.91s\n",
      "823:\tlearn: 1945.8907951\ttotal: 8.87s\tremaining: 1.89s\n",
      "824:\tlearn: 1945.7449926\ttotal: 8.88s\tremaining: 1.88s\n",
      "825:\tlearn: 1945.5111476\ttotal: 8.9s\tremaining: 1.88s\n",
      "826:\tlearn: 1945.4413285\ttotal: 8.92s\tremaining: 1.86s\n",
      "827:\tlearn: 1945.2440419\ttotal: 8.93s\tremaining: 1.85s\n",
      "828:\tlearn: 1945.0240675\ttotal: 8.94s\tremaining: 1.84s\n",
      "829:\tlearn: 1944.9151576\ttotal: 8.96s\tremaining: 1.83s\n",
      "830:\tlearn: 1944.7422343\ttotal: 8.97s\tremaining: 1.82s\n",
      "831:\tlearn: 1944.5284210\ttotal: 8.99s\tremaining: 1.81s\n",
      "832:\tlearn: 1944.3272348\ttotal: 9s\tremaining: 1.8s\n",
      "833:\tlearn: 1944.1469589\ttotal: 9.01s\tremaining: 1.79s\n",
      "834:\tlearn: 1943.9770827\ttotal: 9.02s\tremaining: 1.78s\n",
      "835:\tlearn: 1943.8606664\ttotal: 9.03s\tremaining: 1.77s\n",
      "836:\tlearn: 1943.7483945\ttotal: 9.04s\tremaining: 1.76s\n",
      "837:\tlearn: 1943.5147232\ttotal: 9.05s\tremaining: 1.75s\n",
      "838:\tlearn: 1943.2615847\ttotal: 9.06s\tremaining: 1.74s\n",
      "839:\tlearn: 1943.1178563\ttotal: 9.06s\tremaining: 1.73s\n",
      "840:\tlearn: 1942.9768434\ttotal: 9.08s\tremaining: 1.72s\n",
      "841:\tlearn: 1942.8389653\ttotal: 9.09s\tremaining: 1.71s\n",
      "842:\tlearn: 1942.4870523\ttotal: 9.11s\tremaining: 1.7s\n",
      "843:\tlearn: 1942.3348594\ttotal: 9.12s\tremaining: 1.69s\n",
      "844:\tlearn: 1942.1263993\ttotal: 9.12s\tremaining: 1.67s\n",
      "845:\tlearn: 1941.9437983\ttotal: 9.13s\tremaining: 1.66s\n",
      "846:\tlearn: 1941.7710209\ttotal: 9.14s\tremaining: 1.65s\n",
      "847:\tlearn: 1941.6618722\ttotal: 9.15s\tremaining: 1.64s\n",
      "848:\tlearn: 1941.5391395\ttotal: 9.16s\tremaining: 1.63s\n",
      "849:\tlearn: 1941.3893897\ttotal: 9.19s\tremaining: 1.62s\n",
      "850:\tlearn: 1941.2411954\ttotal: 9.2s\tremaining: 1.61s\n",
      "851:\tlearn: 1940.9741803\ttotal: 9.21s\tremaining: 1.6s\n",
      "852:\tlearn: 1940.7585956\ttotal: 9.23s\tremaining: 1.59s\n",
      "853:\tlearn: 1940.5963465\ttotal: 9.24s\tremaining: 1.58s\n",
      "854:\tlearn: 1940.5007069\ttotal: 9.25s\tremaining: 1.57s\n",
      "855:\tlearn: 1940.2991495\ttotal: 9.26s\tremaining: 1.56s\n",
      "856:\tlearn: 1940.1703414\ttotal: 9.29s\tremaining: 1.55s\n",
      "857:\tlearn: 1940.0803649\ttotal: 9.3s\tremaining: 1.54s\n",
      "858:\tlearn: 1939.9493779\ttotal: 9.31s\tremaining: 1.53s\n",
      "859:\tlearn: 1939.7882331\ttotal: 9.32s\tremaining: 1.52s\n",
      "860:\tlearn: 1939.6573993\ttotal: 9.33s\tremaining: 1.51s\n",
      "861:\tlearn: 1939.5120145\ttotal: 9.34s\tremaining: 1.5s\n",
      "862:\tlearn: 1939.4484462\ttotal: 9.35s\tremaining: 1.48s\n",
      "863:\tlearn: 1939.3300557\ttotal: 9.37s\tremaining: 1.47s\n",
      "864:\tlearn: 1939.1722689\ttotal: 9.38s\tremaining: 1.46s\n",
      "865:\tlearn: 1939.0075069\ttotal: 9.39s\tremaining: 1.45s\n",
      "866:\tlearn: 1938.8596109\ttotal: 9.4s\tremaining: 1.44s\n",
      "867:\tlearn: 1938.5938401\ttotal: 9.4s\tremaining: 1.43s\n",
      "868:\tlearn: 1938.4388819\ttotal: 9.41s\tremaining: 1.42s\n",
      "869:\tlearn: 1938.2774763\ttotal: 9.42s\tremaining: 1.41s\n",
      "870:\tlearn: 1938.0868234\ttotal: 9.43s\tremaining: 1.4s\n",
      "871:\tlearn: 1937.9673961\ttotal: 9.44s\tremaining: 1.39s\n",
      "872:\tlearn: 1937.7132586\ttotal: 9.45s\tremaining: 1.37s\n",
      "873:\tlearn: 1937.4809679\ttotal: 9.46s\tremaining: 1.36s\n",
      "874:\tlearn: 1937.3404634\ttotal: 9.48s\tremaining: 1.35s\n",
      "875:\tlearn: 1937.1764107\ttotal: 9.49s\tremaining: 1.34s\n",
      "876:\tlearn: 1937.0962715\ttotal: 9.5s\tremaining: 1.33s\n",
      "877:\tlearn: 1936.9221928\ttotal: 9.51s\tremaining: 1.32s\n",
      "878:\tlearn: 1936.7371514\ttotal: 9.52s\tremaining: 1.31s\n",
      "879:\tlearn: 1936.5421496\ttotal: 9.53s\tremaining: 1.3s\n",
      "880:\tlearn: 1936.3606243\ttotal: 9.54s\tremaining: 1.29s\n",
      "881:\tlearn: 1936.2540906\ttotal: 9.55s\tremaining: 1.28s\n",
      "882:\tlearn: 1936.0668908\ttotal: 9.56s\tremaining: 1.27s\n",
      "883:\tlearn: 1935.8605502\ttotal: 9.58s\tremaining: 1.26s\n",
      "884:\tlearn: 1935.6762830\ttotal: 9.59s\tremaining: 1.25s\n",
      "885:\tlearn: 1935.4821224\ttotal: 9.6s\tremaining: 1.24s\n",
      "886:\tlearn: 1935.3910072\ttotal: 9.61s\tremaining: 1.22s\n",
      "887:\tlearn: 1935.2182056\ttotal: 9.62s\tremaining: 1.21s\n",
      "888:\tlearn: 1935.0766197\ttotal: 9.63s\tremaining: 1.2s\n",
      "889:\tlearn: 1934.7279479\ttotal: 9.63s\tremaining: 1.19s\n",
      "890:\tlearn: 1934.5608605\ttotal: 9.64s\tremaining: 1.18s\n",
      "891:\tlearn: 1934.3939914\ttotal: 9.65s\tremaining: 1.17s\n",
      "892:\tlearn: 1934.2270914\ttotal: 9.69s\tremaining: 1.16s\n",
      "893:\tlearn: 1934.0013798\ttotal: 9.7s\tremaining: 1.15s\n",
      "894:\tlearn: 1933.8893860\ttotal: 9.72s\tremaining: 1.14s\n",
      "895:\tlearn: 1933.7420563\ttotal: 9.75s\tremaining: 1.13s\n",
      "896:\tlearn: 1933.5432616\ttotal: 9.79s\tremaining: 1.12s\n",
      "897:\tlearn: 1933.3733822\ttotal: 9.81s\tremaining: 1.11s\n",
      "898:\tlearn: 1933.2327784\ttotal: 9.83s\tremaining: 1.1s\n",
      "899:\tlearn: 1933.0152663\ttotal: 9.87s\tremaining: 1.1s\n",
      "900:\tlearn: 1932.9035555\ttotal: 9.88s\tremaining: 1.08s\n",
      "901:\tlearn: 1932.7528673\ttotal: 9.9s\tremaining: 1.07s\n",
      "902:\tlearn: 1932.6334044\ttotal: 9.92s\tremaining: 1.06s\n",
      "903:\tlearn: 1932.4714932\ttotal: 9.94s\tremaining: 1.05s\n",
      "904:\tlearn: 1932.2909234\ttotal: 9.96s\tremaining: 1.04s\n",
      "905:\tlearn: 1932.0589172\ttotal: 9.98s\tremaining: 1.03s\n",
      "906:\tlearn: 1931.9719387\ttotal: 10s\tremaining: 1.02s\n",
      "907:\tlearn: 1931.8779141\ttotal: 10s\tremaining: 1.01s\n",
      "908:\tlearn: 1931.7542174\ttotal: 10s\tremaining: 1s\n",
      "909:\tlearn: 1931.6514034\ttotal: 10.1s\tremaining: 994ms\n",
      "910:\tlearn: 1931.3245886\ttotal: 10.1s\tremaining: 984ms\n",
      "911:\tlearn: 1931.2204462\ttotal: 10.1s\tremaining: 974ms\n",
      "912:\tlearn: 1931.0030423\ttotal: 10.1s\tremaining: 964ms\n",
      "913:\tlearn: 1930.9232955\ttotal: 10.1s\tremaining: 955ms\n",
      "914:\tlearn: 1930.7181959\ttotal: 10.2s\tremaining: 944ms\n",
      "915:\tlearn: 1930.6038675\ttotal: 10.2s\tremaining: 934ms\n",
      "916:\tlearn: 1930.4699931\ttotal: 10.2s\tremaining: 924ms\n",
      "917:\tlearn: 1930.2570957\ttotal: 10.2s\tremaining: 914ms\n",
      "918:\tlearn: 1930.1052000\ttotal: 10.2s\tremaining: 903ms\n",
      "919:\tlearn: 1929.9509723\ttotal: 10.3s\tremaining: 892ms\n",
      "920:\tlearn: 1929.8434874\ttotal: 10.3s\tremaining: 881ms\n",
      "921:\tlearn: 1929.6883877\ttotal: 10.3s\tremaining: 870ms\n",
      "922:\tlearn: 1929.4703268\ttotal: 10.3s\tremaining: 859ms\n",
      "923:\tlearn: 1929.2876439\ttotal: 10.3s\tremaining: 848ms\n",
      "924:\tlearn: 1929.1666192\ttotal: 10.3s\tremaining: 836ms\n",
      "925:\tlearn: 1929.0260493\ttotal: 10.3s\tremaining: 825ms\n",
      "926:\tlearn: 1928.7332310\ttotal: 10.3s\tremaining: 813ms\n",
      "927:\tlearn: 1928.6144602\ttotal: 10.3s\tremaining: 802ms\n",
      "928:\tlearn: 1928.3860629\ttotal: 10.3s\tremaining: 791ms\n",
      "929:\tlearn: 1928.2968494\ttotal: 10.4s\tremaining: 779ms\n",
      "930:\tlearn: 1928.1639919\ttotal: 10.4s\tremaining: 768ms\n",
      "931:\tlearn: 1928.0285389\ttotal: 10.4s\tremaining: 757ms\n",
      "932:\tlearn: 1927.8850567\ttotal: 10.4s\tremaining: 746ms\n",
      "933:\tlearn: 1927.7560264\ttotal: 10.4s\tremaining: 734ms\n",
      "934:\tlearn: 1927.6611287\ttotal: 10.4s\tremaining: 723ms\n",
      "935:\tlearn: 1927.4873103\ttotal: 10.4s\tremaining: 712ms\n",
      "936:\tlearn: 1927.2970412\ttotal: 10.4s\tremaining: 701ms\n",
      "937:\tlearn: 1927.1936575\ttotal: 10.4s\tremaining: 690ms\n",
      "938:\tlearn: 1927.0012196\ttotal: 10.5s\tremaining: 679ms\n",
      "939:\tlearn: 1926.7869789\ttotal: 10.5s\tremaining: 668ms\n",
      "940:\tlearn: 1926.6360520\ttotal: 10.5s\tremaining: 657ms\n",
      "941:\tlearn: 1926.4805996\ttotal: 10.5s\tremaining: 646ms\n",
      "942:\tlearn: 1926.3617478\ttotal: 10.5s\tremaining: 635ms\n",
      "943:\tlearn: 1926.2259902\ttotal: 10.5s\tremaining: 623ms\n",
      "944:\tlearn: 1926.1114339\ttotal: 10.5s\tremaining: 612ms\n",
      "945:\tlearn: 1925.9051410\ttotal: 10.5s\tremaining: 602ms\n",
      "946:\tlearn: 1925.7253652\ttotal: 10.6s\tremaining: 591ms\n",
      "947:\tlearn: 1925.5642404\ttotal: 10.6s\tremaining: 580ms\n",
      "948:\tlearn: 1925.4605016\ttotal: 10.6s\tremaining: 569ms\n",
      "949:\tlearn: 1925.3725206\ttotal: 10.6s\tremaining: 558ms\n",
      "950:\tlearn: 1925.2285730\ttotal: 10.6s\tremaining: 546ms\n",
      "951:\tlearn: 1924.9660068\ttotal: 10.6s\tremaining: 535ms\n",
      "952:\tlearn: 1924.8240936\ttotal: 10.6s\tremaining: 524ms\n",
      "953:\tlearn: 1924.6283963\ttotal: 10.6s\tremaining: 512ms\n",
      "954:\tlearn: 1924.4810706\ttotal: 10.6s\tremaining: 501ms\n",
      "955:\tlearn: 1924.2831169\ttotal: 10.6s\tremaining: 490ms\n",
      "956:\tlearn: 1924.0875402\ttotal: 10.6s\tremaining: 479ms\n",
      "957:\tlearn: 1923.9477799\ttotal: 10.7s\tremaining: 467ms\n",
      "958:\tlearn: 1923.8872199\ttotal: 10.7s\tremaining: 456ms\n",
      "959:\tlearn: 1923.7153321\ttotal: 10.7s\tremaining: 445ms\n",
      "960:\tlearn: 1923.4277375\ttotal: 10.7s\tremaining: 433ms\n",
      "961:\tlearn: 1923.3327926\ttotal: 10.7s\tremaining: 422ms\n",
      "962:\tlearn: 1923.1737692\ttotal: 10.7s\tremaining: 411ms\n",
      "963:\tlearn: 1923.0449919\ttotal: 10.7s\tremaining: 400ms\n",
      "964:\tlearn: 1922.9846007\ttotal: 10.7s\tremaining: 388ms\n",
      "965:\tlearn: 1922.8780280\ttotal: 10.7s\tremaining: 377ms\n",
      "966:\tlearn: 1922.6254397\ttotal: 10.7s\tremaining: 366ms\n",
      "967:\tlearn: 1922.4397846\ttotal: 10.7s\tremaining: 355ms\n",
      "968:\tlearn: 1922.2138066\ttotal: 10.7s\tremaining: 343ms\n",
      "969:\tlearn: 1921.9337008\ttotal: 10.7s\tremaining: 332ms\n",
      "970:\tlearn: 1921.7906946\ttotal: 10.8s\tremaining: 321ms\n",
      "971:\tlearn: 1921.7126376\ttotal: 10.8s\tremaining: 310ms\n",
      "972:\tlearn: 1921.5600197\ttotal: 10.8s\tremaining: 299ms\n",
      "973:\tlearn: 1921.3397470\ttotal: 10.8s\tremaining: 288ms\n",
      "974:\tlearn: 1921.2436884\ttotal: 10.8s\tremaining: 276ms\n",
      "975:\tlearn: 1921.1258896\ttotal: 10.8s\tremaining: 265ms\n",
      "976:\tlearn: 1920.9747540\ttotal: 10.8s\tremaining: 254ms\n",
      "977:\tlearn: 1920.8470001\ttotal: 10.8s\tremaining: 243ms\n",
      "978:\tlearn: 1920.6402792\ttotal: 10.8s\tremaining: 232ms\n",
      "979:\tlearn: 1920.3740090\ttotal: 10.8s\tremaining: 221ms\n",
      "980:\tlearn: 1920.1938265\ttotal: 10.8s\tremaining: 210ms\n",
      "981:\tlearn: 1919.9689747\ttotal: 10.8s\tremaining: 199ms\n",
      "982:\tlearn: 1919.8706269\ttotal: 10.9s\tremaining: 188ms\n",
      "983:\tlearn: 1919.7565475\ttotal: 10.9s\tremaining: 177ms\n",
      "984:\tlearn: 1919.6352317\ttotal: 10.9s\tremaining: 166ms\n",
      "985:\tlearn: 1919.5075195\ttotal: 10.9s\tremaining: 154ms\n",
      "986:\tlearn: 1919.3641720\ttotal: 10.9s\tremaining: 143ms\n",
      "987:\tlearn: 1919.2397893\ttotal: 10.9s\tremaining: 132ms\n",
      "988:\tlearn: 1919.1609552\ttotal: 10.9s\tremaining: 121ms\n",
      "989:\tlearn: 1918.9646142\ttotal: 10.9s\tremaining: 110ms\n",
      "990:\tlearn: 1918.8652741\ttotal: 10.9s\tremaining: 99.2ms\n",
      "991:\tlearn: 1918.6522059\ttotal: 10.9s\tremaining: 88.2ms\n",
      "992:\tlearn: 1918.4501828\ttotal: 10.9s\tremaining: 77.1ms\n",
      "993:\tlearn: 1918.2804294\ttotal: 10.9s\tremaining: 66.1ms\n",
      "994:\tlearn: 1918.1786194\ttotal: 11s\tremaining: 55.1ms\n",
      "995:\tlearn: 1918.0070176\ttotal: 11s\tremaining: 44ms\n",
      "996:\tlearn: 1917.8290348\ttotal: 11s\tremaining: 33ms\n",
      "997:\tlearn: 1917.7554269\ttotal: 11s\tremaining: 22ms\n",
      "998:\tlearn: 1917.6124109\ttotal: 11s\tremaining: 11ms\n",
      "999:\tlearn: 1917.4469186\ttotal: 11s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1e98b877bb0>"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "cb = CatBoostRegressor()\n",
    "cb.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "eb9e1116-2952-4b24-a02e-d8ff95705e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1104.80749\n",
      "R2-Score : 0.64689\n"
     ]
    }
   ],
   "source": [
    "pred = cb.predict(test_x)\n",
    "cb_rmse, cb_r2 = pred_result(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "e01ff0fd-8033-455f-a095-21c22af817a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "cb.best_iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "7589e942-e014-422d-baba-148093c8a7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-79 {color: black;background-color: white;}#sk-container-id-79 pre{padding: 0;}#sk-container-id-79 div.sk-toggleable {background-color: white;}#sk-container-id-79 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-79 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-79 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-79 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-79 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-79 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-79 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-79 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-79 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-79 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-79 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-79 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-79 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-79 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-79 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-79 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-79 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-79 div.sk-item {position: relative;z-index: 1;}#sk-container-id-79 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-79 div.sk-item::before, #sk-container-id-79 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-79 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-79 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-79 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-79 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-79 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-79 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-79 div.sk-label-container {text-align: center;}#sk-container-id-79 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-79 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-79\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" checked><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostRegressor()"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "abr = AdaBoostRegressor()\n",
    "abr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "e4e136f6-7717-43c0-bf1e-d9c15cf07b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1771.76785\n",
      "R2-Score : 0.09187\n"
     ]
    }
   ],
   "source": [
    "pred = abr.predict(test_x)\n",
    "abr_rmse, abr_r2 = pred_result(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "90ae5c1b-3794-4524-b851-bbcc55674ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = abr.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eca3e5-9456-4d8c-a0b9-0644c34254f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "a4b6d777-1dcc-42ac-b977-139d952bdddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1067.66336\n",
      "R2-Score : 0.67023\n"
     ]
    }
   ],
   "source": [
    "# 아래에 실습코드를 작성하세요.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train_x, train_y)\n",
    "pred = lr.predict(test_x)\n",
    "lr_rmse, lr_r2 = pred_result(test_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "ff1065ce-8dde-4c5c-a24e-73d2f6e729a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "1b9ff498-0b2d-41a3-8a22-1004233f410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.reshape(1,1416)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "85893dbf-060b-453f-8149-630dabb8f965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39775.28513106, 39460.3652098 , 39390.06196867, ...,\n",
       "       36777.8716363 , 37014.01576875, 39443.27770107])"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "67d9fe84-f70e-413b-8e6f-bc3f0e81bd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39775.285131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39460.365210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>39390.061969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>39353.077092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>39435.115663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>1411</td>\n",
       "      <td>36310.297035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>1412</td>\n",
       "      <td>36136.104770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>1413</td>\n",
       "      <td>36777.871636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>1414</td>\n",
       "      <td>37014.015769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>1415</td>\n",
       "      <td>39443.277701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1416 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         count\n",
       "0        0  39775.285131\n",
       "1        1  39460.365210\n",
       "2        2  39390.061969\n",
       "3        3  39353.077092\n",
       "4        4  39435.115663\n",
       "...    ...           ...\n",
       "1411  1411  36310.297035\n",
       "1412  1412  36136.104770\n",
       "1413  1413  36777.871636\n",
       "1414  1414  37014.015769\n",
       "1415  1415  39443.277701\n",
       "\n",
       "[1416 rows x 2 columns]"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({'id' : range(0, 1416),\n",
    "                          'count' : pred})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "d7e8eaac-2a77-4433-9c6c-b9d3c06817da",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_lr_236_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "ae250b3c-6519-44a1-8d23-1294df150719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1968, '4m'), (1854, '6m'), (1848, '3m'), (1830, '2m')]"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(lgbm.feature_importances_,list(train_x.columns))),reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "843f8377-81ed-4c6a-a3dc-57dab9d1dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['lr', 'lgbm', 'cb', 'rf', 'gbr']\n",
    "model = [lr, lgbm, 'CatBoostRegressor()', rf, gbr]\n",
    "rmse = [lr_rmse, lgbm_rmse, cb_rmse, rf_rmse, gbr_rmse]\n",
    "r2 = [lr_r2, lgbm_r2, cb_r2, rf_r2, gbr_r2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "55cf12f6-c1cb-48ac-9ba1-ed38f11965b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'model' : name,\n",
    "                      'hyperparameter' : model,\n",
    "                      'rmse' : rmse,\n",
    "                      'r2-score' : r2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "f808e711-c429-4511-9311-34cb960a1bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>hyperparameter</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>1067.66336</td>\n",
       "      <td>0.67023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gbr</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>1090.94316</td>\n",
       "      <td>0.65570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>LGBMRegressor(learning_rate=0.08, min_data_in_...</td>\n",
       "      <td>1103.17873</td>\n",
       "      <td>0.64793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cb</td>\n",
       "      <td>CatBoostRegressor()</td>\n",
       "      <td>1104.80749</td>\n",
       "      <td>0.64689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf</td>\n",
       "      <td>(DecisionTreeRegressor(max_features=1.0, rando...</td>\n",
       "      <td>1210.48582</td>\n",
       "      <td>0.57611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model                                     hyperparameter        rmse  \\\n",
       "0    lr                                 LinearRegression()  1067.66336   \n",
       "1   gbr  ([DecisionTreeRegressor(criterion='friedman_ms...  1090.94316   \n",
       "2  lgbm  LGBMRegressor(learning_rate=0.08, min_data_in_...  1103.17873   \n",
       "3    cb                                CatBoostRegressor()  1104.80749   \n",
       "4    rf  (DecisionTreeRegressor(max_features=1.0, rando...  1210.48582   \n",
       "\n",
       "   r2-score  \n",
       "0   0.67023  \n",
       "1   0.65570  \n",
       "2   0.64793  \n",
       "3   0.64689  \n",
       "4   0.57611  "
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values('rmse').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "90b79403-3a45-401e-aec8-a4924f9f3bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "e6011cea-cd62-4d8c-a2ec-1111665abf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8acdf6-071b-4a24-be2f-10285cb2f06b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
