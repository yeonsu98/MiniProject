{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> [3단계] AI 모델링\n",
    "---\n",
    "\n",
    "## 1, 2 단계에서 진행하신 내용을 아래에 그대로 진행해주세요.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Step 0. 라이브러리 import 및 데이터 불러오기\n",
    "### **가. 라이브러리 import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow 설치하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터 프레임 관련 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **나.  학습데이터 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_len</th>\n",
       "      <th>url_num_hyphens_dom</th>\n",
       "      <th>url_path_len</th>\n",
       "      <th>url_domain_len</th>\n",
       "      <th>url_hostname_len</th>\n",
       "      <th>url_num_dots</th>\n",
       "      <th>url_num_underscores</th>\n",
       "      <th>url_query_len</th>\n",
       "      <th>url_num_query_para</th>\n",
       "      <th>url_ip_present</th>\n",
       "      <th>...</th>\n",
       "      <th>html_num_tags('embed')</th>\n",
       "      <th>html_num_tags('object')</th>\n",
       "      <th>html_num_tags('div')</th>\n",
       "      <th>html_num_tags('head')</th>\n",
       "      <th>html_num_tags('body')</th>\n",
       "      <th>html_num_tags('form')</th>\n",
       "      <th>html_num_tags('a')</th>\n",
       "      <th>Result_v1</th>\n",
       "      <th>hyphens_ratio</th>\n",
       "      <th>total_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>665.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_len  url_num_hyphens_dom  url_path_len  url_domain_len  \\\n",
       "0     23.0                  0.0           8.0            15.0   \n",
       "1     75.0                  0.0          58.0            17.0   \n",
       "2     20.0                  0.0           4.0            16.0   \n",
       "3     27.0                  0.0          13.0            14.0   \n",
       "4     39.0                  2.0          12.0            27.0   \n",
       "\n",
       "   url_hostname_len  url_num_dots  url_num_underscores  url_query_len  \\\n",
       "0              15.0           2.0                  0.0            0.0   \n",
       "1              17.0           6.0                  0.0            0.0   \n",
       "2              16.0           2.0                  0.0            0.0   \n",
       "3              14.0           3.0                  0.0            0.0   \n",
       "4              27.0           2.0                  0.0            0.0   \n",
       "\n",
       "   url_num_query_para  url_ip_present  ...  html_num_tags('embed')  \\\n",
       "0                 0.0             0.0  ...                     0.0   \n",
       "1                 0.0             0.0  ...                     0.0   \n",
       "2                 0.0             0.0  ...                     0.0   \n",
       "3                 0.0             0.0  ...                     0.0   \n",
       "4                 0.0             0.0  ...                     0.0   \n",
       "\n",
       "   html_num_tags('object')  html_num_tags('div')  html_num_tags('head')  \\\n",
       "0                      0.0                   0.0                    1.0   \n",
       "1                      0.0                  20.0                    1.0   \n",
       "2                      0.0                 101.0                    1.0   \n",
       "3                      0.0                 151.0                    1.0   \n",
       "4                      0.0                 332.0                    1.0   \n",
       "\n",
       "   html_num_tags('body')  html_num_tags('form')  html_num_tags('a')  \\\n",
       "0                    1.0                    0.0                 0.0   \n",
       "1                    1.0                    0.0                21.0   \n",
       "2                    1.0                    3.0                70.0   \n",
       "3                    1.0                    1.0                55.0   \n",
       "4                    1.0                    0.0               321.0   \n",
       "\n",
       "   Result_v1  hyphens_ratio  total_tag  \n",
       "0         -1       0.000000        9.0  \n",
       "1          1       0.000000       61.0  \n",
       "2          1       0.000000      210.0  \n",
       "3          1       0.000000      224.0  \n",
       "4          1       0.074074      665.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_len</th>\n",
       "      <th>url_num_hyphens_dom</th>\n",
       "      <th>url_path_len</th>\n",
       "      <th>url_domain_len</th>\n",
       "      <th>url_hostname_len</th>\n",
       "      <th>url_num_dots</th>\n",
       "      <th>url_num_underscores</th>\n",
       "      <th>url_query_len</th>\n",
       "      <th>url_num_query_para</th>\n",
       "      <th>url_ip_present</th>\n",
       "      <th>...</th>\n",
       "      <th>html_num_tags('embed')</th>\n",
       "      <th>html_num_tags('object')</th>\n",
       "      <th>html_num_tags('div')</th>\n",
       "      <th>html_num_tags('head')</th>\n",
       "      <th>html_num_tags('body')</th>\n",
       "      <th>html_num_tags('form')</th>\n",
       "      <th>html_num_tags('a')</th>\n",
       "      <th>Result_v1</th>\n",
       "      <th>hyphens_ratio</th>\n",
       "      <th>total_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>665.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_len  url_num_hyphens_dom  url_path_len  url_domain_len  \\\n",
       "0     23.0                  0.0           8.0            15.0   \n",
       "1     75.0                  0.0          58.0            17.0   \n",
       "2     20.0                  0.0           4.0            16.0   \n",
       "3     27.0                  0.0          13.0            14.0   \n",
       "4     39.0                  2.0          12.0            27.0   \n",
       "\n",
       "   url_hostname_len  url_num_dots  url_num_underscores  url_query_len  \\\n",
       "0              15.0           2.0                  0.0            0.0   \n",
       "1              17.0           6.0                  0.0            0.0   \n",
       "2              16.0           2.0                  0.0            0.0   \n",
       "3              14.0           3.0                  0.0            0.0   \n",
       "4              27.0           2.0                  0.0            0.0   \n",
       "\n",
       "   url_num_query_para  url_ip_present  ...  html_num_tags('embed')  \\\n",
       "0                 0.0             0.0  ...                     0.0   \n",
       "1                 0.0             0.0  ...                     0.0   \n",
       "2                 0.0             0.0  ...                     0.0   \n",
       "3                 0.0             0.0  ...                     0.0   \n",
       "4                 0.0             0.0  ...                     0.0   \n",
       "\n",
       "   html_num_tags('object')  html_num_tags('div')  html_num_tags('head')  \\\n",
       "0                      0.0                   0.0                    1.0   \n",
       "1                      0.0                  20.0                    1.0   \n",
       "2                      0.0                 101.0                    1.0   \n",
       "3                      0.0                 151.0                    1.0   \n",
       "4                      0.0                 332.0                    1.0   \n",
       "\n",
       "   html_num_tags('body')  html_num_tags('form')  html_num_tags('a')  \\\n",
       "0                    1.0                    0.0                 0.0   \n",
       "1                    1.0                    0.0                21.0   \n",
       "2                    1.0                    3.0                70.0   \n",
       "3                    1.0                    1.0                55.0   \n",
       "4                    1.0                    0.0               321.0   \n",
       "\n",
       "   Result_v1  hyphens_ratio  total_tag  \n",
       "0         -1       0.000000        9.0  \n",
       "1          1       0.000000       61.0  \n",
       "2          1       0.000000      210.0  \n",
       "3          1       0.000000      224.0  \n",
       "4          1       0.074074      665.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('data1.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['hyphens_ratio', 'total_tag'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **다.  데이터 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y 분할\n",
    "target = 'Result_v1'\n",
    "\n",
    "x = df.drop(target, axis=1)\n",
    "y = df.loc[:, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.map({-1 : 1, 1 : 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **라. train_test_split을 이용하여 train/test  데이터 분리**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split 사용\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train_s = scaler.fit_transform(x_train)\n",
    "x_val_s = scaler.transform(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **마. Confusion Matrix 함수 정의**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix란 Training 을 통한 Prediction 성능을 측정하기 위해 예측 value와 실제 value를 비교하기 위한 표입니다.\n",
    "#### 아래 함수는 이번 과제에서 confusion matrix 결과를 보기 쉽게 표현한 것으로 사용 예를 참고하여 모델 결과 확인에 사용하시기 바랍니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:green\">[참고링크] 공식 Document**</span>\n",
    " \n",
    "* confusion matrix(https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report as creport\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(ax, matrix, labels = ['malicious','benign'], title='Confusion matrix', fontsize=9):\n",
    "    ax.set_xticks([x for x in range(len(labels))])\n",
    "    ax.set_yticks([y for y in range(len(labels))])\n",
    "\n",
    "    # Place labels on minor ticks\n",
    "    ax.set_xticks([x + 0.5 for x in range(len(labels))], minor=True)\n",
    "    ax.set_xticklabels(labels, rotation='90', fontsize=fontsize, minor=True)\n",
    "    ax.set_yticks([y + 0.5 for y in range(len(labels))], minor=True)\n",
    "    ax.set_yticklabels(labels[::-1], fontsize=fontsize, minor=True)\n",
    "\n",
    "    # Hide major tick labels\n",
    "    ax.tick_params(which='major', labelbottom='off', labelleft='off')\n",
    "\n",
    "    # Finally, hide minor tick marks\n",
    "    ax.tick_params(which='minor', width=0)\n",
    "\n",
    "    # Plot heat map\n",
    "    proportions = [1. * row / sum(row) for row in matrix]\n",
    "    ax.pcolor(np.array(proportions[::-1]), cmap=plt.cm.Blues)\n",
    "\n",
    "    # Plot counts as text\n",
    "    for row in range(len(matrix)):\n",
    "        for col in range(len(matrix[row])):\n",
    "            confusion = matrix[::-1][row][col]\n",
    "            if confusion != 0:\n",
    "                ax.text(col + 0.5, row + 0.5, int(confusion),\n",
    "                        fontsize=fontsize,\n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center')\n",
    "\n",
    "    # Add finishing touches\n",
    "    ax.grid(True, linestyle=':')\n",
    "    ax.set_title(title, fontsize=fontsize)\n",
    "    ax.set_xlabel('prediction', fontsize=fontsize)\n",
    "    ax.set_ylabel('actual', fontsize=fontsize)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">[예시] Confusion Matrix 사용 방법<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 샘플\n",
    "#### > confusion = confusion_matrix(test_y, dt_pred)\n",
    "#### > fig, ax = plt.subplots(figsize=(10,3))\n",
    "#### > plot_confusion_matrix(ax, confusion, fontsize=30)\n"
   ]
  },
  {
   "attachments": {
    "2d1c1b93-2db6-45e4-91b4-cee7ea6ef268.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![confusion_matrix.png](attachment:2d1c1b93-2db6-45e4-91b4-cee7ea6ef268.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Q. AI 분류 모델 만들기\n",
    "\n",
    "* 전처리한 데이터셋을 활용해 악성사이트 여부를 판별하는 AI 분류 모델을 <font color=\"red\">최소 3개 이상 </font>만들어보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.선언 \n",
    "params = {'max_depth' : range(3, 11), 'n_estimators' : range(20, 200, 10), \n",
    "          'learning_rate' : [0.01, 0.02, 0.03, 0.1, 0.2]}\n",
    "xgb = XGBClassifier()\n",
    "model_xgb = GridSearchCV(xgb, params, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=20; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=80; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=120; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=130; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=130; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=140; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=170; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=180; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=180; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=180; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=180; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=190; total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=190; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=60; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=90; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=90; total time=   1.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=110; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=110; total time=   1.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=120; total time=   2.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=120; total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=120; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=120; total time=   1.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=130; total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=130; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=130; total time=   1.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=130; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=130; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=140; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=140; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=140; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=140; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=150; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=150; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=150; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=160; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=160; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=170; total time=   1.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=170; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=180; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=180; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=190; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=190; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=190; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=190; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=40; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=70; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=80; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=110; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=110; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=130; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=130; total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=160; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=170; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=180; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=180; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=180; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=180; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=190; total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=190; total time=   1.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=190; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=190; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=90; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=120; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=130; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=140; total time=   1.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=140; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=160; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=160; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=170; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=170; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=190; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=60; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=60; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=60; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=70; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=70; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=80; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=80; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=80; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=80; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=110; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=110; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=130; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=130; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=130; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=130; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=140; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=140; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=140; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=140; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=150; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=150; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=150; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=160; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=160; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=170; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=170; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=170; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=170; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=180; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=180; total time=   1.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=180; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=190; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=190; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=190; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=190; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=50; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=60; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=80; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=80; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=90; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=110; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=110; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=120; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=120; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=130; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=130; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=140; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=140; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=140; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=140; total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=140; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=150; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=150; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=150; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=150; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=150; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=160; total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=160; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=160; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=160; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=160; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=170; total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=170; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=180; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=180; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=180; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=180; total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=180; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=190; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=190; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=190; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=190; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=190; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=20; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=60; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=60; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=60; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=90; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=100; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=100; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=110; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=110; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=130; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=130; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=130; total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=130; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=130; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=140; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=140; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=140; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=140; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=140; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=150; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=150; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=150; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=150; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=160; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=160; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=160; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=160; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=160; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=170; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=170; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=170; total time=   1.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=170; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=180; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=180; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=180; total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=190; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=190; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=190; total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=190; total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=190; total time=   1.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=20; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=20; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=20; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=40; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=40; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=60; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=60; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=60; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=60; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=60; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=70; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=80; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=80; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=80; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=80; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=110; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=110; total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=110; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=110; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=110; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=120; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=120; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=130; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=130; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=130; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=130; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=130; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=140; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=140; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=140; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=140; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=140; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=150; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=150; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=150; total time=   1.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=160; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=160; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=160; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=160; total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=160; total time=   1.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=170; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=170; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=170; total time=   1.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=170; total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=170; total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=180; total time=   3.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=180; total time=   3.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=180; total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=180; total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=180; total time=   1.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=190; total time=   1.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=190; total time=   2.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=190; total time=   2.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=190; total time=   8.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=190; total time=   7.9s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=20; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=20; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=20; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=30; total time=   1.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=30; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=30; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=30; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=30; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=70; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=80; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=90; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=110; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=120; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=130; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=140; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=140; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=140; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=140; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=150; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=160; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=180; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=180; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=190; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=190; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=90; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=90; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=90; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=90; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=110; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=110; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=110; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=110; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=110; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=120; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=120; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=120; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=130; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=130; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=140; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=160; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=160; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=160; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=170; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=170; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=170; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=180; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=190; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=190; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=190; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=190; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=190; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=80; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=150; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=160; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=180; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=190; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=190; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=190; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=190; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=20; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=70; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=130; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=150; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=160; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=170; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=180; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=180; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=180; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=190; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=190; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=40; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=100; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=110; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=120; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=120; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=120; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=130; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=140; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=140; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=150; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=150; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=160; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=160; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=160; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=170; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=170; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=180; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=180; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=190; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=20; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=20; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=20; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=40; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=40; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=40; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=40; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=60; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=90; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=90; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=90; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=90; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=100; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=100; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=110; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=110; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=110; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=120; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=120; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=130; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=140; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=140; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=140; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=140; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=140; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=150; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=150; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=160; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=160; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=160; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=160; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=160; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=170; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=180; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=180; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=180; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=180; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=190; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=190; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=190; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=190; total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=190; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=50; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=60; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=60; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=60; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=70; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=70; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=80; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=90; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=90; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=90; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=100; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=100; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=100; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=100; total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=110; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=110; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=110; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=110; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=120; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=120; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=130; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=130; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=130; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=130; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=140; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=140; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=140; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=140; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=140; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=150; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=150; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=150; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=150; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=160; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=160; total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=160; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=160; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=160; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=170; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=170; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=170; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=170; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=180; total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=180; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=180; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=190; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=190; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=190; total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=190; total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=190; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=30; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=30; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=30; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=60; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=60; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=70; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=70; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=80; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=90; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=90; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=100; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=110; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=110; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=110; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=110; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=110; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=120; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=120; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=130; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=130; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=130; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=130; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=140; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=140; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=140; total time=   1.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=140; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=140; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=150; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=150; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=150; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=160; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=160; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=160; total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=160; total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=160; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=170; total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=170; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=170; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=170; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=170; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=180; total time=   1.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=180; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=180; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=180; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=180; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=190; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=190; total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=190; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=190; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=190; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=150; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=150; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=150; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=160; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=160; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=170; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=170; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=180; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=90; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=90; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=90; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=100; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=110; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=120; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=160; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=160; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=160; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=170; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=170; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=170; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=180; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=190; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=190; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=190; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=190; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=190; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=120; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=120; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=130; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=140; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=150; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=160; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=170; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=180; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=180; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=180; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=180; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=190; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=190; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=190; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=190; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=90; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=100; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=130; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=130; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=130; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=140; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=150; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=160; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=170; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=170; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=180; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=190; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=190; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=20; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=70; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=80; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=80; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=90; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=100; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=120; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=130; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=140; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=150; total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=150; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=150; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=160; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=170; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=170; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=170; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=180; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=190; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=190; total time=   1.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=60; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=60; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=60; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=90; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=90; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=120; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=120; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=140; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=140; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=140; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=140; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=140; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=150; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=150; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=150; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=160; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=160; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=160; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=170; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=170; total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=180; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=180; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=190; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=190; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=190; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=40; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=40; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=60; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=80; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=100; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=130; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=130; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=130; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=130; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=130; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=140; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=140; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=140; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=140; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=140; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=150; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=150; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=150; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=150; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=160; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=160; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=160; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=160; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=170; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=170; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=170; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=170; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=170; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=180; total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=180; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=190; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=190; total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=190; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=190; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=190; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=40; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=40; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=70; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=70; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=70; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=80; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=100; total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=110; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=110; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=120; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=120; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=130; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=130; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=130; total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=130; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=130; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=140; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=140; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=140; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=140; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=140; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=160; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=160; total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=160; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=160; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=160; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=170; total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=170; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=170; total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=170; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=170; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=180; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=180; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=180; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=180; total time=   1.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=180; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=190; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=190; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=190; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=190; total time=   1.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=190; total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=60; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=60; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=60; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=60; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=70; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=110; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=120; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=130; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=140; total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=140; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=140; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=160; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=70; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=70; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=110; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=120; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=130; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=140; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=150; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=150; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=160; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=160; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=160; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=160; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=170; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=180; total time=   1.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=180; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=190; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=190; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=190; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=190; total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=190; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=60; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=60; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=120; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=120; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=130; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=150; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=150; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=150; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=150; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=160; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=160; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=160; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=160; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=170; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=180; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=180; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=180; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=180; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=190; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=190; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=190; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=190; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=190; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=80; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=90; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=110; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=110; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=130; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=130; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=130; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=130; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=150; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=150; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=160; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=170; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=170; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=170; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=180; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=190; total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=190; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=60; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=110; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=110; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=120; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=120; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=130; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=140; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=140; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=150; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=160; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=160; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=160; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=160; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=170; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=170; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=180; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=180; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=190; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=190; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=190; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=60; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=70; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=90; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=120; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=120; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=130; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=140; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=140; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=140; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=150; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=150; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=150; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=160; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=160; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=170; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=170; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=170; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=180; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=180; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=180; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=180; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=190; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=190; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=190; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=40; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=40; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=80; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=110; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=120; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=130; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=140; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=150; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=150; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=150; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=150; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=150; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=160; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=160; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=160; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=170; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=170; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=170; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=180; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=180; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=190; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=190; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=190; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=190; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=30; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=30; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=70; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=110; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=110; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=120; total time=   1.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=120; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=130; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=130; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=130; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=130; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=130; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=140; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=140; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=140; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=140; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=140; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=150; total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=150; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=150; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=160; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=160; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=160; total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=160; total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=160; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=170; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=170; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=170; total time=   1.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=170; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=180; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=180; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=180; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=180; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=180; total time=   1.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=190; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=190; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=190; total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=190; total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=190; total time=   1.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=80; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=110; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=110; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=120; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=130; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=130; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=140; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=140; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=160; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=170; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=170; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=170; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=170; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=180; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=180; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=180; total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=180; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=190; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=190; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=190; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=30; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=40; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=40; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=90; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=110; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=120; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=120; total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=120; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=140; total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=140; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=150; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=150; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=160; total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=170; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=170; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=180; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=180; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=180; total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=190; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=190; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=190; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=20; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=30; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=30; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=70; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=70; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=80; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=80; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=130; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=150; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=150; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=170; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=170; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=180; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=180; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=180; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=190; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=190; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=190; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=190; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=20; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=30; total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=30; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=70; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=120; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=130; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=150; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=150; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=170; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=170; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=170; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=180; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=180; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=190; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=190; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=30; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=30; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=40; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=60; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=70; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=80; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=80; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=80; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=90; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=90; total time=   1.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=90; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=110; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=130; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=130; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=130; total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=130; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=140; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=140; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=140; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=140; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=150; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=150; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=150; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=150; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=160; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=160; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=170; total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=170; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=170; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=170; total time=   1.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=170; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=180; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=180; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=190; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=190; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=40; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=40; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=40; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=50; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=50; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=50; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=50; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=50; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=60; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=70; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=70; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=70; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=80; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=90; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=100; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=120; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=120; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=120; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=140; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=140; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=140; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=140; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=150; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=150; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=150; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=150; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=160; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=160; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=170; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=170; total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=170; total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=170; total time=   2.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=180; total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=180; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=180; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=190; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=190; total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=190; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=20; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=40; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=40; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=40; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=50; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=50; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=50; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=60; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=60; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=70; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=80; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=80; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=90; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=90; total time=   1.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=90; total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=110; total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=110; total time=   2.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=110; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=110; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=120; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=120; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=140; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=140; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=140; total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=140; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=150; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=150; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=150; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=150; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=160; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=160; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=160; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=160; total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=160; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=170; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=170; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=170; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=170; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=170; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=180; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=180; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=180; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=190; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=190; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=190; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=190; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=30; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=60; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=70; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=100; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=120; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=130; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=140; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=140; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=140; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=140; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=140; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=150; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=150; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=150; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=160; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=160; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=160; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=170; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=170; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=170; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=170; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=180; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=180; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=180; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=180; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=190; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=190; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=190; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=190; total time=   0.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_ca...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, ...),\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.1, 0.2],\n",
       "                         'max_depth': range(3, 11),\n",
       "                         'n_estimators': range(20, 200, 10)},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. fit(), 학습\n",
    "model_xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=60; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=60; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=60; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=60; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=60; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=70; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=70; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=70; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=70; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=70; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=80; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=80; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=90; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=90; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=90; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=90; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=90; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=110; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=110; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=110; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=120; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=120; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=120; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=120; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=120; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=130; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=130; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=130; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=130; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=130; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=140; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=140; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=140; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=140; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=160; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=160; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=160; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=160; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=160; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=170; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=170; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=170; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=170; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=170; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=180; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=180; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=180; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=180; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=180; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=190; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=190; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=190; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=190; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=60; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=60; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=60; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=60; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=60; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=70; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=70; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=70; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=70; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=70; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=90; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=90; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=90; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=90; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=110; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=110; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=110; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=110; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=110; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=120; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=120; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=120; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=120; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=120; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=130; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=130; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=130; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=130; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=130; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=140; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=150; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=150; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=150; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=150; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=150; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=160; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=160; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=160; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=160; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=160; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=170; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=170; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=170; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=170; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=170; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=180; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=180; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=180; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=180; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=180; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=190; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=190; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=190; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=190; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=190; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=60; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=80; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=80; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=90; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=90; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=90; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=120; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=120; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=120; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=120; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=130; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=130; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=140; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=160; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=160; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=160; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=160; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=160; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=170; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=170; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=170; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=180; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=180; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=180; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=180; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=190; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=190; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=190; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=190; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=80; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=110; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=130; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=130; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=130; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=140; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=140; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=140; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=150; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=150; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=160; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=170; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=170; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=170; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=170; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=170; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=180; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=180; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=190; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=190; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=60; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=60; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=90; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=90; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=90; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=110; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=130; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=130; total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=130; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=140; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=140; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=140; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=140; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=150; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=150; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=150; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=150; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=150; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=160; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=160; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=160; total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=160; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=160; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=170; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=170; total time=   1.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=170; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=180; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=180; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=180; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=180; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=180; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=190; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=190; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=190; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=190; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=190; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=20; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=20; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=30; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=30; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=40; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=40; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=40; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=40; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=40; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=50; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=50; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=50; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=50; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=50; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=60; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=60; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=60; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=70; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=80; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=80; total time=   1.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=80; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=90; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=90; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=90; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=90; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=90; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=100; total time=   1.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=100; total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=110; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=110; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=110; total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=110; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=120; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=120; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=120; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=120; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=130; total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=130; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=130; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=130; total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=140; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=140; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=140; total time=   1.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=140; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=140; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=150; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=150; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=150; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=150; total time=   1.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=150; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=160; total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=160; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=160; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=160; total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=160; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=170; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=170; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=170; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=170; total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=180; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=180; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=180; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=180; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=180; total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=8, n_estimators=190; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=8, n_estimators=190; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=8, n_estimators=190; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=8, n_estimators=190; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=8, n_estimators=190; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=30; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=30; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=40; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=40; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=60; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=60; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=60; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=60; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=70; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=80; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=80; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=80; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=90; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=90; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=100; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=110; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=110; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=110; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=110; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=110; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=120; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=120; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=120; total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=130; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=130; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=130; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=130; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=130; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=140; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=140; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=140; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=140; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=140; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=150; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=150; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=150; total time=   1.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=150; total time=   1.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=150; total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=160; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=160; total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=160; total time=   1.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=160; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=160; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=170; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=170; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=170; total time=   1.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=170; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=170; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=180; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=180; total time=   1.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=180; total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=190; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=190; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=190; total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=190; total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=190; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=20; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=40; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=60; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=60; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=70; total time=   2.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=80; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=90; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=110; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=110; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=110; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=110; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=110; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=120; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=120; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=130; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=130; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=130; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=130; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=130; total time=   1.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=140; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=140; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=140; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=140; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=140; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=150; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=150; total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=150; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=150; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=160; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=160; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=160; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=160; total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=160; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=170; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=170; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=170; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=170; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=170; total time=   1.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=180; total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=180; total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=180; total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=180; total time=   1.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=180; total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, n_estimators=190; total time=   1.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, n_estimators=190; total time=   1.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, n_estimators=190; total time=   1.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, n_estimators=190; total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, n_estimators=190; total time=   1.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=80; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=90; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=110; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=120; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=130; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=130; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=140; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=140; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=150; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=150; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=150; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=160; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=160; total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=160; total time=   1.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=170; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=170; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=170; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=170; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=180; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=180; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=180; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=3, n_estimators=190; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=3, n_estimators=190; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=90; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=90; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=110; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=110; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=120; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=130; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=140; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=140; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=150; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=150; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=150; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=170; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=180; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=4, n_estimators=190; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=4, n_estimators=190; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=4, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=4, n_estimators=190; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=4, n_estimators=190; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=30; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=60; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=60; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=70; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=80; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=90; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=120; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=120; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=140; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=140; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=150; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=150; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=160; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=160; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=170; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=170; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=180; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=180; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=5, n_estimators=190; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=5, n_estimators=190; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=5, n_estimators=190; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=5, n_estimators=190; total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=5, n_estimators=190; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=50; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=50; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=60; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=80; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=80; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=90; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=100; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=100; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=100; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=110; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=110; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=110; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=120; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=120; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=130; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=130; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=130; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=140; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=140; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=150; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=150; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=150; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=160; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=160; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=160; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=160; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=170; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=170; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=170; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=180; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=6, n_estimators=190; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=6, n_estimators=190; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=6, n_estimators=190; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=6, n_estimators=190; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=20; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=30; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=40; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=40; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=50; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=50; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=80; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=90; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=100; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=110; total time=   1.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=110; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=110; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=120; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=120; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=130; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=130; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=130; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=140; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=140; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=140; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=140; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=140; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=160; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=160; total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=160; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=160; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=170; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=170; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=170; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=180; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=180; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=180; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=180; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=180; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=7, n_estimators=190; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=7, n_estimators=190; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=7, n_estimators=190; total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=7, n_estimators=190; total time=   1.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=20; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=20; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=20; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=20; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=40; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=60; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=60; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=70; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=80; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=80; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=90; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=90; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=90; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=90; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=100; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=100; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=100; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=100; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=110; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=110; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=120; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=120; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=120; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=120; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=130; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=140; total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=140; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=140; total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=140; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=140; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=150; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=150; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=150; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=150; total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=150; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=160; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=160; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=160; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=160; total time=   1.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=160; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=170; total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=170; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=170; total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=180; total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=180; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=180; total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=180; total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=180; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=8, n_estimators=190; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=8, n_estimators=190; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=8, n_estimators=190; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=8, n_estimators=190; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=8, n_estimators=190; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=20; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=20; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=20; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=30; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=40; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=40; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=40; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=60; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=60; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=60; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=70; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=80; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=80; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=90; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=90; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=100; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=100; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=100; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=110; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=110; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=110; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=110; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=120; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=120; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=120; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=130; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=130; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=130; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=130; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=140; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=140; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=140; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=140; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=140; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=150; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=150; total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=150; total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=150; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=150; total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=160; total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=160; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=160; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=160; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=160; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=170; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=170; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=170; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=170; total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=170; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=180; total time=   1.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=180; total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=180; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=180; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=9, n_estimators=190; total time=   1.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=9, n_estimators=190; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=9, n_estimators=190; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=9, n_estimators=190; total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=9, n_estimators=190; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=20; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=50; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=60; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=60; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=60; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=70; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=80; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=80; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=80; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=80; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=90; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=90; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=90; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=100; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=110; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=110; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=110; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=110; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=120; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=120; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=120; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=130; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=130; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=130; total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=130; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=130; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=140; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=140; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=140; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=140; total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=140; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=150; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=160; total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=160; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=160; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=160; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=160; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=170; total time=   1.5s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=170; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=170; total time=   1.3s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=170; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=170; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=180; total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=180; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=180; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=180; total time=   1.7s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=180; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.02, max_depth=10, n_estimators=190; total time=   1.4s\n",
      "[CV 2/5] END learning_rate=0.02, max_depth=10, n_estimators=190; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.02, max_depth=10, n_estimators=190; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.02, max_depth=10, n_estimators=190; total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.02, max_depth=10, n_estimators=190; total time=   1.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=40; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=60; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=130; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=150; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=160; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=180; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=180; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=3, n_estimators=190; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=3, n_estimators=190; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=60; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=90; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=110; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=110; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=110; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=120; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=120; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=150; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=150; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=150; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=160; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=160; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=160; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=170; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=4, n_estimators=190; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=4, n_estimators=190; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=4, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=4, n_estimators=190; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=4, n_estimators=190; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=60; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=140; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=140; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=150; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=150; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=150; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=160; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=180; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=5, n_estimators=190; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=5, n_estimators=190; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=5, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=5, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=5, n_estimators=190; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=30; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=110; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=120; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=120; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=120; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=130; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=130; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=140; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=150; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=170; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=170; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=180; total time=   1.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=180; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=180; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=180; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=6, n_estimators=190; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=20; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=20; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=20; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=60; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=60; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=70; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=70; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=100; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=100; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=110; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=110; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=110; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=110; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=120; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=120; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=130; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=130; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=130; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=140; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=140; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=140; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=140; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=140; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=150; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=150; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=150; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=150; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=160; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=160; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=160; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=170; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=180; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=180; total time=   1.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=7, n_estimators=190; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=7, n_estimators=190; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=7, n_estimators=190; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=7, n_estimators=190; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=40; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=40; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=60; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=80; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=80; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=80; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=80; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=90; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=90; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=90; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=110; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=110; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=110; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=120; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=120; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=120; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=120; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=120; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=130; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=130; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=130; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=130; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=140; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=140; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=140; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=140; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=140; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=150; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=150; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=150; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=150; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=160; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=160; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=160; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=160; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=160; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=170; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=170; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=170; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=180; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=180; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=180; total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=180; total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=180; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=8, n_estimators=190; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=8, n_estimators=190; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=8, n_estimators=190; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=8, n_estimators=190; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=8, n_estimators=190; total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=20; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=20; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=20; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=30; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=60; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=60; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=60; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=60; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=70; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=70; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=80; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=90; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=110; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=110; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=110; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=110; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=120; total time=   1.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=130; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=130; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=130; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=130; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=130; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=140; total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=140; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=140; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=140; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=140; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=150; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=150; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=150; total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=150; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=150; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=160; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=160; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=160; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=160; total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=160; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=170; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=170; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=170; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=170; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=170; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=180; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=9, n_estimators=190; total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=9, n_estimators=190; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=9, n_estimators=190; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=9, n_estimators=190; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=9, n_estimators=190; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=20; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=20; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=20; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=30; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=60; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=60; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=60; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=70; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=70; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=80; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=80; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=90; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=90; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=100; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=100; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=100; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=110; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=110; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=110; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=110; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=110; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=120; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=120; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=130; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=130; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=130; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=130; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=130; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=140; total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=140; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=140; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=140; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=140; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=150; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=150; total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=150; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=160; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=160; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=160; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=160; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=160; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=170; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=170; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=170; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=170; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=170; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=180; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=180; total time=   1.2s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=180; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=180; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=180; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.03, max_depth=10, n_estimators=190; total time=   1.2s\n",
      "[CV 2/5] END learning_rate=0.03, max_depth=10, n_estimators=190; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.03, max_depth=10, n_estimators=190; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.03, max_depth=10, n_estimators=190; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.03, max_depth=10, n_estimators=190; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=110; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=140; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=140; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=140; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=160; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=180; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=180; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=180; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=180; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=190; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=190; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=190; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=190; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=90; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=90; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=110; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=120; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=120; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=120; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=130; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=130; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=130; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=140; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=150; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=160; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=170; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=180; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=180; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=190; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=190; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=190; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=190; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=80; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=130; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=150; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=150; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=170; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=170; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=180; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=180; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=180; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=180; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=190; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=190; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=190; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=190; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=90; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=90; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=110; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=130; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=140; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=140; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=150; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=160; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=170; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=170; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=190; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=190; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=190; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=40; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=60; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=70; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=90; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=90; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=90; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=110; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=120; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=120; total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=120; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=120; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=130; total time=   1.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=130; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=130; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=130; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=140; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=140; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=140; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=140; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=140; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=160; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=160; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=160; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=160; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=170; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=170; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=170; total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=170; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=180; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=180; total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=180; total time=   1.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=190; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=190; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=30; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=30; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=70; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=70; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=90; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=110; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=110; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=120; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=120; total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=140; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=140; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=140; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=140; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=150; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=150; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=150; total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=160; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=160; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=160; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=160; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=160; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=170; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=180; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=180; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=180; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=180; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=180; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=8, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=8, n_estimators=190; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=8, n_estimators=190; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=8, n_estimators=190; total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=8, n_estimators=190; total time=   1.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=20; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=20; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=40; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=40; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=40; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=40; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=60; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=60; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=80; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=80; total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=90; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=90; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=100; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=110; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=110; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=110; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=110; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=120; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=130; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=130; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=130; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=140; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=140; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=140; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=140; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=140; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=150; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=150; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=150; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=150; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=160; total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=160; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=160; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=160; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=160; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=170; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=170; total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=170; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=170; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=180; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=180; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=180; total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=180; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=180; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=190; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=190; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=190; total time=   1.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=190; total time=   1.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=190; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=60; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=60; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=60; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=70; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=70; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=70; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=70; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=80; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=80; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=90; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=120; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=120; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=120; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=130; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=130; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=130; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=130; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=140; total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=140; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=140; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=140; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=140; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=150; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=150; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=150; total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=150; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=150; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=160; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=160; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=160; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=160; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=170; total time=   1.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=170; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=170; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=170; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=170; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=180; total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=180; total time=   1.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=180; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=180; total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=180; total time=   1.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=190; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=190; total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=190; total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=190; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=190; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=80; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=90; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=110; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=110; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=120; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=130; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=130; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=140; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=140; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=160; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=170; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=180; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=190; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=190; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=190; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=190; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=20; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=80; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=110; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=110; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=110; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=110; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=120; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=120; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=120; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=120; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=130; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=140; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=160; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=160; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=170; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=170; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=180; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=180; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=180; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=190; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=190; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=190; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=70; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=110; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=120; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=130; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=140; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=150; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=160; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=160; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=160; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=170; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=180; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=180; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=180; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=180; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=180; total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=190; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=190; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=190; total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=20; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=60; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=70; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=70; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=110; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=130; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=130; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=130; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=130; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=140; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=140; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=150; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=150; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=170; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=170; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=170; total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=170; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=180; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=6, n_estimators=190; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=6, n_estimators=190; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=6, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=6, n_estimators=190; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=6, n_estimators=190; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=30; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=40; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=40; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=60; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=80; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=80; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=90; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=90; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=90; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=110; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=120; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=130; total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=140; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=150; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=150; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=150; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=150; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=160; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=160; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=160; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=160; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=170; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=170; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=180; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=180; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=190; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=190; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=190; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=190; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=20; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=40; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=50; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=60; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=60; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=90; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=110; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=110; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=120; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=120; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=120; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=130; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=140; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=140; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=140; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=140; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=150; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=150; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=150; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=150; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=160; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=160; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=160; total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=160; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=160; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=170; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=170; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=180; total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=180; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=180; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, n_estimators=190; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, n_estimators=190; total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, n_estimators=190; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, n_estimators=190; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=30; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=50; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=50; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=60; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=70; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=80; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=90; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=90; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=100; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=100; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=100; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=110; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=110; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=110; total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=120; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=120; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=120; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=120; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=120; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=130; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=130; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=140; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=140; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=140; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=140; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=150; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=150; total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=150; total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=150; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=160; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=160; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=160; total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=160; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=170; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=170; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=180; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=180; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=180; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, n_estimators=190; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, n_estimators=190; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, n_estimators=190; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, n_estimators=190; total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=20; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=30; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=30; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=40; total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=50; total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=50; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=50; total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=60; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=60; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=70; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=70; total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=70; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=70; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=80; total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=80; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=80; total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=80; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=90; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=90; total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=90; total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=100; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=100; total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=110; total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=110; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=110; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=120; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=120; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=120; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=120; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=130; total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=130; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=130; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=130; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=130; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=140; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=140; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=140; total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=140; total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=140; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=150; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=150; total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=150; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=150; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=150; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=160; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=160; total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=160; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=160; total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=160; total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=170; total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=170; total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=170; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=170; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=170; total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=180; total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=180; total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=180; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=180; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=180; total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=190; total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=190; total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=190; total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=190; total time=   0.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_ca...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, ...),\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03, 0.1, 0.2],\n",
       "                         'max_depth': range(3, 11),\n",
       "                         'n_estimators': range(20, 200, 10)},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 70}\n",
      "0.954878001133056\n"
     ]
    }
   ],
   "source": [
    "print(model_xgb.best_params_)\n",
    "print(model_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.2, 'max_depth': 8, 'n_estimators': 60}\n",
      "0.9536013596671159\n"
     ]
    }
   ],
   "source": [
    "print(model_xgb.best_params_)\n",
    "print(model_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. predict(), 예측\n",
    "pred_xgb = model_xgb.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       473\n",
      "           1       0.95      0.94      0.95       497\n",
      "\n",
      "    accuracy                           0.95       970\n",
      "   macro avg       0.95      0.95      0.95       970\n",
      "weighted avg       0.95      0.95      0.95       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train 및 val 데이터 정확도 확인 \n",
    "print(creport(pred_xgb, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 데이터 결과 Confusion Matrix 확인\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "confusion = confusion_matrix(y_val, pred_xgb)\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "plot_confusion_matrix(ax, confusion, fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_feature_importance(importance, names):\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "    fi_df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(x='feature_importance', y='feature_names', data = fi_df)\n",
    "\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')\n",
    "    plt.grid()\n",
    "\n",
    "    return fi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature(특징)별 가중치 확인\n",
    "result = plot_feature_importance(model_xgb.best_estimator_.feature_importances_, x_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.선언 \n",
    "params2 = {'n_estimators' : range(20, 201, 10), 'max_features' : range(1, x.shape[1]+1)}\n",
    "rf = RandomForestClassifier(max_features=5, n_estimators=120)\n",
    "model_rf = GridSearchCV(rf, params2, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 399 candidates, totalling 1995 fits\n",
      "[CV 1/5] END ................max_features=1, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END ................max_features=1, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END ................max_features=1, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END ................max_features=1, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END ................max_features=1, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END ................max_features=1, n_estimators=30; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ................max_features=1, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END ................max_features=1, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END ................max_features=1, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END ................max_features=1, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END ................max_features=1, n_estimators=40; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ................max_features=1, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END ................max_features=1, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END ................max_features=1, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END ................max_features=1, n_estimators=40; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ................max_features=1, n_estimators=50; total time=   0.1s\n",
      "[CV 2/5] END ................max_features=1, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END ................max_features=1, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END ................max_features=1, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END ................max_features=1, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END ................max_features=1, n_estimators=60; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ................max_features=1, n_estimators=60; total time=   0.0s\n",
      "[CV 3/5] END ................max_features=1, n_estimators=60; total time=   0.0s\n",
      "[CV 4/5] END ................max_features=1, n_estimators=60; total time=   0.0s\n",
      "[CV 5/5] END ................max_features=1, n_estimators=60; total time=   0.0s\n",
      "[CV 1/5] END ................max_features=1, n_estimators=70; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ................max_features=1, n_estimators=70; total time=   0.0s\n",
      "[CV 3/5] END ................max_features=1, n_estimators=70; total time=   0.0s\n",
      "[CV 4/5] END ................max_features=1, n_estimators=70; total time=   0.0s\n",
      "[CV 5/5] END ................max_features=1, n_estimators=70; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ................max_features=1, n_estimators=80; total time=   0.1s\n",
      "[CV 2/5] END ................max_features=1, n_estimators=80; total time=   0.0s\n",
      "[CV 3/5] END ................max_features=1, n_estimators=80; total time=   0.0s\n",
      "[CV 4/5] END ................max_features=1, n_estimators=80; total time=   0.0s\n",
      "[CV 5/5] END ................max_features=1, n_estimators=80; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ................max_features=1, n_estimators=90; total time=   0.2s\n",
      "[CV 2/5] END ................max_features=1, n_estimators=90; total time=   0.0s\n",
      "[CV 3/5] END ................max_features=1, n_estimators=90; total time=   0.0s\n",
      "[CV 4/5] END ................max_features=1, n_estimators=90; total time=   0.0s\n",
      "[CV 5/5] END ................max_features=1, n_estimators=90; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............max_features=1, n_estimators=100; total time=   0.3s\n",
      "[CV 2/5] END ...............max_features=1, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END ...............max_features=1, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END ...............max_features=1, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END ...............max_features=1, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............max_features=1, n_estimators=110; total time=   0.3s\n",
      "[CV 2/5] END ...............max_features=1, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END ...............max_features=1, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END ...............max_features=1, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END ...............max_features=1, n_estimators=110; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............max_features=1, n_estimators=120; total time=   0.4s\n",
      "[CV 2/5] END ...............max_features=1, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END ...............max_features=1, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END ...............max_features=1, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END ...............max_features=1, n_estimators=120; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............max_features=1, n_estimators=130; total time=   0.3s\n",
      "[CV 2/5] END ...............max_features=1, n_estimators=130; total time=   0.0s\n",
      "[CV 3/5] END ...............max_features=1, n_estimators=130; total time=   0.0s\n",
      "[CV 4/5] END ...............max_features=1, n_estimators=130; total time=   0.0s\n",
      "[CV 5/5] END ...............max_features=1, n_estimators=130; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............max_features=1, n_estimators=140; total time=   0.5s\n",
      "[CV 2/5] END ...............max_features=1, n_estimators=140; total time=   0.0s\n",
      "[CV 3/5] END ...............max_features=1, n_estimators=140; total time=   0.0s\n",
      "[CV 4/5] END ...............max_features=1, n_estimators=140; total time=   0.0s\n",
      "[CV 5/5] END ...............max_features=1, n_estimators=140; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............max_features=1, n_estimators=150; total time=   0.5s\n",
      "[CV 2/5] END ...............max_features=1, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END ...............max_features=1, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END ...............max_features=1, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END ...............max_features=1, n_estimators=150; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............max_features=1, n_estimators=160; total time=   0.5s\n",
      "[CV 2/5] END ...............max_features=1, n_estimators=160; total time=   0.0s\n",
      "[CV 3/5] END ...............max_features=1, n_estimators=160; total time=   0.0s\n",
      "[CV 4/5] END ...............max_features=1, n_estimators=160; total time=   0.0s\n",
      "[CV 5/5] END ...............max_features=1, n_estimators=160; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............max_features=1, n_estimators=170; total time=   0.6s\n",
      "[CV 2/5] END ...............max_features=1, n_estimators=170; total time=   0.0s\n",
      "[CV 3/5] END ...............max_features=1, n_estimators=170; total time=   0.0s\n",
      "[CV 4/5] END ...............max_features=1, n_estimators=170; total time=   0.0s\n",
      "[CV 5/5] END ...............max_features=1, n_estimators=170; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............max_features=1, n_estimators=180; total time=   0.5s\n",
      "[CV 2/5] END ...............max_features=1, n_estimators=180; total time=   0.0s\n",
      "[CV 3/5] END ...............max_features=1, n_estimators=180; total time=   0.0s\n",
      "[CV 4/5] END ...............max_features=1, n_estimators=180; total time=   0.0s\n",
      "[CV 5/5] END ...............max_features=1, n_estimators=180; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............max_features=1, n_estimators=190; total time=   0.6s\n",
      "[CV 2/5] END ...............max_features=1, n_estimators=190; total time=   0.0s\n",
      "[CV 3/5] END ...............max_features=1, n_estimators=190; total time=   0.0s\n",
      "[CV 4/5] END ...............max_features=1, n_estimators=190; total time=   0.0s\n",
      "[CV 5/5] END ...............max_features=1, n_estimators=190; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............max_features=1, n_estimators=200; total time=   0.6s\n",
      "[CV 2/5] END ...............max_features=1, n_estimators=200; total time=   0.0s\n",
      "[CV 3/5] END ...............max_features=1, n_estimators=200; total time=   0.0s\n",
      "[CV 4/5] END ...............max_features=1, n_estimators=200; total time=   0.0s\n",
      "[CV 5/5] END ...............max_features=1, n_estimators=200; total time=   0.0s\n",
      "[CV 1/5] END ................max_features=2, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END ................max_features=2, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END ................max_features=2, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END ................max_features=2, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END ................max_features=2, n_estimators=20; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ................max_features=2, n_estimators=30; total time=   0.0s\n",
      "[CV 2/5] END ................max_features=2, n_estimators=30; total time=   0.0s\n",
      "[CV 3/5] END ................max_features=2, n_estimators=30; total time=   0.0s\n",
      "[CV 4/5] END ................max_features=2, n_estimators=30; total time=   0.0s\n",
      "[CV 5/5] END ................max_features=2, n_estimators=30; total time=   0.0s\n",
      "[CV 1/5] END ................max_features=2, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END ................max_features=2, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END ................max_features=2, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END ................max_features=2, n_estimators=40; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ................max_features=2, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END ................max_features=2, n_estimators=50; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ................max_features=2, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END ................max_features=2, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END ................max_features=2, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END ................max_features=2, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ................max_features=2, n_estimators=60; total time=   0.1s\n",
      "[CV 2/5] END ................max_features=2, n_estimators=60; total time=   0.0s\n",
      "[CV 3/5] END ................max_features=2, n_estimators=60; total time=   0.0s\n",
      "[CV 4/5] END ................max_features=2, n_estimators=60; total time=   0.0s\n",
      "[CV 5/5] END ................max_features=2, n_estimators=60; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ................max_features=2, n_estimators=70; total time=   0.2s\n",
      "[CV 2/5] END ................max_features=2, n_estimators=70; total time=   0.0s\n",
      "[CV 3/5] END ................max_features=2, n_estimators=70; total time=   0.0s\n",
      "[CV 4/5] END ................max_features=2, n_estimators=70; total time=   0.0s\n",
      "[CV 5/5] END ................max_features=2, n_estimators=70; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 500, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 630, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 674, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 422, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 402, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 304, in fit\n",
      "    X, y = self._validate_data(X, y, multi_output=True,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ................max_features=2, n_estimators=80; total time=   0.2s\n",
      "[CV 2/5] END ................max_features=2, n_estimators=80; total time=   0.0s\n",
      "[CV 3/5] END ................max_features=2, n_estimators=80; total time=   0.0s\n",
      "[CV 4/5] END ................max_features=2, n_estimators=80; total time=   0.0s\n",
      "[CV 5/5] END ................max_features=2, n_estimators=80; total time=   0.0s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-212-475dd074113e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 3. fit(), 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    167\u001b[0m                                                         indices=indices)\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    896\u001b[0m         \"\"\"\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 3. fit(), 학습\n",
    "model_rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=5, n_estimators=120)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 5, 'n_estimators': 120}\n",
      "0.9570923440582938\n"
     ]
    }
   ],
   "source": [
    "print(model_rf.best_params_)\n",
    "print(model_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. predict(), 예측\n",
    "pred_rf = model_rf.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf1 = rf.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       471\n",
      "           1       0.95      0.94      0.95       499\n",
      "\n",
      "    accuracy                           0.95       970\n",
      "   macro avg       0.95      0.95      0.95       970\n",
      "weighted avg       0.95      0.95      0.95       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train 및 val 데이터 정확도 확인 \n",
    "print(creport(pred_rf1, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 데이터 결과 Confusion Matrix 확인\n",
    "confusion = confusion_matrix(y_val, pred_rf1)\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "plot_confusion_matrix(ax, confusion, fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'sklearn.ensemble._forest.RandomForestClassifier'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-235-a0916718e080>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Test 데이터 결과 Confusion Matrix 확인\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mconfusion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \"\"\"\n\u001b[1;32m--> 296\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \"\"\"\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \"\"\"\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;31m# Don't get num_samples from an ensembles length!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'sklearn.ensemble._forest.RandomForestClassifier'>"
     ]
    }
   ],
   "source": [
    "# Test 데이터 결과 Confusion Matrix 확인\n",
    "confusion = confusion_matrix(y_val, rf)\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "plot_confusion_matrix(ax, confusion, fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature(특징)별 가중치 확인\n",
    "result = plot_feature_importance(model_rf.best_estimator_.feature_importances_, x_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 테스트 셋 데이터 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_len</th>\n",
       "      <th>url_num_hyphens_dom</th>\n",
       "      <th>url_path_len</th>\n",
       "      <th>url_domain_len</th>\n",
       "      <th>url_hostname_len</th>\n",
       "      <th>url_num_dots</th>\n",
       "      <th>url_num_underscores</th>\n",
       "      <th>url_query_len</th>\n",
       "      <th>url_num_query_para</th>\n",
       "      <th>url_ip_present</th>\n",
       "      <th>...</th>\n",
       "      <th>html_num_tags('iframe')</th>\n",
       "      <th>html_num_tags('script')</th>\n",
       "      <th>html_num_tags('embed')</th>\n",
       "      <th>html_num_tags('object')</th>\n",
       "      <th>html_num_tags('div')</th>\n",
       "      <th>html_num_tags('head')</th>\n",
       "      <th>html_num_tags('body')</th>\n",
       "      <th>html_num_tags('form')</th>\n",
       "      <th>html_num_tags('a')</th>\n",
       "      <th>Result_v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_len  url_num_hyphens_dom  url_path_len  url_domain_len  \\\n",
       "0     23.0                  0.0           8.0            15.0   \n",
       "1     75.0                  0.0          58.0            17.0   \n",
       "2     20.0                  0.0           4.0            16.0   \n",
       "3     27.0                  0.0          13.0            14.0   \n",
       "4     39.0                  2.0          12.0            27.0   \n",
       "\n",
       "   url_hostname_len  url_num_dots  url_num_underscores  url_query_len  \\\n",
       "0              15.0           2.0                  0.0            0.0   \n",
       "1              17.0           6.0                  0.0            0.0   \n",
       "2              16.0           2.0                  0.0            0.0   \n",
       "3              14.0           3.0                  0.0            0.0   \n",
       "4              27.0           2.0                  0.0            0.0   \n",
       "\n",
       "   url_num_query_para  url_ip_present  ...  html_num_tags('iframe')  \\\n",
       "0                 0.0             0.0  ...                      0.0   \n",
       "1                 0.0             0.0  ...                      0.0   \n",
       "2                 0.0             0.0  ...                      1.0   \n",
       "3                 0.0             0.0  ...                      0.0   \n",
       "4                 0.0             0.0  ...                      0.0   \n",
       "\n",
       "   html_num_tags('script')  html_num_tags('embed')  html_num_tags('object')  \\\n",
       "0                      7.0                     0.0                      0.0   \n",
       "1                     18.0                     0.0                      0.0   \n",
       "2                     33.0                     0.0                      0.0   \n",
       "3                     15.0                     0.0                      0.0   \n",
       "4                     10.0                     0.0                      0.0   \n",
       "\n",
       "   html_num_tags('div')  html_num_tags('head')  html_num_tags('body')  \\\n",
       "0                   0.0                    1.0                    1.0   \n",
       "1                  20.0                    1.0                    1.0   \n",
       "2                 101.0                    1.0                    1.0   \n",
       "3                 151.0                    1.0                    1.0   \n",
       "4                 332.0                    1.0                    1.0   \n",
       "\n",
       "   html_num_tags('form')  html_num_tags('a')  Result_v1  \n",
       "0                    0.0                 0.0         -1  \n",
       "1                    0.0                21.0          1  \n",
       "2                    3.0                70.0          1  \n",
       "3                    1.0                55.0          1  \n",
       "4                    0.0               321.0          1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['hyphens_ratio', 'total_tag'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Logistic Regrssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 아래 함수는 로지스틱 회귀를 위한 전진선택법 함수 입니다.\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def forward_stepwise_logistic(x_train, y_train):\n",
    "\n",
    "    # 변수목록, 선택된 변수 목록, 단계별 모델과 AIC 저장소 정의\n",
    "    features = list(x_train)\n",
    "    selected = []\n",
    "    step_df = pd.DataFrame({ 'step':[], 'feature':[],'aic':[]})\n",
    "\n",
    "    # \n",
    "    for s in range(0, len(features)) :\n",
    "        result =  { 'step':[], 'feature':[],'aic':[]}\n",
    "\n",
    "        # 변수 목록에서 변수 한개씩 뽑아서 모델에 추가\n",
    "        for f in features :\n",
    "            vars = selected + [f]\n",
    "            x_tr = x_train[vars]\n",
    "            model = sm.Logit(y_train, x_tr).fit()\n",
    "            result['step'].append(s+1)\n",
    "            result['feature'].append(vars)\n",
    "            result['aic'].append(model.aic)\n",
    "        \n",
    "        # 모델별 aic 집계\n",
    "        temp = pd.DataFrame(result).sort_values('aic').reset_index(drop = True)\n",
    "\n",
    "        # 만약 이전 aic보다 새로운 aic 가 크다면 멈추기\n",
    "        if step_df['aic'].min() < temp['aic'].min() :\n",
    "            break\n",
    "        step_df = pd.concat([step_df, temp], axis = 0).reset_index(drop = True)\n",
    "\n",
    "        # 선택된 변수 제거\n",
    "        v = temp.loc[0,'feature'][s]\n",
    "        features.remove(v)\n",
    "\n",
    "        selected.append(v)\n",
    "    \n",
    "    # 선택된 변수와 step_df 결과 반환\n",
    "    return selected, step_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.693042\n",
      "         Iterations 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.628452\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684549\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680422\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680000\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692424\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682959\n",
      "         Iterations 6\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.649002\n",
      "         Iterations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.656053\n",
      "         Iterations 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-7c9f3fd6c650>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_stepwise_logistic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-edf4d4def340>\u001b[0m in \u001b[0;36mforward_stepwise_logistic\u001b[1;34m(x_train, y_train)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mvars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselected\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mx_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'feature'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m   1972\u001b[0m     def fit(self, start_params=None, method='newton', maxiter=35,\n\u001b[0;32m   1973\u001b[0m             full_output=1, disp=1, callback=None, **kwargs):\n\u001b[1;32m-> 1974\u001b[1;33m         bnryfit = super().fit(start_params=start_params,\n\u001b[0m\u001b[0;32m   1975\u001b[0m                               \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1976\u001b[0m                               \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mpass\u001b[0m  \u001b[1;31m# TODO: make a function factory to have multiple call-backs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m         mlefit = super().fit(start_params=start_params,\n\u001b[0m\u001b[0;32m    228\u001b[0m                              \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                              \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[0mHinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcov_params_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m             \u001b[0mHinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mretvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Hessian'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mskip_hessian\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m             \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    543\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->D'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m     \u001b[0mainv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Singular matrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "var, step_df = forward_stepwise_logistic(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'var' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-84ddba356ca3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'var' is not defined"
     ]
    }
   ],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = model_lr.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 데이터 결과 Confusion Matrix 확인\n",
    "confusion = confusion_matrix(y_val, pred_lr)\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "plot_confusion_matrix(ax, confusion, fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.선언 \n",
    "params = {'max_depth' : range(3, 16), 'min_samples_leaf' : range(10, 101, 10)}\n",
    "dt = DecisionTreeClassifier()\n",
    "model_dt = GridSearchCV(dt, params, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 130 candidates, totalling 650 fits\n",
      "[CV 1/5] END ...............max_depth=3, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=3, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=3, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=3, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=3, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=3, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=3, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=3, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=3, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=3, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=3, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=3, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=3, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=3, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=3, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=3, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=3, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=3, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=3, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=3, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=3, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=3, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=3, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=3, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=3, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=3, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=3, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=3, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=3, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=3, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=3, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=3, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=3, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=3, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=3, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=3, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=3, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=3, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=3, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=3, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=3, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=3, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=3, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=3, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=3, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=3, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=3, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=3, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=3, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=3, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=4, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=4, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=4, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=4, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=4, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=4, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=4, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=4, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=4, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=4, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=4, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=4, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=4, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=4, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=4, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=4, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=4, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=4, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=4, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=4, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=4, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=4, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=4, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=4, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=4, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=4, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=4, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=4, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=4, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=4, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=4, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=4, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=4, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=4, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=4, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=4, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=4, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=4, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=4, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=4, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=4, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=4, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=4, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=4, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=4, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=4, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=4, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=4, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=4, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=4, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=5, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=5, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=5, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=5, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=5, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=5, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=5, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=5, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=5, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=5, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=5, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=5, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=5, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=5, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=5, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=5, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=5, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=5, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=5, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=5, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=5, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=5, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=5, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=5, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=5, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=5, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=5, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=5, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=5, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=5, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=5, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=5, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=5, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=5, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=5, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=5, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=5, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=5, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=5, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=5, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=5, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=5, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=5, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=5, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=5, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=5, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=5, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=5, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=5, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=5, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=6, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=6, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=6, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=6, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=6, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=6, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=6, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=6, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=6, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=6, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=6, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=6, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=6, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=6, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=6, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=6, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=6, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=6, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=6, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=6, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=6, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=6, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=6, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=6, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=6, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=6, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=6, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=6, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=6, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=6, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=6, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=6, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=6, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=6, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=6, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=6, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=6, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=6, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=6, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=6, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=6, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=6, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=6, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=6, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=6, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=6, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=6, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=6, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=6, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=6, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=7, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=7, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=7, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=7, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=7, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=7, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=7, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=7, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=7, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=7, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=7, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=7, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=7, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=7, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=7, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=7, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=7, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=7, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=7, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=7, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=7, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=7, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=7, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=7, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=7, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=7, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=7, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=7, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=7, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=7, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=7, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=7, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=7, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=7, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=7, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=7, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=7, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=7, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=7, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=7, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=7, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=7, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=7, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=7, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=7, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=7, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=7, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=7, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=7, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=7, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=8, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=8, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=8, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=8, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=8, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=8, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=8, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=8, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=8, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=8, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=8, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=8, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=8, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=8, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=8, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=8, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=8, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=8, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=8, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=8, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=8, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=8, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=8, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=8, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=8, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=8, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=8, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=8, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=8, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=8, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=8, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=8, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=8, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=8, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=8, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=8, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=8, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=8, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=8, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=8, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=8, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=8, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=8, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=8, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=8, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=8, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=8, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=8, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=8, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=8, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=9, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=9, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=9, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=9, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=9, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=9, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=9, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=9, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=9, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=9, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=9, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=9, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=9, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=9, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=9, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=9, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=9, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=9, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=9, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=9, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=9, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=9, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=9, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=9, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=9, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=9, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=9, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=9, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=9, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=9, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=9, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=9, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=9, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=9, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=9, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=9, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=9, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=9, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=9, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=9, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 1/5] END ...............max_depth=9, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 2/5] END ...............max_depth=9, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 3/5] END ...............max_depth=9, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 4/5] END ...............max_depth=9, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 5/5] END ...............max_depth=9, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=9, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=9, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=9, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=9, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=9, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=10, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=10, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=10, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=10, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=10, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=10, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=10, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=10, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=10, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=10, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=10, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=10, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=10, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=10, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=10, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=10, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=10, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=10, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=10, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=10, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=10, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=10, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=10, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=10, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=10, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=10, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=10, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=10, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=10, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=10, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=10, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=10, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=10, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=10, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=10, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=10, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=10, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=10, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=10, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=10, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=10, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=10, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=10, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=10, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=10, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 1/5] END .............max_depth=10, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 2/5] END .............max_depth=10, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 3/5] END .............max_depth=10, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 4/5] END .............max_depth=10, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 5/5] END .............max_depth=10, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=11, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=11, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=11, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=11, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=11, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=11, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=11, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=11, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=11, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=11, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=11, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=11, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=11, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=11, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=11, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=11, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=11, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=11, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=11, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=11, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=11, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=11, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=11, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=11, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=11, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=11, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=11, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=11, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=11, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=11, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=11, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=11, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=11, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=11, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=11, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=11, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=11, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=11, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=11, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=11, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=11, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=11, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=11, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=11, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=11, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 1/5] END .............max_depth=11, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 2/5] END .............max_depth=11, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 3/5] END .............max_depth=11, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 4/5] END .............max_depth=11, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 5/5] END .............max_depth=11, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=12, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=12, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=12, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=12, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=12, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=12, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=12, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=12, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=12, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=12, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=12, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=12, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=12, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=12, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=12, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=12, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=12, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=12, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=12, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=12, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=12, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=12, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=12, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=12, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=12, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=12, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=12, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=12, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=12, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=12, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=12, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=12, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=12, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=12, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=12, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=12, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=12, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=12, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=12, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=12, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=12, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=12, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=12, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=12, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=12, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 1/5] END .............max_depth=12, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 2/5] END .............max_depth=12, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 3/5] END .............max_depth=12, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 4/5] END .............max_depth=12, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 5/5] END .............max_depth=12, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=13, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=13, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=13, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=13, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=13, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=13, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=13, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=13, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=13, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=13, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=13, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=13, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=13, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=13, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=13, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=13, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=13, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=13, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=13, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=13, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=13, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=13, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=13, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=13, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=13, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=13, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=13, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=13, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=13, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=13, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=13, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=13, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=13, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=13, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=13, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=13, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=13, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=13, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=13, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=13, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=13, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=13, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=13, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=13, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=13, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 1/5] END .............max_depth=13, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 2/5] END .............max_depth=13, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 3/5] END .............max_depth=13, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 4/5] END .............max_depth=13, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 5/5] END .............max_depth=13, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=14, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=14, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=14, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=14, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=14, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=14, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=14, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=14, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=14, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=14, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=14, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=14, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=14, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=14, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=14, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=14, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=14, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=14, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=14, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=14, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=14, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=14, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=14, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=14, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=14, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=14, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=14, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=14, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=14, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=14, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=14, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=14, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=14, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=14, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=14, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=14, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=14, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=14, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=14, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=14, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=14, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=14, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=14, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=14, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=14, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 1/5] END .............max_depth=14, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 2/5] END .............max_depth=14, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 3/5] END .............max_depth=14, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 4/5] END .............max_depth=14, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 5/5] END .............max_depth=14, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=15, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=15, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=15, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=15, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=15, min_samples_leaf=10; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=15, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=15, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=15, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=15, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=15, min_samples_leaf=20; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=15, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=15, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=15, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=15, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=15, min_samples_leaf=30; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=15, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=15, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=15, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=15, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=15, min_samples_leaf=40; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=15, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=15, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=15, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=15, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=15, min_samples_leaf=50; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=15, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=15, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=15, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=15, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=15, min_samples_leaf=60; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=15, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=15, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=15, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=15, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=15, min_samples_leaf=70; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=15, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=15, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=15, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=15, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=15, min_samples_leaf=80; total time=   0.0s\n",
      "[CV 1/5] END ..............max_depth=15, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 2/5] END ..............max_depth=15, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 3/5] END ..............max_depth=15, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 4/5] END ..............max_depth=15, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 5/5] END ..............max_depth=15, min_samples_leaf=90; total time=   0.0s\n",
      "[CV 1/5] END .............max_depth=15, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 2/5] END .............max_depth=15, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 3/5] END .............max_depth=15, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 4/5] END .............max_depth=15, min_samples_leaf=100; total time=   0.0s\n",
      "[CV 5/5] END .............max_depth=15, min_samples_leaf=100; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': range(3, 16),\n",
       "                         'min_samples_leaf': range(10, 101, 10)},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. fit(), 학습\n",
    "model_dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'min_samples_leaf': 10}\n",
      "0.9137519779640156\n"
     ]
    }
   ],
   "source": [
    "print(model_dt.best_params_)\n",
    "print(model_dt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. predict(), 예측\n",
    "pred_dt = model_dt.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       474\n",
      "           1       0.91      0.90      0.90       496\n",
      "\n",
      "    accuracy                           0.90       970\n",
      "   macro avg       0.90      0.90      0.90       970\n",
      "weighted avg       0.90      0.90      0.90       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train 및 val 데이터 정확도 확인 \n",
    "print(creport(pred_dt, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 데이터 결과 Confusion Matrix 확인\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "confusion = confusion_matrix(y_val, pred_dt)\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "plot_confusion_matrix(ax, confusion, fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature(특징)별 가중치 확인\n",
    "result = plot_feature_importance(model_dt.best_estimator_.feature_importances_, x_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.선언 \n",
    "params = {'C' : [0.1, 0.5, 1, 1.5, 2], 'gamma' : [0.1, 0.5, 1, 1.5, 2]}\n",
    "svc = SVC()\n",
    "model_svc = GridSearchCV(svc, params, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ...............................C=0.1, gamma=0.1; total time=   0.2s\n",
      "[CV 2/5] END ...............................C=0.1, gamma=0.1; total time=   0.2s\n",
      "[CV 3/5] END ...............................C=0.1, gamma=0.1; total time=   0.2s\n",
      "[CV 4/5] END ...............................C=0.1, gamma=0.1; total time=   0.2s\n",
      "[CV 5/5] END ...............................C=0.1, gamma=0.1; total time=   0.2s\n",
      "[CV 1/5] END ...............................C=0.1, gamma=0.5; total time=   0.2s\n",
      "[CV 2/5] END ...............................C=0.1, gamma=0.5; total time=   0.3s\n",
      "[CV 3/5] END ...............................C=0.1, gamma=0.5; total time=   0.2s\n",
      "[CV 4/5] END ...............................C=0.1, gamma=0.5; total time=   0.2s\n",
      "[CV 5/5] END ...............................C=0.1, gamma=0.5; total time=   0.2s\n",
      "[CV 1/5] END .................................C=0.1, gamma=1; total time=   0.2s\n",
      "[CV 2/5] END .................................C=0.1, gamma=1; total time=   0.2s\n",
      "[CV 3/5] END .................................C=0.1, gamma=1; total time=   0.2s\n",
      "[CV 4/5] END .................................C=0.1, gamma=1; total time=   0.2s\n",
      "[CV 5/5] END .................................C=0.1, gamma=1; total time=   0.2s\n",
      "[CV 1/5] END ...............................C=0.1, gamma=1.5; total time=   0.2s\n",
      "[CV 2/5] END ...............................C=0.1, gamma=1.5; total time=   0.2s\n",
      "[CV 3/5] END ...............................C=0.1, gamma=1.5; total time=   0.2s\n",
      "[CV 4/5] END ...............................C=0.1, gamma=1.5; total time=   0.2s\n",
      "[CV 5/5] END ...............................C=0.1, gamma=1.5; total time=   0.2s\n",
      "[CV 1/5] END .................................C=0.1, gamma=2; total time=   0.1s\n",
      "[CV 2/5] END .................................C=0.1, gamma=2; total time=   0.2s\n",
      "[CV 3/5] END .................................C=0.1, gamma=2; total time=   0.2s\n",
      "[CV 4/5] END .................................C=0.1, gamma=2; total time=   0.2s\n",
      "[CV 5/5] END .................................C=0.1, gamma=2; total time=   0.2s\n",
      "[CV 1/5] END ...............................C=0.5, gamma=0.1; total time=   0.3s\n",
      "[CV 2/5] END ...............................C=0.5, gamma=0.1; total time=   0.3s\n",
      "[CV 3/5] END ...............................C=0.5, gamma=0.1; total time=   0.2s\n",
      "[CV 4/5] END ...............................C=0.5, gamma=0.1; total time=   0.2s\n",
      "[CV 5/5] END ...............................C=0.5, gamma=0.1; total time=   0.2s\n",
      "[CV 1/5] END ...............................C=0.5, gamma=0.5; total time=   0.2s\n",
      "[CV 2/5] END ...............................C=0.5, gamma=0.5; total time=   0.1s\n",
      "[CV 3/5] END ...............................C=0.5, gamma=0.5; total time=   0.2s\n",
      "[CV 4/5] END ...............................C=0.5, gamma=0.5; total time=   0.2s\n",
      "[CV 5/5] END ...............................C=0.5, gamma=0.5; total time=   0.2s\n",
      "[CV 1/5] END .................................C=0.5, gamma=1; total time=   0.1s\n",
      "[CV 2/5] END .................................C=0.5, gamma=1; total time=   0.1s\n",
      "[CV 3/5] END .................................C=0.5, gamma=1; total time=   0.1s\n",
      "[CV 4/5] END .................................C=0.5, gamma=1; total time=   0.2s\n",
      "[CV 5/5] END .................................C=0.5, gamma=1; total time=   0.1s\n",
      "[CV 1/5] END ...............................C=0.5, gamma=1.5; total time=   0.1s\n",
      "[CV 2/5] END ...............................C=0.5, gamma=1.5; total time=   0.1s\n",
      "[CV 3/5] END ...............................C=0.5, gamma=1.5; total time=   0.1s\n",
      "[CV 4/5] END ...............................C=0.5, gamma=1.5; total time=   0.1s\n",
      "[CV 5/5] END ...............................C=0.5, gamma=1.5; total time=   0.1s\n",
      "[CV 1/5] END .................................C=0.5, gamma=2; total time=   0.1s\n",
      "[CV 2/5] END .................................C=0.5, gamma=2; total time=   0.3s\n",
      "[CV 3/5] END .................................C=0.5, gamma=2; total time=   0.2s\n",
      "[CV 4/5] END .................................C=0.5, gamma=2; total time=   0.2s\n",
      "[CV 5/5] END .................................C=0.5, gamma=2; total time=   0.1s\n",
      "[CV 1/5] END .................................C=1, gamma=0.1; total time=   0.2s\n",
      "[CV 2/5] END .................................C=1, gamma=0.1; total time=   0.2s\n",
      "[CV 3/5] END .................................C=1, gamma=0.1; total time=   0.2s\n",
      "[CV 4/5] END .................................C=1, gamma=0.1; total time=   0.2s\n",
      "[CV 5/5] END .................................C=1, gamma=0.1; total time=   0.2s\n",
      "[CV 1/5] END .................................C=1, gamma=0.5; total time=   0.1s\n",
      "[CV 2/5] END .................................C=1, gamma=0.5; total time=   0.1s\n",
      "[CV 3/5] END .................................C=1, gamma=0.5; total time=   0.2s\n",
      "[CV 4/5] END .................................C=1, gamma=0.5; total time=   0.2s\n",
      "[CV 5/5] END .................................C=1, gamma=0.5; total time=   0.1s\n",
      "[CV 1/5] END ...................................C=1, gamma=1; total time=   0.1s\n",
      "[CV 2/5] END ...................................C=1, gamma=1; total time=   0.1s\n",
      "[CV 3/5] END ...................................C=1, gamma=1; total time=   0.1s\n",
      "[CV 4/5] END ...................................C=1, gamma=1; total time=   0.1s\n",
      "[CV 5/5] END ...................................C=1, gamma=1; total time=   0.1s\n",
      "[CV 1/5] END .................................C=1, gamma=1.5; total time=   0.1s\n",
      "[CV 2/5] END .................................C=1, gamma=1.5; total time=   0.1s\n",
      "[CV 3/5] END .................................C=1, gamma=1.5; total time=   0.2s\n",
      "[CV 4/5] END .................................C=1, gamma=1.5; total time=   0.2s\n",
      "[CV 5/5] END .................................C=1, gamma=1.5; total time=   0.1s\n",
      "[CV 1/5] END ...................................C=1, gamma=2; total time=   0.1s\n",
      "[CV 2/5] END ...................................C=1, gamma=2; total time=   0.1s\n",
      "[CV 3/5] END ...................................C=1, gamma=2; total time=   0.1s\n",
      "[CV 4/5] END ...................................C=1, gamma=2; total time=   0.1s\n",
      "[CV 5/5] END ...................................C=1, gamma=2; total time=   0.1s\n",
      "[CV 1/5] END ...............................C=1.5, gamma=0.1; total time=   0.2s\n",
      "[CV 2/5] END ...............................C=1.5, gamma=0.1; total time=   0.2s\n",
      "[CV 3/5] END ...............................C=1.5, gamma=0.1; total time=   0.1s\n",
      "[CV 4/5] END ...............................C=1.5, gamma=0.1; total time=   0.2s\n",
      "[CV 5/5] END ...............................C=1.5, gamma=0.1; total time=   0.2s\n",
      "[CV 1/5] END ...............................C=1.5, gamma=0.5; total time=   0.1s\n",
      "[CV 2/5] END ...............................C=1.5, gamma=0.5; total time=   0.1s\n",
      "[CV 3/5] END ...............................C=1.5, gamma=0.5; total time=   0.1s\n",
      "[CV 4/5] END ...............................C=1.5, gamma=0.5; total time=   0.1s\n",
      "[CV 5/5] END ...............................C=1.5, gamma=0.5; total time=   0.2s\n",
      "[CV 1/5] END .................................C=1.5, gamma=1; total time=   0.1s\n",
      "[CV 2/5] END .................................C=1.5, gamma=1; total time=   0.1s\n",
      "[CV 3/5] END .................................C=1.5, gamma=1; total time=   0.1s\n",
      "[CV 4/5] END .................................C=1.5, gamma=1; total time=   0.1s\n",
      "[CV 5/5] END .................................C=1.5, gamma=1; total time=   0.2s\n",
      "[CV 1/5] END ...............................C=1.5, gamma=1.5; total time=   0.2s\n",
      "[CV 2/5] END ...............................C=1.5, gamma=1.5; total time=   0.2s\n",
      "[CV 3/5] END ...............................C=1.5, gamma=1.5; total time=   0.2s\n",
      "[CV 4/5] END ...............................C=1.5, gamma=1.5; total time=   0.2s\n",
      "[CV 5/5] END ...............................C=1.5, gamma=1.5; total time=   0.1s\n",
      "[CV 1/5] END .................................C=1.5, gamma=2; total time=   0.1s\n",
      "[CV 2/5] END .................................C=1.5, gamma=2; total time=   0.1s\n",
      "[CV 3/5] END .................................C=1.5, gamma=2; total time=   0.1s\n",
      "[CV 4/5] END .................................C=1.5, gamma=2; total time=   0.1s\n",
      "[CV 5/5] END .................................C=1.5, gamma=2; total time=   0.1s\n",
      "[CV 1/5] END .................................C=2, gamma=0.1; total time=   0.2s\n",
      "[CV 2/5] END .................................C=2, gamma=0.1; total time=   0.2s\n",
      "[CV 3/5] END .................................C=2, gamma=0.1; total time=   0.2s\n",
      "[CV 4/5] END .................................C=2, gamma=0.1; total time=   0.2s\n",
      "[CV 5/5] END .................................C=2, gamma=0.1; total time=   0.1s\n",
      "[CV 1/5] END .................................C=2, gamma=0.5; total time=   0.1s\n",
      "[CV 2/5] END .................................C=2, gamma=0.5; total time=   0.1s\n",
      "[CV 3/5] END .................................C=2, gamma=0.5; total time=   0.1s\n",
      "[CV 4/5] END .................................C=2, gamma=0.5; total time=   0.1s\n",
      "[CV 5/5] END .................................C=2, gamma=0.5; total time=   0.1s\n",
      "[CV 1/5] END ...................................C=2, gamma=1; total time=   0.1s\n",
      "[CV 2/5] END ...................................C=2, gamma=1; total time=   0.1s\n",
      "[CV 3/5] END ...................................C=2, gamma=1; total time=   0.2s\n",
      "[CV 4/5] END ...................................C=2, gamma=1; total time=   0.2s\n",
      "[CV 5/5] END ...................................C=2, gamma=1; total time=   0.1s\n",
      "[CV 1/5] END .................................C=2, gamma=1.5; total time=   0.1s\n",
      "[CV 2/5] END .................................C=2, gamma=1.5; total time=   0.1s\n",
      "[CV 3/5] END .................................C=2, gamma=1.5; total time=   0.1s\n",
      "[CV 4/5] END .................................C=2, gamma=1.5; total time=   0.1s\n",
      "[CV 5/5] END .................................C=2, gamma=1.5; total time=   0.1s\n",
      "[CV 1/5] END ...................................C=2, gamma=2; total time=   0.1s\n",
      "[CV 2/5] END ...................................C=2, gamma=2; total time=   0.1s\n",
      "[CV 3/5] END ...................................C=2, gamma=2; total time=   0.1s\n",
      "[CV 4/5] END ...................................C=2, gamma=2; total time=   0.1s\n",
      "[CV 5/5] END ...................................C=2, gamma=2; total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 0.5, 1, 1.5, 2],\n",
       "                         'gamma': [0.1, 0.5, 1, 1.5, 2]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. fit(), 학습\n",
    "model_svc.fit(x_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2, 'gamma': 2}\n",
      "0.8107112856277716\n"
     ]
    }
   ],
   "source": [
    "print(model_svc.best_params_)\n",
    "print(model_svc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. predict(), 예측\n",
    "pred_svc = model_svc.predict(x_val_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.84       547\n",
      "           1       0.76      0.89      0.82       423\n",
      "\n",
      "    accuracy                           0.83       970\n",
      "   macro avg       0.83      0.84      0.83       970\n",
      "weighted avg       0.84      0.83      0.83       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train 및 val 데이터 정확도 확인 \n",
    "print(creport(pred_svc, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 데이터 결과 Confusion Matrix 확인\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "confusion = confusion_matrix(y_val, pred_svc)\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "plot_confusion_matrix(ax, confusion, fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV 1/5] END ..................................n_neighbors=1; total time=   0.0s\n",
      "[CV 2/5] END ..................................n_neighbors=1; total time=   0.0s\n",
      "[CV 3/5] END ..................................n_neighbors=1; total time=   0.0s\n",
      "[CV 4/5] END ..................................n_neighbors=1; total time=   0.0s\n",
      "[CV 5/5] END ..................................n_neighbors=1; total time=   0.0s\n",
      "[CV 1/5] END ..................................n_neighbors=2; total time=   0.0s\n",
      "[CV 2/5] END ..................................n_neighbors=2; total time=   0.0s\n",
      "[CV 3/5] END ..................................n_neighbors=2; total time=   0.0s\n",
      "[CV 4/5] END ..................................n_neighbors=2; total time=   0.0s\n",
      "[CV 5/5] END ..................................n_neighbors=2; total time=   0.0s\n",
      "[CV 1/5] END ..................................n_neighbors=3; total time=   0.0s\n",
      "[CV 2/5] END ..................................n_neighbors=3; total time=   0.0s\n",
      "[CV 3/5] END ..................................n_neighbors=3; total time=   0.0s\n",
      "[CV 4/5] END ..................................n_neighbors=3; total time=   0.0s\n",
      "[CV 5/5] END ..................................n_neighbors=3; total time=   0.0s\n",
      "[CV 1/5] END ..................................n_neighbors=4; total time=   0.0s\n",
      "[CV 2/5] END ..................................n_neighbors=4; total time=   0.0s\n",
      "[CV 3/5] END ..................................n_neighbors=4; total time=   0.0s\n",
      "[CV 4/5] END ..................................n_neighbors=4; total time=   0.0s\n",
      "[CV 5/5] END ..................................n_neighbors=4; total time=   0.0s\n",
      "[CV 1/5] END ..................................n_neighbors=5; total time=   0.0s\n",
      "[CV 2/5] END ..................................n_neighbors=5; total time=   0.0s\n",
      "[CV 3/5] END ..................................n_neighbors=5; total time=   0.0s\n",
      "[CV 4/5] END ..................................n_neighbors=5; total time=   0.0s\n",
      "[CV 5/5] END ..................................n_neighbors=5; total time=   0.0s\n",
      "[CV 1/5] END ..................................n_neighbors=6; total time=   0.0s\n",
      "[CV 2/5] END ..................................n_neighbors=6; total time=   0.0s\n",
      "[CV 3/5] END ..................................n_neighbors=6; total time=   0.0s\n",
      "[CV 4/5] END ..................................n_neighbors=6; total time=   0.0s\n",
      "[CV 5/5] END ..................................n_neighbors=6; total time=   0.0s\n",
      "[CV 1/5] END ..................................n_neighbors=7; total time=   0.0s\n",
      "[CV 2/5] END ..................................n_neighbors=7; total time=   0.0s\n",
      "[CV 3/5] END ..................................n_neighbors=7; total time=   0.0s\n",
      "[CV 4/5] END ..................................n_neighbors=7; total time=   0.0s\n",
      "[CV 5/5] END ..................................n_neighbors=7; total time=   0.0s\n",
      "[CV 1/5] END ..................................n_neighbors=8; total time=   0.0s\n",
      "[CV 2/5] END ..................................n_neighbors=8; total time=   0.0s\n",
      "[CV 3/5] END ..................................n_neighbors=8; total time=   0.0s\n",
      "[CV 4/5] END ..................................n_neighbors=8; total time=   0.0s\n",
      "[CV 5/5] END ..................................n_neighbors=8; total time=   0.0s\n",
      "[CV 1/5] END ..................................n_neighbors=9; total time=   0.0s\n",
      "[CV 2/5] END ..................................n_neighbors=9; total time=   0.0s\n",
      "[CV 3/5] END ..................................n_neighbors=9; total time=   0.0s\n",
      "[CV 4/5] END ..................................n_neighbors=9; total time=   0.0s\n",
      "[CV 5/5] END ..................................n_neighbors=9; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=10; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=10; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=10; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=10; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=10; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=11; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=11; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=11; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=11; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=11; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=12; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=12; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=12; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=12; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=12; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=13; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=13; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=13; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=13; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=13; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=14; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=14; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=14; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=14; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=14; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=15; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=15; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=15; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=15; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=15; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=16; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=16; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=16; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=16; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=16; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=17; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=17; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=17; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=17; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=17; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=18; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=18; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=18; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=18; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=18; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=19; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=19; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=19; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=19; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=19; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=20; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=20; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=20; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=20; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=20; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=21; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=21; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=21; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=21; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=21; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=22; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=22; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=22; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=22; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=22; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=23; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=23; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=23; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=23; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=23; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=24; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=24; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=24; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=24; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=24; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=25; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=25; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=25; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=25; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=25; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=26; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=26; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=26; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=26; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=26; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=27; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=27; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=27; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=27; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=27; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=28; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=28; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=28; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=28; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=28; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=29; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=29; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=29; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=29; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=29; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=30; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=30; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=30; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=30; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=30; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=31; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=31; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=31; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=31; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=31; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=32; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=32; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=32; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=32; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=32; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=33; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=33; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=33; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=33; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=33; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=34; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=34; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=34; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=34; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=34; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=35; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=35; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=35; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=35; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=35; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=36; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=36; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=36; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=36; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=36; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=37; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=37; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=37; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=37; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=37; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=38; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=38; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=38; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=38; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=38; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=39; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=39; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=39; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=39; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=39; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=40; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=40; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=40; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=40; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=40; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=41; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=41; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=41; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=41; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=41; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=42; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=42; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=42; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=42; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=42; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=43; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=43; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=43; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=43; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=43; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=44; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=44; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=44; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=44; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=44; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=45; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=45; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=45; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=45; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=45; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=46; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=46; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=46; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=46; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=46; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=47; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=47; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=47; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=47; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=47; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=48; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=48; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=48; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=48; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=48; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=49; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=49; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=49; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=49; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=49; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=50; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=50; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=50; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=50; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=50; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': range(1, 51)}, verbose=3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_neighbors' : range(1, 51)}\n",
    "knn = KNeighborsClassifier()\n",
    "model_knn = GridSearchCV(knn, params, cv=5, verbose=3)\n",
    "model_knn.fit(x_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 6}\n",
      "0.8562523198343394\n"
     ]
    }
   ],
   "source": [
    "print(model_knn.best_params_)\n",
    "print(model_knn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 ML 모델 객체 생성 (기반모델)\n",
    "#knn_clf = KNeighborsClassifier(n_neighbors=6)\n",
    "rf_clf = RandomForestClassifier(max_features=5, n_estimators=120)\n",
    "dt_clf = DecisionTreeClassifier(max_depth=9, min_samples_leaf=10)\n",
    "xgb_clf = XGBClassifier(learning_rate=0.2, max_depth=9, n_estimators=70)\n",
    "#svm_clf = SVC(C=2, gamma=2)\n",
    "\n",
    "# 메타모델(스태킹으로 만들어진 데이터 학습 및 예측)\n",
    "rf_final = RandomForestClassifier(max_features=5, n_estimators=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.2, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=9, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=70, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(x_train, y_train)\n",
    "dt_clf.fit(x_train, y_train)\n",
    "xgb_clf.fit(x_train, y_train)\n",
    "#svm_clf.fit(x_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-0d55403e2f45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mxgb_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrf_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdt_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#svm_pred = svm_clf.predict(x_val_s)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    628\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m--> 630\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[1;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n\u001b[0m\u001b[0;32m    403\u001b[0m                                     reset=False)\n\u001b[0;32m    404\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "xgb_pred = xgb_clf.predict(x_val)\n",
    "rf_pred = rf_clf.predict(x_val)\n",
    "dt_pred = dt_clf.predict(x_val)\n",
    "#svm_pred = svm_clf.predict(x_val_s)\n",
    "\n",
    "print('XGB 정확도 :',accuracy_score(y_val, xgb_pred))\n",
    "print('RF 정확도 :',accuracy_score(y_val, rf_pred))\n",
    "print('DT 정확도 :',accuracy_score(y_val, dt_pred))\n",
    "#print('ADA부스트 정확도 :',accuracy_score(y_val, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 970)\n",
      "(970, 2)\n"
     ]
    }
   ],
   "source": [
    "# 기반 모델의 예측 결과를 스태킹\n",
    "\n",
    "stacked_pred = np.array([xgb_pred, rf_pred])\n",
    "print(stacked_pred.shape)\n",
    "\n",
    "# transpose를 이용, 행과 열의 위치를 교환, 칼럼 레벨로 각 모델의 예측 결과를 피처로 사용\n",
    "\n",
    "stacked_pred = np.transpose(stacked_pred)\n",
    "print(stacked_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델 정확도 :  0.9474226804123711\n"
     ]
    }
   ],
   "source": [
    "# 메타 모델은 기반모델의 예측결과를 기반으로 학습\n",
    "\n",
    "dt_clf.fit(stacked_pred, y_val)\n",
    "final_pred = dt_clf.predict(stacked_pred)\n",
    "\n",
    "print('최종 메타 모델 정확도 : ',accuracy_score(y_val, final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_prep4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop('range_url', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2261, 21), (2441, 21))"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(['hyphens_ratio', 'total_tag'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. predict(), 예측\n",
    "pred_rf = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = model_xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# train 및 val 데이터 정확도 확인 \n",
    "print(pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred_rf)):\n",
    "    if pred_rf[i] == 1:\n",
    "        pred_rf[i] = -1\n",
    "    else: pred_rf[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 ...  1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(pred_rf, columns=['expected'])\n",
    "data['id'] = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['id', 'expected']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>2436</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437</th>\n",
       "      <td>2437</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>2438</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>2439</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>2440</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2441 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  expected\n",
       "0        0         1\n",
       "1        1         1\n",
       "2        2         1\n",
       "3        3        -1\n",
       "4        4         1\n",
       "...    ...       ...\n",
       "2436  2436         1\n",
       "2437  2437        -1\n",
       "2438  2438         1\n",
       "2439  2439        -1\n",
       "2440  2440        -1\n",
       "\n",
       "[2441 rows x 2 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('submission7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb1 = model_xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_xgb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred_xgb1)):\n",
    "    if pred_xgb1[i] == 1:\n",
    "        pred_xgb1[i] = -1\n",
    "    else: pred_xgb1[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(pred_xgb1, columns=['expected'])\n",
    "data1['id'] = data1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1[['id', 'expected']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
